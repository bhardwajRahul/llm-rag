{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345c364e-1395-499c-bd91-e4eb117fe943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from IPython.display import display\n",
    "from rich import print as rprint\n",
    "from rich.markdown import Markdown\n",
    "from rich.pretty import Pretty\n",
    "from rich.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a82ea84-71c2-464f-b6f4-1fc402f4c765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25bf618-9b16-4b27-bc98-4993289dd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG From Scratch: Part 9 (Query Translation - HyDE)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410814f2-2b92-4c20-9357-7972793284f4",
   "metadata": {},
   "source": [
    "# Query translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903de153-9de3-4f45-884f-3b99378cc11c",
   "metadata": {},
   "source": [
    "![](images/query-translation-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22872f-9628-4fac-8089-3fa2edd30e51",
   "metadata": {},
   "source": [
    "# Part 9: Query Translation - HyDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09ffb6-8754-47f1-8b97-a821fd8e94f1",
   "metadata": {},
   "source": [
    "![](images/09-hyde.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac6d36-a13c-42ed-a8f4-6795e46475c7",
   "metadata": {},
   "source": [
    "## Configure components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab45993b-bbd9-4bfc-a625-05bf2fe49f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7947660-1a81-4fba-8985-91cc918ca541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-449c178e-2364-4fb7-bf9b-b92d52287eb4-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1\n",
    ")\n",
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edca4c60-f492-4f5e-860b-aec63d65b28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "len(embeddings.embed_query(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c05aeb5-c158-47f3-a2fc-4e9d4eb1511d",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e23cf80-2c23-4872-9304-323ea7697e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e97bc41-ce13-4b21-9631-d9196ddc2a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c0b94a-e7ca-4214-8343-e9f69a64a7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82272c1e-903c-4afd-853c-84312c25956c",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5505d36-c430-43b4-a12d-3bda4671b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d0ff5a8-9469-4c1e-bf76-f2a36a186131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb81332-a8bf-4589-b885-6c1f8bf36733",
   "metadata": {},
   "source": [
    "## Store documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dba68874-7c1e-435e-b2fb-4f6b831b1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c8b5d56-91a2-4c01-a318-a7ced2c62e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = InMemoryVectorStore(embeddings)\n",
    "doc_ids = vectorstore.add_documents(documents=splits)\n",
    "len(doc_ids), len(vectorstore.store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe7ffa-9221-444c-ba6c-5a5f1ca3320e",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a020ed11-a677-47e8-aa19-9f3cd9775647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ed185d-4a4c-4e1e-b2c2-0e95f4225237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write a passage to answer the question\n",
      "Question: {question}\n",
      "Passage:\n"
     ]
    }
   ],
   "source": [
    "hyde_prompt_template = \"\"\"Please write a passage to answer the question\n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "print(hyde_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c680829-4ce4-48b9-8e2f-d069c2715e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question based on this context:\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_prompt_template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "print(rag_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d3467a2-666a-4b26-a944-f5d4d4681fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53e5b53d-1143-4739-bd43-7abc74fcdc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is task decomposition for LLM agents?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efd4dd07-610a-459b-bb43-c4e9344d572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    generated_documents: list[str]\n",
    "    hyde_embeddings: np.ndarray\n",
    "    context: list[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abce7134-6b43-4e35-afd0-3203d8a7bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_documents(state: State, config: RunnableConfig) -> list[Document]:\n",
    "    generated_documents_count = config['configurable'].get(\"generated_documents_count\", 3)\n",
    "    \n",
    "    hyde_prompt = hyde_prompt_template.format(\n",
    "        question=state[\"question\"]\n",
    "    )\n",
    "    generated_documents = llm.batch([hyde_prompt] * generated_documents_count)\n",
    "    \n",
    "    return {\"generated_documents\": [document.content for document in generated_documents]}\n",
    "\n",
    "\n",
    "def calculate_hyde_embeddings(state: State):\n",
    "    question_embeddings = np.array(embeddings.embed_query(state['question']))\n",
    "    generated_documents_embeddings = np.array(embeddings.embed_documents(state['generated_documents']))\n",
    "    hyde_embeddings = np.vstack([question_embeddings, generated_documents_embeddings]).mean(axis=0)\n",
    "    return {\"hyde_embeddings\": hyde_embeddings}\n",
    "\n",
    "\n",
    "def get_relevant_documents(state: State):\n",
    "    documents = vectorstore.similarity_search_by_vector(state[\"hyde_embeddings\"])\n",
    "    return {\"context\": documents}\n",
    "\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    docs_content = format_docs(state[\"context\"])\n",
    "    rag_prompt = rag_prompt_template.format(\n",
    "        context=docs_content,\n",
    "        question=state[\"question\"]\n",
    "    )\n",
    "    response = llm.invoke([\n",
    "        HumanMessage(content=rag_prompt)\n",
    "    ])\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1115f445-fbe8-43ab-91a7-c17ff26aec99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7fec343aac50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"generate_documents\", generate_documents)\n",
    "graph_builder.add_node(\"calculate_hyde_embeddings\", calculate_hyde_embeddings)\n",
    "graph_builder.add_node(\"get_relevant_documents\", get_relevant_documents)\n",
    "graph_builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "graph_builder.add_edge(START, \"generate_documents\")\n",
    "graph_builder.add_edge(\"generate_documents\", \"calculate_hyde_embeddings\")\n",
    "graph_builder.add_edge(\"calculate_hyde_embeddings\", \"get_relevant_documents\")\n",
    "graph_builder.add_edge(\"get_relevant_documents\", \"generate_answer\")\n",
    "graph_builder.add_edge(\"generate_answer\", END)\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9aa8516-8eae-4d29-a6aa-640bc661c4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is task decomposition for LLM agents?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is task decomposition for LLM agents?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generated_documents'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for Large Language Model (LLM) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks or problems into smaller, more manageable sub-tasks that can be addressed sequentially or concurrently. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">method leverages the capabilities of LLMs to analyze and understand diverse contexts, allowing them to tackle </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">intricate challenges more effectively. \\n\\nBy decomposing a task, an LLM agent can focus on one aspect at a time, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">minimizing cognitive overload and improving the clarity of its outputs. For instance, if an agent is tasked with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">writing a research paper, it might decompose this task into several key sub-tasks: conducting literature reviews, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">developing an outline, drafting sections, and editing for coherence and style. \\n\\nEach of these sub-tasks can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">handled individually, allowing the agent to produce high-quality responses for each component before integrating </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">them into a coherent final product. This approach not only enhances the performance and efficiency of LLM agents </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">but also makes it easier for users to interact with and guide the completion of complex tasks. In summary, task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition serves as a crucial strategy to optimize LLM functionality and output quality, enabling them to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectively manage extensive and multifaceted assignments.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks or objectives into smaller, manageable components that can be more easily executed by the language model. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This approach enhances the model's efficiency and effectiveness in handling intricate queries or multi-step </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">processes.\\n\\nIn practical terms, task decomposition involves identifying the various subtasks that contribute to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an overall goal. For instance, if the objective is to write a research paper, the decomposition might include </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">defining the research question, conducting a literature review, outlining sections, drafting content, and revising </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the final document. By segmenting the task, the LLM can focus on one aspect at a time, allowing for more precise </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and contextually relevant responses.\\n\\nThis method also allows for improved coordination when multiple LLM agents </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">are involved, as each agent can specialize in specific subtasks. Consequently, task decomposition not only </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">increases the accuracy of outputs but also streamlines the overall workflow, making it easier for users to achieve </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">their desired results.\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down a complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task into smaller, more manageable components that can be individually understood and executed by the model. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">approach involves identifying the various sub-tasks or steps required to achieve the overall objective, allowing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the LLM to focus on specific aspects of a task one at a time. \\n\\nBy decomposing tasks, LLM agents can enhance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">their problem-solving capabilities, improve efficiency, and reduce the likelihood of errors. For example, if the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">overall task is to write a research paper, task decomposition might involve first gathering information, then </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">creating an outline, followed by writing each section, and finally editing the document. Each of these sub-tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be addressed sequentially or independently, enabling a more structured approach to complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">challenges.\\n\\nAdditionally, task decomposition can facilitate better collaboration between LLMs and human users, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as both parties can work on discrete components of a project. It also allows the model to leverage its strengths in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specific domains (like generating text or analyzing data) while simplifying the cognitive load required to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">understand a multi-faceted task. Overall, task decomposition is a critical strategy for maximizing the potential of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM agents in various applications, from natural language processing to automated decision-making.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hyde_embeddings'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00807217</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02233843</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05167598</span>, <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01630242</span>,\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.00076759</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01732805</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (large language model) agents refers to the process of breaking down </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks into smaller, more manageable subgoals. This is accomplished using a technique known as Chain of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Thought (CoT), where the model is prompted to â€œthink step by step.â€ By doing so, the agent can transform a large, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complicated task into simpler, sequential steps that are easier to handle. This not only aids in effectively </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">managing complex tasks but also provides insight into the modelâ€™s reasoning and thought process.'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'What is task decomposition for LLM agents?'\u001b[0m,\n",
       "    \u001b[32m'generated_documents'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'Task decomposition for Large Language Model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks or problems into smaller, more manageable sub-tasks that can be addressed sequentially or concurrently. This \u001b[0m\n",
       "\u001b[32mmethod leverages the capabilities of LLMs to analyze and understand diverse contexts, allowing them to tackle \u001b[0m\n",
       "\u001b[32mintricate challenges more effectively. \\n\\nBy decomposing a task, an LLM agent can focus on one aspect at a time, \u001b[0m\n",
       "\u001b[32mminimizing cognitive overload and improving the clarity of its outputs. For instance, if an agent is tasked with \u001b[0m\n",
       "\u001b[32mwriting a research paper, it might decompose this task into several key sub-tasks: conducting literature reviews, \u001b[0m\n",
       "\u001b[32mdeveloping an outline, drafting sections, and editing for coherence and style. \\n\\nEach of these sub-tasks can be \u001b[0m\n",
       "\u001b[32mhandled individually, allowing the agent to produce high-quality responses for each component before integrating \u001b[0m\n",
       "\u001b[32mthem into a coherent final product. This approach not only enhances the performance and efficiency of LLM agents \u001b[0m\n",
       "\u001b[32mbut also makes it easier for users to interact with and guide the completion of complex tasks. In summary, task \u001b[0m\n",
       "\u001b[32mdecomposition serves as a crucial strategy to optimize LLM functionality and output quality, enabling them to \u001b[0m\n",
       "\u001b[32meffectively manage extensive and multifaceted assignments.'\u001b[0m,\n",
       "        \u001b[32m\"Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks or objectives into smaller, manageable components that can be more easily executed by the language model. \u001b[0m\n",
       "\u001b[32mThis approach enhances the model's efficiency and effectiveness in handling intricate queries or multi-step \u001b[0m\n",
       "\u001b[32mprocesses.\\n\\nIn practical terms, task decomposition involves identifying the various subtasks that contribute to \u001b[0m\n",
       "\u001b[32man overall goal. For instance, if the objective is to write a research paper, the decomposition might include \u001b[0m\n",
       "\u001b[32mdefining the research question, conducting a literature review, outlining sections, drafting content, and revising \u001b[0m\n",
       "\u001b[32mthe final document. By segmenting the task, the LLM can focus on one aspect at a time, allowing for more precise \u001b[0m\n",
       "\u001b[32mand contextually relevant responses.\\n\\nThis method also allows for improved coordination when multiple LLM agents \u001b[0m\n",
       "\u001b[32mare involved, as each agent can specialize in specific subtasks. Consequently, task decomposition not only \u001b[0m\n",
       "\u001b[32mincreases the accuracy of outputs but also streamlines the overall workflow, making it easier for users to achieve \u001b[0m\n",
       "\u001b[32mtheir desired results.\"\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down a complex \u001b[0m\n",
       "\u001b[32mtask into smaller, more manageable components that can be individually understood and executed by the model. This \u001b[0m\n",
       "\u001b[32mapproach involves identifying the various sub-tasks or steps required to achieve the overall objective, allowing \u001b[0m\n",
       "\u001b[32mthe LLM to focus on specific aspects of a task one at a time. \\n\\nBy decomposing tasks, LLM agents can enhance \u001b[0m\n",
       "\u001b[32mtheir problem-solving capabilities, improve efficiency, and reduce the likelihood of errors. For example, if the \u001b[0m\n",
       "\u001b[32moverall task is to write a research paper, task decomposition might involve first gathering information, then \u001b[0m\n",
       "\u001b[32mcreating an outline, followed by writing each section, and finally editing the document. Each of these sub-tasks \u001b[0m\n",
       "\u001b[32mcan be addressed sequentially or independently, enabling a more structured approach to complex \u001b[0m\n",
       "\u001b[32mchallenges.\\n\\nAdditionally, task decomposition can facilitate better collaboration between LLMs and human users, \u001b[0m\n",
       "\u001b[32mas both parties can work on discrete components of a project. It also allows the model to leverage its strengths in\u001b[0m\n",
       "\u001b[32mspecific domains \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlike generating text or analyzing data\u001b[0m\u001b[32m)\u001b[0m\u001b[32m while simplifying the cognitive load required to \u001b[0m\n",
       "\u001b[32munderstand a multi-faceted task. Overall, task decomposition is a critical strategy for maximizing the potential of\u001b[0m\n",
       "\u001b[32mLLM agents in various applications, from natural language processing to automated decision-making.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'hyde_embeddings'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.00807217\u001b[0m,  \u001b[1;36m0.02233843\u001b[0m,  \u001b[1;36m0.05167598\u001b[0m, \u001b[33m...\u001b[0m,  \u001b[1;36m0.01630242\u001b[0m,\n",
       "       \u001b[1;36m-0.00076759\u001b[0m,  \u001b[1;36m0.01732805\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down \u001b[0m\n",
       "\u001b[32mcomplex tasks into smaller, more manageable subgoals. This is accomplished using a technique known as Chain of \u001b[0m\n",
       "\u001b[32mThought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, where the model is prompted to â€œthink step by step.â€ By doing so, the agent can transform a large, \u001b[0m\n",
       "\u001b[32mcomplicated task into simpler, sequential steps that are easier to handle. This not only aids in effectively \u001b[0m\n",
       "\u001b[32mmanaging complex tasks but also provides insight into the modelâ€™s reasoning and thought process.'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task decomposition for LLM (large language model) agents refers to the process of breaking down complex tasks into \n",
       "smaller, more manageable subgoals. This is accomplished using a technique known as Chain of Thought (CoT), where   \n",
       "the model is prompted to â€œthink step by step.â€ By doing so, the agent can transform a large, complicated task into \n",
       "simpler, sequential steps that are easier to handle. This not only aids in effectively managing complex tasks but  \n",
       "also provides insight into the modelâ€™s reasoning and thought process.                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Task decomposition for LLM (large language model) agents refers to the process of breaking down complex tasks into \n",
       "smaller, more manageable subgoals. This is accomplished using a technique known as Chain of Thought (CoT), where   \n",
       "the model is prompted to â€œthink step by step.â€ By doing so, the agent can transform a large, complicated task into \n",
       "simpler, sequential steps that are easier to handle. This not only aids in effectively managing complex tasks but  \n",
       "also provides insight into the modelâ€™s reasoning and thought process.                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(query)\n",
    "\n",
    "response = graph.invoke({\"question\": query})\n",
    "\n",
    "display(Pretty(response, max_depth=2))\n",
    "display(Markdown(response[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dfd34b0-bb3d-43a1-9764-5708bd93ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is task decomposition for LLM agents?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is task decomposition for LLM agents?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generated_documents'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for Large Language Model (LLM) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, more manageable sub-tasks that can be tackled individually. This approach enhances the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiency and effectiveness of LLMs in various applications, including natural language understanding, data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">analysis, and problem-solving scenarios. By analyzing a larger task and identifying its constituent components, LLM</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents can focus on each part with greater precision, leading to improved outcomes.\\n\\nFor example, if an LLM is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasked with writing a research paper, task decomposition would involve dividing the process into specific actions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">such as conducting literature reviews, drafting sections, generating references, and editing the final document. By</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">systematically addressing these smaller tasks, the LLM can maintain clarity and coherence while also ensuring that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">each aspect is addressed thoroughly.\\n\\nMoreover, task decomposition allows for parallel processing, where </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">different sub-tasks can be handled simultaneously or by multiple LLMs, thereby accelerating the overall workflow. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">It also aids in error reduction, as smaller components are often easier to validate and correct than a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comprehensive task. Ultimately, task decomposition empowers LLM agents to operate more strategically and produce </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">higher-quality outputs in diverse contexts.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the method of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, more manageable components that can be addressed individually. This approach is essential for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">optimizing the performance of LLMs, as it enables them to focus on specific elements of a problem without being </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">overwhelmed by its entirety.\\n\\nWhen dealing with intricate queries or multi-step processes, task decomposition </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">allows LLM agents to analyze each part systematically. For example, if the goal is to write a research paper, the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks could be decomposed into components such as topic selection, literature review, outline creation, drafting, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and revision. By addressing each component step-by-step, the LLM can generate more coherent and structured </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">responses, ultimately leading to a higher quality output.\\n\\nFurthermore, task decomposition enhances the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiency of LLM agents by facilitating parallel processing, where different sub-tasks can be tackled </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">simultaneously or sequentially based on dependencies. This method not only improves the overall workflow but also </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aids in better resource allocation, allowing the model to utilize its capabilities more effectively. Overall, task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition plays a crucial role in maximizing the utility and performance of LLM agents in a variety of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">applications, from academic writing to complex problem-solving in diverse fields.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for large language model (LLM) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, more manageable sub-tasks that can be addressed more easily by the model. This approach </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhances the efficiency and effectiveness of LLMs in various applications, as it allows them to focus on specific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components of a broader task one at a time. By decomposing a task, an LLM can leverage its abilities to generate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">coherent responses, extract relevant information, and perform reasoning in a more structured manner.\\n\\nFor </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">instance, when given a multifaceted question, an LLM agent might first identify key components, such as gathering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data, analyzing context, and synthesizing a final response. Each of these components can then be processed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sequentially or in parallel, which increases the likelihood of achieving accurate and comprehensive results. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Additionally, task decomposition can facilitate iterative improvements, as each sub-task can be reviewed and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">refined independently before being integrated into the overall solution. Ultimately, task decomposition empowers </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM agents to tackle complex challenges in a systematic way, improving their performance and usability across </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">various domains.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM agents refers to the process of breaking down complex tasks into smaller, more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manageable sub-tasks that can be individually addressed by the language model. This method leverages the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capabilities of large language models (LLMs) to approach intricate problems systematically, enhancing efficiency </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and effectiveness in generating solutions or responses. By deconstructing a task, such as writing an essay, solving</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a mathematical problem, or developing a software script, LLM agents can focus on one aspect at a timeâ€”like </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">brainstorming ideas, outlining the structure, or refining languageâ€”before integrating these elements into a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cohesive output. This systematic approach not only simplifies the task but also helps to ensure that the model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">addresses all relevant components thoroughly, minimizing the risk of overlooking critical details. Task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition is particularly beneficial in complex scenarios where the final output requires a nuanced </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">understanding of multiple factors or sequential reasoning.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, more manageable components that can be individually addressed and solved by the model. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">approach leverages the strengths of LLMs by enabling them to handle intricate problems in a structured manner, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing their efficiency and effectiveness.\\n\\nIn practice, task decomposition involves identifying the various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">steps or sub-tasks involved in achieving a larger goal. For instance, if the overall task is to write a research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">paper, the decomposition might involve several stages: selecting a topic, conducting a literature review, outlining</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the structure, writing individual sections, and finally editing and formatting the document. By isolating these </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components, an LLM can focus on one aspect at a time, improving the quality of its output through focused </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">processing.\\n\\nMoreover, task decomposition allows for better collaboration between LLMs and human users. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provides a framework for users to interact with the agent more effectively, as they can guide the model through </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">each sub-task, offering feedback and adjustments along the way. This iterative process ensures that the end result </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aligns closely with the userâ€™s expectations and requirements.\\n\\nOverall, task decomposition is a valuable strategy</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in optimizing the capabilities of LLM agents, rendering complex tasks approachable and facilitating seamless </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">human-agent interaction.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hyde_embeddings'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00585794</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01827631</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05184456</span>, <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01400666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00047919</span>,\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02011572</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM agents is the process of breaking down complicated tasks into smaller, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manageable subgoals. This approach allows agents to efficiently handle complex tasks by transforming large, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">challenging objectives into simpler, more easily addressable steps. The technique of Chain of Thought (CoT) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">prompting enhances this process by instructing the model to \"think step by step,\" which utilizes additional </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computational resources during test time to articulate the model\\'s reasoning and planning. This structured </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition not only aids in task execution but also provides insight into the modelâ€™s thought process.'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'What is task decomposition for LLM agents?'\u001b[0m,\n",
       "    \u001b[32m'generated_documents'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'Task decomposition for Large Language Model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, more manageable sub-tasks that can be tackled individually. This approach enhances the \u001b[0m\n",
       "\u001b[32mefficiency and effectiveness of LLMs in various applications, including natural language understanding, data \u001b[0m\n",
       "\u001b[32manalysis, and problem-solving scenarios. By analyzing a larger task and identifying its constituent components, LLM\u001b[0m\n",
       "\u001b[32magents can focus on each part with greater precision, leading to improved outcomes.\\n\\nFor example, if an LLM is \u001b[0m\n",
       "\u001b[32mtasked with writing a research paper, task decomposition would involve dividing the process into specific actions \u001b[0m\n",
       "\u001b[32msuch as conducting literature reviews, drafting sections, generating references, and editing the final document. By\u001b[0m\n",
       "\u001b[32msystematically addressing these smaller tasks, the LLM can maintain clarity and coherence while also ensuring that \u001b[0m\n",
       "\u001b[32meach aspect is addressed thoroughly.\\n\\nMoreover, task decomposition allows for parallel processing, where \u001b[0m\n",
       "\u001b[32mdifferent sub-tasks can be handled simultaneously or by multiple LLMs, thereby accelerating the overall workflow. \u001b[0m\n",
       "\u001b[32mIt also aids in error reduction, as smaller components are often easier to validate and correct than a \u001b[0m\n",
       "\u001b[32mcomprehensive task. Ultimately, task decomposition empowers LLM agents to operate more strategically and produce \u001b[0m\n",
       "\u001b[32mhigher-quality outputs in diverse contexts.'\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the method of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, more manageable components that can be addressed individually. This approach is essential for \u001b[0m\n",
       "\u001b[32moptimizing the performance of LLMs, as it enables them to focus on specific elements of a problem without being \u001b[0m\n",
       "\u001b[32moverwhelmed by its entirety.\\n\\nWhen dealing with intricate queries or multi-step processes, task decomposition \u001b[0m\n",
       "\u001b[32mallows LLM agents to analyze each part systematically. For example, if the goal is to write a research paper, the \u001b[0m\n",
       "\u001b[32mtasks could be decomposed into components such as topic selection, literature review, outline creation, drafting, \u001b[0m\n",
       "\u001b[32mand revision. By addressing each component step-by-step, the LLM can generate more coherent and structured \u001b[0m\n",
       "\u001b[32mresponses, ultimately leading to a higher quality output.\\n\\nFurthermore, task decomposition enhances the \u001b[0m\n",
       "\u001b[32mefficiency of LLM agents by facilitating parallel processing, where different sub-tasks can be tackled \u001b[0m\n",
       "\u001b[32msimultaneously or sequentially based on dependencies. This method not only improves the overall workflow but also \u001b[0m\n",
       "\u001b[32maids in better resource allocation, allowing the model to utilize its capabilities more effectively. Overall, task \u001b[0m\n",
       "\u001b[32mdecomposition plays a crucial role in maximizing the utility and performance of LLM agents in a variety of \u001b[0m\n",
       "\u001b[32mapplications, from academic writing to complex problem-solving in diverse fields.'\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, more manageable sub-tasks that can be addressed more easily by the model. This approach \u001b[0m\n",
       "\u001b[32menhances the efficiency and effectiveness of LLMs in various applications, as it allows them to focus on specific \u001b[0m\n",
       "\u001b[32mcomponents of a broader task one at a time. By decomposing a task, an LLM can leverage its abilities to generate \u001b[0m\n",
       "\u001b[32mcoherent responses, extract relevant information, and perform reasoning in a more structured manner.\\n\\nFor \u001b[0m\n",
       "\u001b[32minstance, when given a multifaceted question, an LLM agent might first identify key components, such as gathering \u001b[0m\n",
       "\u001b[32mdata, analyzing context, and synthesizing a final response. Each of these components can then be processed \u001b[0m\n",
       "\u001b[32msequentially or in parallel, which increases the likelihood of achieving accurate and comprehensive results. \u001b[0m\n",
       "\u001b[32mAdditionally, task decomposition can facilitate iterative improvements, as each sub-task can be reviewed and \u001b[0m\n",
       "\u001b[32mrefined independently before being integrated into the overall solution. Ultimately, task decomposition empowers \u001b[0m\n",
       "\u001b[32mLLM agents to tackle complex challenges in a systematic way, improving their performance and usability across \u001b[0m\n",
       "\u001b[32mvarious domains.'\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for LLM agents refers to the process of breaking down complex tasks into smaller, more \u001b[0m\n",
       "\u001b[32mmanageable sub-tasks that can be individually addressed by the language model. This method leverages the \u001b[0m\n",
       "\u001b[32mcapabilities of large language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to approach intricate problems systematically, enhancing efficiency \u001b[0m\n",
       "\u001b[32mand effectiveness in generating solutions or responses. By deconstructing a task, such as writing an essay, solving\u001b[0m\n",
       "\u001b[32ma mathematical problem, or developing a software script, LLM agents can focus on one aspect at a timeâ€”like \u001b[0m\n",
       "\u001b[32mbrainstorming ideas, outlining the structure, or refining languageâ€”before integrating these elements into a \u001b[0m\n",
       "\u001b[32mcohesive output. This systematic approach not only simplifies the task but also helps to ensure that the model \u001b[0m\n",
       "\u001b[32maddresses all relevant components thoroughly, minimizing the risk of overlooking critical details. Task \u001b[0m\n",
       "\u001b[32mdecomposition is particularly beneficial in complex scenarios where the final output requires a nuanced \u001b[0m\n",
       "\u001b[32munderstanding of multiple factors or sequential reasoning.'\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, more manageable components that can be individually addressed and solved by the model. This \u001b[0m\n",
       "\u001b[32mapproach leverages the strengths of LLMs by enabling them to handle intricate problems in a structured manner, \u001b[0m\n",
       "\u001b[32menhancing their efficiency and effectiveness.\\n\\nIn practice, task decomposition involves identifying the various \u001b[0m\n",
       "\u001b[32msteps or sub-tasks involved in achieving a larger goal. For instance, if the overall task is to write a research \u001b[0m\n",
       "\u001b[32mpaper, the decomposition might involve several stages: selecting a topic, conducting a literature review, outlining\u001b[0m\n",
       "\u001b[32mthe structure, writing individual sections, and finally editing and formatting the document. By isolating these \u001b[0m\n",
       "\u001b[32mcomponents, an LLM can focus on one aspect at a time, improving the quality of its output through focused \u001b[0m\n",
       "\u001b[32mprocessing.\\n\\nMoreover, task decomposition allows for better collaboration between LLMs and human users. It \u001b[0m\n",
       "\u001b[32mprovides a framework for users to interact with the agent more effectively, as they can guide the model through \u001b[0m\n",
       "\u001b[32meach sub-task, offering feedback and adjustments along the way. This iterative process ensures that the end result \u001b[0m\n",
       "\u001b[32maligns closely with the userâ€™s expectations and requirements.\\n\\nOverall, task decomposition is a valuable strategy\u001b[0m\n",
       "\u001b[32min optimizing the capabilities of LLM agents, rendering complex tasks approachable and facilitating seamless \u001b[0m\n",
       "\u001b[32mhuman-agent interaction.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'hyde_embeddings'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.00585794\u001b[0m, \u001b[1;36m0.01827631\u001b[0m, \u001b[1;36m0.05184456\u001b[0m, \u001b[33m...\u001b[0m, \u001b[1;36m0.01400666\u001b[0m, \u001b[1;36m0.00047919\u001b[0m,\n",
       "       \u001b[1;36m0.02011572\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'Task decomposition for LLM agents is the process of breaking down complicated tasks into smaller, \u001b[0m\n",
       "\u001b[32mmanageable subgoals. This approach allows agents to efficiently handle complex tasks by transforming large, \u001b[0m\n",
       "\u001b[32mchallenging objectives into simpler, more easily addressable steps. The technique of Chain of Thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mprompting enhances this process by instructing the model to \"think step by step,\" which utilizes additional \u001b[0m\n",
       "\u001b[32mcomputational resources during test time to articulate the model\\'s reasoning and planning. This structured \u001b[0m\n",
       "\u001b[32mdecomposition not only aids in task execution but also provides insight into the modelâ€™s thought process.'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task decomposition for LLM agents is the process of breaking down complicated tasks into smaller, manageable       \n",
       "subgoals. This approach allows agents to efficiently handle complex tasks by transforming large, challenging       \n",
       "objectives into simpler, more easily addressable steps. The technique of Chain of Thought (CoT) prompting enhances \n",
       "this process by instructing the model to \"think step by step,\" which utilizes additional computational resources   \n",
       "during test time to articulate the model's reasoning and planning. This structured decomposition not only aids in  \n",
       "task execution but also provides insight into the modelâ€™s thought process.                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Task decomposition for LLM agents is the process of breaking down complicated tasks into smaller, manageable       \n",
       "subgoals. This approach allows agents to efficiently handle complex tasks by transforming large, challenging       \n",
       "objectives into simpler, more easily addressable steps. The technique of Chain of Thought (CoT) prompting enhances \n",
       "this process by instructing the model to \"think step by step,\" which utilizes additional computational resources   \n",
       "during test time to articulate the model's reasoning and planning. This structured decomposition not only aids in  \n",
       "task execution but also provides insight into the modelâ€™s thought process.                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(query)\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"generated_documents_count\": 5,   \n",
    "    }\n",
    "}\n",
    "response = graph.invoke({\"question\": query}, config=config)\n",
    "\n",
    "display(Pretty(response, max_depth=2))\n",
    "display(Markdown(response[\"answer\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-rag",
   "language": "python",
   "name": "llm-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
