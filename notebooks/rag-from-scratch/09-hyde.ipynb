{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345c364e-1395-499c-bd91-e4eb117fe943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from IPython.display import display\n",
    "from rich import print as rprint\n",
    "from rich.markdown import Markdown\n",
    "from rich.pretty import Pretty\n",
    "from rich.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a82ea84-71c2-464f-b6f4-1fc402f4c765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25bf618-9b16-4b27-bc98-4993289dd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG From Scratch: Part 9 (Query Translation - HyDE)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410814f2-2b92-4c20-9357-7972793284f4",
   "metadata": {},
   "source": [
    "# Query translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903de153-9de3-4f45-884f-3b99378cc11c",
   "metadata": {},
   "source": [
    "![](images/query-translation-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22872f-9628-4fac-8089-3fa2edd30e51",
   "metadata": {},
   "source": [
    "# Part 9: Query Translation - HyDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09ffb6-8754-47f1-8b97-a821fd8e94f1",
   "metadata": {},
   "source": [
    "![](images/09-hyde.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac6d36-a13c-42ed-a8f4-6795e46475c7",
   "metadata": {},
   "source": [
    "## Configure components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab45993b-bbd9-4bfc-a625-05bf2fe49f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7947660-1a81-4fba-8985-91cc918ca541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-bb337a70-0689-467c-b730-8da1af54be8f-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1\n",
    ")\n",
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edca4c60-f492-4f5e-860b-aec63d65b28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "len(embeddings.embed_query(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c05aeb5-c158-47f3-a2fc-4e9d4eb1511d",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e23cf80-2c23-4872-9304-323ea7697e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e97bc41-ce13-4b21-9631-d9196ddc2a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c0b94a-e7ca-4214-8343-e9f69a64a7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82272c1e-903c-4afd-853c-84312c25956c",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5505d36-c430-43b4-a12d-3bda4671b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d0ff5a8-9469-4c1e-bf76-f2a36a186131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb81332-a8bf-4589-b885-6c1f8bf36733",
   "metadata": {},
   "source": [
    "## Store documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dba68874-7c1e-435e-b2fb-4f6b831b1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c8b5d56-91a2-4c01-a318-a7ced2c62e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = InMemoryVectorStore(embeddings)\n",
    "doc_ids = vectorstore.add_documents(documents=splits)\n",
    "len(doc_ids), len(vectorstore.store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe7ffa-9221-444c-ba6c-5a5f1ca3320e",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a020ed11-a677-47e8-aa19-9f3cd9775647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ed185d-4a4c-4e1e-b2c2-0e95f4225237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Please write a passage to answer the question\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "Passage:\n"
     ]
    }
   ],
   "source": [
    "hyde_prompt_template = \"\"\"Please write a passage to answer the question\n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "hyde_prompt = ChatPromptTemplate.from_template(hyde_prompt_template)\n",
    "hyde_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c680829-4ce4-48b9-8e2f-d069c2715e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Answer the following question based on this context:\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_prompt_template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_prompt_template)\n",
    "rag_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d3467a2-666a-4b26-a944-f5d4d4681fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53e5b53d-1143-4739-bd43-7abc74fcdc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is task decomposition for LLM agents?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749698de-245f-486f-876c-948e3ec96bb0",
   "metadata": {},
   "source": [
    "### LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee6bcf04-9150-4247-848e-f00e529629ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import chain, RunnableConfig, RunnableParallel, RunnablePassthrough\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd507f-dd4c-455c-8e40-d68dbf8b50b5",
   "metadata": {},
   "source": [
    "#### Define retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cefea0d-3d70-4bcf-9b1b-59377e5c259b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into smaller, more manageable subtasks that an LLM can handle effectively. This approach is essential in maximizing</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the efficiency and effectiveness of LLMs, especially when faced with intricate or multifaceted queries. By </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposing a larger task, the model can focus on one aspect at a time, thereby reducing the cognitive load and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">potential for errors.\\n\\nFor instance, if the overall task is to generate a research report, task decomposition </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">would involve identifying and tackling subtasks such as gathering relevant information, outlining key sections, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">drafting individual paragraphs, and formatting the final document. Each of these subtasks can be addressed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sequentially or in parallel, allowing the LLM to leverage its strengths in language understanding and generation in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a more structured manner.\\n\\nTask decomposition also facilitates better interaction with users, as it allows the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM to provide iterative feedback or partial results, thereby enhancing the collaborative process. This method not </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">only improves the overall quality of the output but also aids in clarifying user intentions and expectations, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">leading to more satisfactory outcomes. In summary, task decomposition is a strategic approach that empowers LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents to manage complexity by converting challenging problems into simpler, actionable components.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for Large Language Model (LLM) agents refers to the process of breaking down complex tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into smaller, more manageable subtasks that can be more easily understood and executed by the model. This approach </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">leverages the capabilities of LLMs to analyze and generate language in a structured manner, enabling more effective</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problem-solving and decision-making.\\n\\nIn practice, task decomposition involves identifying the key components of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a larger task and articulating them clearly. For example, if the overarching goal is to generate a research paper, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition might involve subtasks such as selecting a topic, conducting a literature review, outlining the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">structure, drafting individual sections, and finally editing the content. By systematically tackling each subtask, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the LLM can produce higher quality outputs and maintain coherence throughout the project.\\n\\nFurthermore, task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition can enhance collaboration between LLM agents and users, allowing for iterative feedback and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">adjustments at each stage of the process. This method also facilitates the integration of external resources, such </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as databases or APIs, to gather information relevant to specific subtasks, thereby enriching the overall output. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Ultimately, effective task decomposition not only improves the efficiency of LLM agents but also harnesses their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language processing power to deliver more precise and relevant results.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"Task decomposition for Large Language Model (LLM) agents refers to the process of breaking down complex tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into smaller, manageable sub-tasks that the LLM can handle more effectively. This approach is vital for enhancing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the performance and efficiency of LLMs when addressing intricate problems or queries. By segmenting a larger task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into simpler components, the LLM can leverage its strengths in understanding and generating language while focusing</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on one aspect of the task at a time.\\n\\nFor example, if the overall task is to draft a research paper, task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition might involve dividing it into sub-tasks such as conducting a literature review, outlining key </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sections, drafting individual paragraphs, and revising content for clarity and coherence. Each of these smaller </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks can be tackled sequentially or in parallel, allowing the agent to produce more focused and coherent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outputs.\\n\\nMoreover, task decomposition facilitates better resource management, as it allows LLMs to optimize </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">their processing capabilities and memory usage by concentrating on one part of the task at a time. This structured </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">approach not only enhances the output quality but also provides a clearer framework for assessing the model's </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance on each sub-task. Consequently, task decomposition serves as a powerful strategy for maximizing the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">utility of LLM agents in various applications, from content creation to problem-solving in diverse domains.\"</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex tasks \u001b[0m\n",
       "\u001b[32minto smaller, more manageable subtasks that an LLM can handle effectively. This approach is essential in maximizing\u001b[0m\n",
       "\u001b[32mthe efficiency and effectiveness of LLMs, especially when faced with intricate or multifaceted queries. By \u001b[0m\n",
       "\u001b[32mdecomposing a larger task, the model can focus on one aspect at a time, thereby reducing the cognitive load and \u001b[0m\n",
       "\u001b[32mpotential for errors.\\n\\nFor instance, if the overall task is to generate a research report, task decomposition \u001b[0m\n",
       "\u001b[32mwould involve identifying and tackling subtasks such as gathering relevant information, outlining key sections, \u001b[0m\n",
       "\u001b[32mdrafting individual paragraphs, and formatting the final document. Each of these subtasks can be addressed \u001b[0m\n",
       "\u001b[32msequentially or in parallel, allowing the LLM to leverage its strengths in language understanding and generation in\u001b[0m\n",
       "\u001b[32ma more structured manner.\\n\\nTask decomposition also facilitates better interaction with users, as it allows the \u001b[0m\n",
       "\u001b[32mLLM to provide iterative feedback or partial results, thereby enhancing the collaborative process. This method not \u001b[0m\n",
       "\u001b[32monly improves the overall quality of the output but also aids in clarifying user intentions and expectations, \u001b[0m\n",
       "\u001b[32mleading to more satisfactory outcomes. In summary, task decomposition is a strategic approach that empowers LLM \u001b[0m\n",
       "\u001b[32magents to manage complexity by converting challenging problems into simpler, actionable components.'\u001b[0m,\n",
       "    \u001b[32m'Task decomposition for Large Language Model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex tasks \u001b[0m\n",
       "\u001b[32minto smaller, more manageable subtasks that can be more easily understood and executed by the model. This approach \u001b[0m\n",
       "\u001b[32mleverages the capabilities of LLMs to analyze and generate language in a structured manner, enabling more effective\u001b[0m\n",
       "\u001b[32mproblem-solving and decision-making.\\n\\nIn practice, task decomposition involves identifying the key components of \u001b[0m\n",
       "\u001b[32ma larger task and articulating them clearly. For example, if the overarching goal is to generate a research paper, \u001b[0m\n",
       "\u001b[32mdecomposition might involve subtasks such as selecting a topic, conducting a literature review, outlining the \u001b[0m\n",
       "\u001b[32mstructure, drafting individual sections, and finally editing the content. By systematically tackling each subtask, \u001b[0m\n",
       "\u001b[32mthe LLM can produce higher quality outputs and maintain coherence throughout the project.\\n\\nFurthermore, task \u001b[0m\n",
       "\u001b[32mdecomposition can enhance collaboration between LLM agents and users, allowing for iterative feedback and \u001b[0m\n",
       "\u001b[32madjustments at each stage of the process. This method also facilitates the integration of external resources, such \u001b[0m\n",
       "\u001b[32mas databases or APIs, to gather information relevant to specific subtasks, thereby enriching the overall output. \u001b[0m\n",
       "\u001b[32mUltimately, effective task decomposition not only improves the efficiency of LLM agents but also harnesses their \u001b[0m\n",
       "\u001b[32mlanguage processing power to deliver more precise and relevant results.'\u001b[0m,\n",
       "    \u001b[32m\"Task decomposition for Large Language Model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex tasks \u001b[0m\n",
       "\u001b[32minto smaller, manageable sub-tasks that the LLM can handle more effectively. This approach is vital for enhancing \u001b[0m\n",
       "\u001b[32mthe performance and efficiency of LLMs when addressing intricate problems or queries. By segmenting a larger task \u001b[0m\n",
       "\u001b[32minto simpler components, the LLM can leverage its strengths in understanding and generating language while focusing\u001b[0m\n",
       "\u001b[32mon one aspect of the task at a time.\\n\\nFor example, if the overall task is to draft a research paper, task \u001b[0m\n",
       "\u001b[32mdecomposition might involve dividing it into sub-tasks such as conducting a literature review, outlining key \u001b[0m\n",
       "\u001b[32msections, drafting individual paragraphs, and revising content for clarity and coherence. Each of these smaller \u001b[0m\n",
       "\u001b[32mtasks can be tackled sequentially or in parallel, allowing the agent to produce more focused and coherent \u001b[0m\n",
       "\u001b[32moutputs.\\n\\nMoreover, task decomposition facilitates better resource management, as it allows LLMs to optimize \u001b[0m\n",
       "\u001b[32mtheir processing capabilities and memory usage by concentrating on one part of the task at a time. This structured \u001b[0m\n",
       "\u001b[32mapproach not only enhances the output quality but also provides a clearer framework for assessing the model's \u001b[0m\n",
       "\u001b[32mperformance on each sub-task. Consequently, task decomposition serves as a powerful strategy for maximizing the \u001b[0m\n",
       "\u001b[32mutility of LLM agents in various applications, from content creation to problem-solving in diverse domains.\"\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@chain\n",
    "def generate_documents(query: str, config: RunnableConfig) -> list[Document]:\n",
    "    generated_documents_count = config['configurable'].get(\"generated_documents_count\", 3)\n",
    "    chain = (\n",
    "        hyde_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    generated_documents = chain.batch([{'question': query}] * generated_documents_count)\n",
    "    return generated_documents\n",
    "\n",
    "rprint(generate_documents.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0af1de76-dc95-4328-aed6-59b989143f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">or problems into smaller, more manageable sub-tasks. This approach is critical for enhancing the efficiency and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectiveness of LLMs in performing intricate tasks that require multi-step reasoning or diverse forms of knowledge</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">application. By subdividing a larger task, LLM agents can focus on solving each component separately, allowing for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">greater clarity, improved organization, and more effective use of the model's capabilities.\\n\\nFor instance, when </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasked with generating a project proposal, an LLM might decompose this into specific sub-tasks such as researching </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">background information, outlining the structure of the proposal, drafting individual sections, and refining the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">final document. Each sub-task can be approached sequentially or iteratively, leveraging the model's ability to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">handle natural language processing, comprehension, and generation at a granular level. This systematic breakdown </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">not only aids in the efficient management of the overall task but also reduces the likelihood of errors and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhances the quality of the final output. Overall, task decomposition empowers LLM agents to tackle complex queries</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and applications with greater precision and efficacy.\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"Task decomposition for large language model (LLM) agents refers to the process of breaking down complex tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into smaller, more manageable sub-tasks. This approach allows the LLM to tackle intricate problems by focusing on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specific components, rather than attempting to solve the entire task in one go. By dividing tasks into discrete </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">steps, LLM agents can leverage their capabilities more effectively, enhancing their understanding and improving the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quality of their responses.\\n\\nFor instance, when assigned a multi-step question—such as planning an event—task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition would involve identifying individual aspects, such as venue selection, guest lists, catering, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scheduling. The LLM could then address each sub-task systematically, ensuring that each element is thoroughly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">considered. This method not only increases the clarity of the agent's output but also allows for iterative </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">refinement, as the agent can evaluate each completed sub-task before moving onto the next.\\n\\nAdditionally, task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition can help LLM agents manage resources more efficiently, facilitating better allocation of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computational power and time. In collaborative scenarios, it can also enhance teamwork among multiple agents by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clearly defining roles and responsibilities. Overall, task decomposition is a vital strategy that enables LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents to handle complexity with greater precision and efficacy, ultimately leading to improved problem-solving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outcomes.\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down a complex task</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">or problem into smaller, more manageable sub-tasks that can be addressed sequentially or in parallel. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">technique is essential for enhancing the efficiency and effectiveness of LLM agents, allowing them to tackle </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">intricate queries by focusing on individual components rather than attempting to solve everything at once.\\n\\nBy </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">segmenting tasks, LLM agents can leverage their language understanding capabilities more effectively, applying </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning and generating appropriate responses for each sub-task. For example, if an agent is tasked with writing a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">research paper, task decomposition might involve first identifying the key topics, outlining the structure, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conducting literature reviews, and then drafting sections. Each of these subtasks can be approached independently, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ensuring that the agent maintains clarity and coherence throughout the overall task execution.\\n\\nAdditionally, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task decomposition allows LLM agents to prioritize and manage their outputs more easily. By clarifying the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relationships between sub-tasks, agents can also better allocate computational resources, ensuring that they </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generate high-quality responses for each part of the task. Overall, task decomposition is a crucial strategy that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enables LLM agents to handle complexity more effectively, improve response accuracy, and streamline their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">workflow.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for Large Language Model (LLM) agents refers to the process of breaking down complex tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into smaller, more manageable sub-tasks that can be systematically addressed. This approach is crucial for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing the efficiency and effectiveness of LLMs in performing multi-step processes or solving intricate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problems. By dividing a larger task into a series of simpler actions, LLM agents can better organize their response</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">strategy, prioritize certain aspects, and ensure that they address each component thoroughly.\\n\\nFor instance, if </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an LLM agent is asked to create a research report, task decomposition might involve breaking it down into several </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">key phases: identifying the research topic, gathering relevant information, outlining the report structure, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">drafting sections, and finally, reviewing and editing the document. Each of these phases can be tackled </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">individually, allowing the LLM to focus its computational resources and linguistic capabilities on each task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">respectively, leading to higher quality outcomes.\\n\\nAdditionally, task decomposition allows for improved </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interaction between LLM agents and users, as it can enable more structured dialogues where users can provide input </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">at various stages of the task. This method not only aids in clarity and organization but also helps in managing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">user expectations and fostering collaboration. Overall, task decomposition is a foundational strategy in optimizing</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the performance of LLM agents in real-world applications.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into smaller, more manageable sub-tasks that can be tackled sequentially or in parallel. This approach is essential</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for enhancing the efficiency and effectiveness of LLM agents, as it allows them to focus on specific components of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a task rather than attempting to solve it as a whole in one go.\\n\\nIn practice, task decomposition involves </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">analyzing the overall objective and identifying distinct steps or phases that lead to the desired outcome. For </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">example, if the ultimate goal is to write a research paper, task decomposition might involve breaking it down into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">several sub-tasks: selecting a topic, conducting literature review, drafting an outline, writing individual </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sections, and finally, revising and editing.\\n\\nBy structuring tasks in this manner, LLM agents can utilize their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">advanced capabilities to generate relevant content, analyze data, and draw connections between ideas more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiently. Moreover, task decomposition can enhance the agent's ability to manage context and persist information</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across sub-tasks, ensuring coherent and relevant outputs throughout the completion of the overall </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task.\\n\\nAdditionally, this method allows for easier tracking of progress and facilitates troubleshooting, as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">issues can be identified and addressed at the sub-task level rather than at the final outcome. Overall, task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition is a crucial strategy for optimizing the performance and utility of LLM agents in a variety of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">applications, spanning from content generation to more complex problem-solving scenarios.\"</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m\"Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex tasks \u001b[0m\n",
       "\u001b[32mor problems into smaller, more manageable sub-tasks. This approach is critical for enhancing the efficiency and \u001b[0m\n",
       "\u001b[32meffectiveness of LLMs in performing intricate tasks that require multi-step reasoning or diverse forms of knowledge\u001b[0m\n",
       "\u001b[32mapplication. By subdividing a larger task, LLM agents can focus on solving each component separately, allowing for \u001b[0m\n",
       "\u001b[32mgreater clarity, improved organization, and more effective use of the model's capabilities.\\n\\nFor instance, when \u001b[0m\n",
       "\u001b[32mtasked with generating a project proposal, an LLM might decompose this into specific sub-tasks such as researching \u001b[0m\n",
       "\u001b[32mbackground information, outlining the structure of the proposal, drafting individual sections, and refining the \u001b[0m\n",
       "\u001b[32mfinal document. Each sub-task can be approached sequentially or iteratively, leveraging the model's ability to \u001b[0m\n",
       "\u001b[32mhandle natural language processing, comprehension, and generation at a granular level. This systematic breakdown \u001b[0m\n",
       "\u001b[32mnot only aids in the efficient management of the overall task but also reduces the likelihood of errors and \u001b[0m\n",
       "\u001b[32menhances the quality of the final output. Overall, task decomposition empowers LLM agents to tackle complex queries\u001b[0m\n",
       "\u001b[32mand applications with greater precision and efficacy.\"\u001b[0m,\n",
       "    \u001b[32m\"Task decomposition for large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex tasks \u001b[0m\n",
       "\u001b[32minto smaller, more manageable sub-tasks. This approach allows the LLM to tackle intricate problems by focusing on \u001b[0m\n",
       "\u001b[32mspecific components, rather than attempting to solve the entire task in one go. By dividing tasks into discrete \u001b[0m\n",
       "\u001b[32msteps, LLM agents can leverage their capabilities more effectively, enhancing their understanding and improving the\u001b[0m\n",
       "\u001b[32mquality of their responses.\\n\\nFor instance, when assigned a multi-step question—such as planning an event—task \u001b[0m\n",
       "\u001b[32mdecomposition would involve identifying individual aspects, such as venue selection, guest lists, catering, and \u001b[0m\n",
       "\u001b[32mscheduling. The LLM could then address each sub-task systematically, ensuring that each element is thoroughly \u001b[0m\n",
       "\u001b[32mconsidered. This method not only increases the clarity of the agent's output but also allows for iterative \u001b[0m\n",
       "\u001b[32mrefinement, as the agent can evaluate each completed sub-task before moving onto the next.\\n\\nAdditionally, task \u001b[0m\n",
       "\u001b[32mdecomposition can help LLM agents manage resources more efficiently, facilitating better allocation of \u001b[0m\n",
       "\u001b[32mcomputational power and time. In collaborative scenarios, it can also enhance teamwork among multiple agents by \u001b[0m\n",
       "\u001b[32mclearly defining roles and responsibilities. Overall, task decomposition is a vital strategy that enables LLM \u001b[0m\n",
       "\u001b[32magents to handle complexity with greater precision and efficacy, ultimately leading to improved problem-solving \u001b[0m\n",
       "\u001b[32moutcomes.\"\u001b[0m,\n",
       "    \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down a complex task\u001b[0m\n",
       "\u001b[32mor problem into smaller, more manageable sub-tasks that can be addressed sequentially or in parallel. This \u001b[0m\n",
       "\u001b[32mtechnique is essential for enhancing the efficiency and effectiveness of LLM agents, allowing them to tackle \u001b[0m\n",
       "\u001b[32mintricate queries by focusing on individual components rather than attempting to solve everything at once.\\n\\nBy \u001b[0m\n",
       "\u001b[32msegmenting tasks, LLM agents can leverage their language understanding capabilities more effectively, applying \u001b[0m\n",
       "\u001b[32mreasoning and generating appropriate responses for each sub-task. For example, if an agent is tasked with writing a\u001b[0m\n",
       "\u001b[32mresearch paper, task decomposition might involve first identifying the key topics, outlining the structure, \u001b[0m\n",
       "\u001b[32mconducting literature reviews, and then drafting sections. Each of these subtasks can be approached independently, \u001b[0m\n",
       "\u001b[32mensuring that the agent maintains clarity and coherence throughout the overall task execution.\\n\\nAdditionally, \u001b[0m\n",
       "\u001b[32mtask decomposition allows LLM agents to prioritize and manage their outputs more easily. By clarifying the \u001b[0m\n",
       "\u001b[32mrelationships between sub-tasks, agents can also better allocate computational resources, ensuring that they \u001b[0m\n",
       "\u001b[32mgenerate high-quality responses for each part of the task. Overall, task decomposition is a crucial strategy that \u001b[0m\n",
       "\u001b[32menables LLM agents to handle complexity more effectively, improve response accuracy, and streamline their \u001b[0m\n",
       "\u001b[32mworkflow.'\u001b[0m,\n",
       "    \u001b[32m'Task decomposition for Large Language Model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex tasks \u001b[0m\n",
       "\u001b[32minto smaller, more manageable sub-tasks that can be systematically addressed. This approach is crucial for \u001b[0m\n",
       "\u001b[32menhancing the efficiency and effectiveness of LLMs in performing multi-step processes or solving intricate \u001b[0m\n",
       "\u001b[32mproblems. By dividing a larger task into a series of simpler actions, LLM agents can better organize their response\u001b[0m\n",
       "\u001b[32mstrategy, prioritize certain aspects, and ensure that they address each component thoroughly.\\n\\nFor instance, if \u001b[0m\n",
       "\u001b[32man LLM agent is asked to create a research report, task decomposition might involve breaking it down into several \u001b[0m\n",
       "\u001b[32mkey phases: identifying the research topic, gathering relevant information, outlining the report structure, \u001b[0m\n",
       "\u001b[32mdrafting sections, and finally, reviewing and editing the document. Each of these phases can be tackled \u001b[0m\n",
       "\u001b[32mindividually, allowing the LLM to focus its computational resources and linguistic capabilities on each task \u001b[0m\n",
       "\u001b[32mrespectively, leading to higher quality outcomes.\\n\\nAdditionally, task decomposition allows for improved \u001b[0m\n",
       "\u001b[32minteraction between LLM agents and users, as it can enable more structured dialogues where users can provide input \u001b[0m\n",
       "\u001b[32mat various stages of the task. This method not only aids in clarity and organization but also helps in managing \u001b[0m\n",
       "\u001b[32muser expectations and fostering collaboration. Overall, task decomposition is a foundational strategy in optimizing\u001b[0m\n",
       "\u001b[32mthe performance of LLM agents in real-world applications.'\u001b[0m,\n",
       "    \u001b[32m\"Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex tasks \u001b[0m\n",
       "\u001b[32minto smaller, more manageable sub-tasks that can be tackled sequentially or in parallel. This approach is essential\u001b[0m\n",
       "\u001b[32mfor enhancing the efficiency and effectiveness of LLM agents, as it allows them to focus on specific components of \u001b[0m\n",
       "\u001b[32ma task rather than attempting to solve it as a whole in one go.\\n\\nIn practice, task decomposition involves \u001b[0m\n",
       "\u001b[32manalyzing the overall objective and identifying distinct steps or phases that lead to the desired outcome. For \u001b[0m\n",
       "\u001b[32mexample, if the ultimate goal is to write a research paper, task decomposition might involve breaking it down into \u001b[0m\n",
       "\u001b[32mseveral sub-tasks: selecting a topic, conducting literature review, drafting an outline, writing individual \u001b[0m\n",
       "\u001b[32msections, and finally, revising and editing.\\n\\nBy structuring tasks in this manner, LLM agents can utilize their \u001b[0m\n",
       "\u001b[32madvanced capabilities to generate relevant content, analyze data, and draw connections between ideas more \u001b[0m\n",
       "\u001b[32mefficiently. Moreover, task decomposition can enhance the agent's ability to manage context and persist information\u001b[0m\n",
       "\u001b[32macross sub-tasks, ensuring coherent and relevant outputs throughout the completion of the overall \u001b[0m\n",
       "\u001b[32mtask.\\n\\nAdditionally, this method allows for easier tracking of progress and facilitates troubleshooting, as \u001b[0m\n",
       "\u001b[32missues can be identified and addressed at the sub-task level rather than at the final outcome. Overall, task \u001b[0m\n",
       "\u001b[32mdecomposition is a crucial strategy for optimizing the performance and utility of LLM agents in a variety of \u001b[0m\n",
       "\u001b[32mapplications, spanning from content generation to more complex problem-solving scenarios.\"\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(generate_documents.with_config(generated_documents_count=5).invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1989f62-78a5-4eac-9e75-033fe5449d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hyde_embeddings(hyde_components):\n",
    "    question_embeddings = np.array(embeddings.embed_query(hyde_components['question']))\n",
    "    generated_documents_embeddings = np.array(embeddings.embed_documents(hyde_components['generated_documents']))\n",
    "    hyde_embeddings = np.vstack([question_embeddings, generated_documents_embeddings]).mean(axis=0)\n",
    "    return hyde_embeddings\n",
    "\n",
    "def get_relevant_documents(hyde_embeddings):\n",
    "    return vectorstore.similarity_search_by_vector(hyde_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e40c5989-9e60-47a3-ad22-a79c7f1f686b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What is task decomposition for LLM agents?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "What is task decomposition for LLM agents?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'85a96e8b-b7fc-4d1d-89f2-aaa03fe355a4'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'11e40a49-f0a3-454b-8fbe-ccf99bad696d'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'f0a0f781-621f-4922-ab59-92600a129f5c'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural language as</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an interface between LLMs and external components such as memory and tools. However, the reliability of model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'d18c90b6-9746-447c-a09d-f6407b460b0b'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'(4) Response generation: LLM receives the execution results and provides summarized results </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">external model services.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'85a96e8b-b7fc-4d1d-89f2-aaa03fe355a4'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA \u001b[0m\n",
       "\u001b[32mcomplicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask \u001b[0m\n",
       "\u001b[32mDecomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for enhancing \u001b[0m\n",
       "\u001b[32mmodel performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time \u001b[0m\n",
       "\u001b[32mcomputation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple \u001b[0m\n",
       "\u001b[32mmanageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'11e40a49-f0a3-454b-8fbe-ccf99bad696d'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  \u001b[0m\n",
       "\u001b[32m|  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a cool \u001b[0m\n",
       "\u001b[32mconcept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. \u001b[0m\n",
       "\u001b[32mThe potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be \u001b[0m\n",
       "\u001b[32mframed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM\u001b[0m\n",
       "\u001b[32mfunctions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: \u001b[0m\n",
       "\u001b[32mThe agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex \u001b[0m\n",
       "\u001b[32mtasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn \u001b[0m\n",
       "\u001b[32mfrom mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'f0a0f781-621f-4922-ab59-92600a129f5c'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural language as\u001b[0m\n",
       "\u001b[32man interface between LLMs and external components such as memory and tools. However, the reliability of model \u001b[0m\n",
       "\u001b[32moutputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. \u001b[0m\n",
       "\u001b[32mrefuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'd18c90b6-9746-447c-a09d-f6407b460b0b'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m(\u001b[0m\u001b[32m4\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Response generation: LLM receives the execution results and provides summarized results \u001b[0m\n",
       "\u001b[32mto users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Efficiency improvement \u001b[0m\n",
       "\u001b[32mis needed as both LLM inference rounds and interactions with other models slow down the process; \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m It relies on a\u001b[0m\n",
       "\u001b[32mlong context window to communicate over complicated task content; \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Stability improvement of LLM outputs and \u001b[0m\n",
       "\u001b[32mexternal model services.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retrieval_chain =  (\n",
    "    RunnableParallel({\n",
    "        'question': RunnablePassthrough(),\n",
    "        'generated_documents': generate_documents\n",
    "    })\n",
    "    | calculate_hyde_embeddings\n",
    "    | get_relevant_documents\n",
    ")\n",
    "\n",
    "rprint(query)\n",
    "docs = retrieval_chain.invoke(query)\n",
    "rprint(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "059554d6-e488-47ed-8304-e8be096da18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What is task decomposition for LLM agents?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "What is task decomposition for LLM agents?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Chunk 1:</span>\n",
       "Fig. 1. Overview of a <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span>-powered autonomous <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span> system.\n",
       "Component One: Planning#\n",
       "A complicated <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">task</span> usually involves many steps. An <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span> needs to know <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">what</span> they are and plan ahead.\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Task</span> <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Decomposition</span>#\n",
       "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">for</span> enhancing model performance \n",
       "on complex tasks. The model <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">is</span> instructed to “think step by step” to utilize more test-time computation to \n",
       "decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and \n",
       "shed lights into an interpretation of the model’s thinking process.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mChunk 1:\u001b[0m\n",
       "Fig. 1. Overview of a \u001b[4;31mLLM\u001b[0m-powered autonomous \u001b[4;31magent\u001b[0m system.\n",
       "Component One: Planning#\n",
       "A complicated \u001b[4;31mtask\u001b[0m usually involves many steps. An \u001b[4;31magent\u001b[0m needs to know \u001b[4;31mwhat\u001b[0m they are and plan ahead.\n",
       "\u001b[4;31mTask\u001b[0m \u001b[4;31mDecomposition\u001b[0m#\n",
       "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique \u001b[4;31mfor\u001b[0m enhancing model performance \n",
       "on complex tasks. The model \u001b[4;31mis\u001b[0m instructed to “think step by step” to utilize more test-time computation to \n",
       "decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and \n",
       "shed lights into an interpretation of the model’s thinking process.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Chunk 2:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> Powered Autonomous <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Agents</span>\n",
       "    \n",
       "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
       "\n",
       "\n",
       "Building <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agents</span> with <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> (large language model) as its core controller <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">is</span> a cool concept. Several proof-of-concepts\n",
       "demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> extends \n",
       "beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem\n",
       "solver.\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Agent</span> System Overview#\n",
       "In a <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span>-powered autonomous <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span> system, <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> functions as the <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span>’s brain, complemented by several key \n",
       "components:\n",
       "\n",
       "Planning\n",
       "\n",
       "Subgoal and <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">decomposition</span>: The <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span> breaks down large tasks into smaller, manageable subgoals, enabling efficient \n",
       "handling of complex tasks.\n",
       "Reflection and refinement: The <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span> can do self-criticism and self-reflection over past actions, learn from \n",
       "mistakes and refine them <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">for</span> future steps, thereby improving the quality of final results.\n",
       "\n",
       "\n",
       "Memory\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mChunk 2:\u001b[0m\n",
       "\u001b[4;31mLLM\u001b[0m Powered Autonomous \u001b[4;31mAgents\u001b[0m\n",
       "    \n",
       "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
       "\n",
       "\n",
       "Building \u001b[4;31magents\u001b[0m with \u001b[4;31mLLM\u001b[0m (large language model) as its core controller \u001b[4;31mis\u001b[0m a cool concept. Several proof-of-concepts\n",
       "demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of \u001b[4;31mLLM\u001b[0m extends \n",
       "beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem\n",
       "solver.\n",
       "\u001b[4;31mAgent\u001b[0m System Overview#\n",
       "In a \u001b[4;31mLLM\u001b[0m-powered autonomous \u001b[4;31magent\u001b[0m system, \u001b[4;31mLLM\u001b[0m functions as the \u001b[4;31magent\u001b[0m’s brain, complemented by several key \n",
       "components:\n",
       "\n",
       "Planning\n",
       "\n",
       "Subgoal and \u001b[4;31mdecomposition\u001b[0m: The \u001b[4;31magent\u001b[0m breaks down large tasks into smaller, manageable subgoals, enabling efficient \n",
       "handling of complex tasks.\n",
       "Reflection and refinement: The \u001b[4;31magent\u001b[0m can do self-criticism and self-reflection over past actions, learn from \n",
       "mistakes and refine them \u001b[4;31mfor\u001b[0m future steps, thereby improving the quality of final results.\n",
       "\n",
       "\n",
       "Memory\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Chunk 3:</span>\n",
       "Reliability of natural language interface: Current <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span> system relies on natural language as an interface between \n",
       "LLMs and external components such as memory and tools. However, the reliability of model outputs <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">is</span> questionable, \n",
       "as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an \n",
       "instruction). Consequently, much of the <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span> demo code focuses on parsing model output.\n",
       "\n",
       "\n",
       "Citation#\n",
       "Cited as:\n",
       "\n",
       "Weng, Lilian. (Jun 2023). “<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span>-powered Autonomous <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">Agents</span>”. Lil’Log. \n",
       "https://lilianweng.github.io/posts/2023-06-23-<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">agent</span>/.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mChunk 3:\u001b[0m\n",
       "Reliability of natural language interface: Current \u001b[4;31magent\u001b[0m system relies on natural language as an interface between \n",
       "LLMs and external components such as memory and tools. However, the reliability of model outputs \u001b[4;31mis\u001b[0m questionable, \n",
       "as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an \n",
       "instruction). Consequently, much of the \u001b[4;31magent\u001b[0m demo code focuses on parsing model output.\n",
       "\n",
       "\n",
       "Citation#\n",
       "Cited as:\n",
       "\n",
       "Weng, Lilian. (Jun 2023). “\u001b[4;31mLLM\u001b[0m-powered Autonomous \u001b[4;31mAgents\u001b[0m”. Lil’Log. \n",
       "https://lilianweng.github.io/posts/2023-06-23-\u001b[4;31magent\u001b[0m/.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Chunk 4:</span>\n",
       "(4) Response generation: <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> receives the execution results and provides summarized results to users.\n",
       "To put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">is</span> needed as\n",
       "both <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> inference rounds and interactions with other models slow down the process; (2) It relies on a long context\n",
       "window to communicate over complicated <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">task</span> content; (3) Stability improvement of <span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">LLM</span> outputs and external model \n",
       "services.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mChunk 4:\u001b[0m\n",
       "(4) Response generation: \u001b[4;31mLLM\u001b[0m receives the execution results and provides summarized results to users.\n",
       "To put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement \u001b[4;31mis\u001b[0m needed as\n",
       "both \u001b[4;31mLLM\u001b[0m inference rounds and interactions with other models slow down the process; (2) It relies on a long context\n",
       "window to communicate over complicated \u001b[4;31mtask\u001b[0m content; (3) Stability improvement of \u001b[4;31mLLM\u001b[0m outputs and external model \n",
       "services.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(query)\n",
    "\n",
    "chunk_pattern = re.compile(r'^Chunk \\d+.*:$', flags=re.MULTILINE)\n",
    "terms_pattern = re.compile(rf'\\b({\"|\".join(query.split())})\\b', flags=re.IGNORECASE)\n",
    "\n",
    "for chunk_id, doc in enumerate(docs, start=1):\n",
    "    text = Text(f\"Chunk {chunk_id}:\\n{doc.page_content}\")\n",
    "    text.highlight_regex(chunk_pattern, \"bold green\")\n",
    "    text.highlight_regex(terms_pattern, \"underline red\")\n",
    "    rprint(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43903dd-1500-4eee-9673-c0a2a6f74ec0",
   "metadata": {},
   "source": [
    "#### Define RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29068024-9c00-4ce9-a0a0-ac138c8de9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What is task decomposition for LLM agents?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "What is task decomposition for LLM agents?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task decomposition for LLM agents involves breaking down large, complex tasks into smaller, manageable subgoals.   \n",
       "This process enables the agent to handle tasks more efficiently by transforming big tasks into multiple simpler    \n",
       "steps. A common technique used for task decomposition is Chain of Thought (CoT), where the model is prompted to    \n",
       "\"think step by step,\" helping to clarify and interpret the model's thinking process. Additionally, decomposition   \n",
       "can be achieved through simple prompting, task-specific instructions, or human inputs, allowing the agent to       \n",
       "systematically approach and solve challenges.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Task decomposition for LLM agents involves breaking down large, complex tasks into smaller, manageable subgoals.   \n",
       "This process enables the agent to handle tasks more efficiently by transforming big tasks into multiple simpler    \n",
       "steps. A common technique used for task decomposition is Chain of Thought (CoT), where the model is prompted to    \n",
       "\"think step by step,\" helping to clarify and interpret the model's thinking process. Additionally, decomposition   \n",
       "can be achieved through simple prompting, task-specific instructions, or human inputs, allowing the agent to       \n",
       "systematically approach and solve challenges.                                                                      \n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retrieval_chain | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rprint(query)\n",
    "response = rag_chain.invoke(query)\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b49bd13-6654-488c-9e79-59ff23b0c0ca",
   "metadata": {},
   "source": [
    "### LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8df08370-72be-4dfd-bd41-135eeb897c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efd4dd07-610a-459b-bb43-c4e9344d572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    generated_documents: list[str]\n",
    "    hyde_embeddings: np.ndarray\n",
    "    context: list[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abce7134-6b43-4e35-afd0-3203d8a7bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_documents(state: State, config: RunnableConfig) -> list[Document]:\n",
    "    generated_documents_count = config['configurable'].get(\"generated_documents_count\", 3)\n",
    "    \n",
    "    chain = (\n",
    "        hyde_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    generated_documents = chain.batch([{'question': state[\"question\"]}] * generated_documents_count)\n",
    "    \n",
    "    return {\"generated_documents\": generated_documents}\n",
    "\n",
    "\n",
    "def calculate_hyde_embeddings(state: State):\n",
    "    question_embeddings = np.array(embeddings.embed_query(state['question']))\n",
    "    generated_documents_embeddings = np.array(embeddings.embed_documents(state['generated_documents']))\n",
    "    hyde_embeddings = np.vstack([question_embeddings, generated_documents_embeddings]).mean(axis=0)\n",
    "    return {\"hyde_embeddings\": hyde_embeddings}\n",
    "\n",
    "def get_relevant_documents(state: State):\n",
    "    documents = vectorstore.similarity_search_by_vector(state[\"hyde_embeddings\"])\n",
    "    return {\"context\": documents}\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    docs_content = format_docs(state[\"context\"])\n",
    "    chain = rag_prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"question\": state[\"question\"], \n",
    "            \"context\": docs_content\n",
    "        }\n",
    "    )\n",
    "    return {\"answer\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1115f445-fbe8-43ab-91a7-c17ff26aec99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7f5bc6bfa550>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"generate_documents\", generate_documents)\n",
    "graph_builder.add_node(\"calculate_hyde_embeddings\", calculate_hyde_embeddings)\n",
    "graph_builder.add_node(\"get_relevant_documents\", get_relevant_documents)\n",
    "graph_builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "graph_builder.add_edge(START, \"generate_documents\")\n",
    "graph_builder.add_edge(\"generate_documents\", \"calculate_hyde_embeddings\")\n",
    "graph_builder.add_edge(\"calculate_hyde_embeddings\", \"get_relevant_documents\")\n",
    "graph_builder.add_edge(\"get_relevant_documents\", \"generate_answer\")\n",
    "graph_builder.add_edge(\"generate_answer\", END)\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9aa8516-8eae-4d29-a6aa-640bc661c4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is task decomposition for LLM agents?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is task decomposition for LLM agents?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generated_documents'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for large language model (LLM) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into simpler, more manageable sub-tasks that can be tackled individually. This technique enhances the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiency and effectiveness of LLMs by allowing them to focus on specific components of a problem rather than </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">attempting to solve it all at once. For instance, if an LLM is tasked with writing a research paper, task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition would involve identifying and delineating various stages such as topic selection, literature review, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data analysis, and drafting. By addressing each stage separately, the LLM can generate more coherent and focused </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outputs, ultimately leading to a higher quality end result. Task decomposition not only aids in organizational </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clarity but also allows for better resource allocation and error management, ensuring that each sub-task receives </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the appropriate attention and expertise needed to achieve optimal performance.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, more manageable subtasks to enhance problem-solving efficiency and effectiveness. This approach</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">allows LLMs to tackle intricate challenges by addressing each subtask individually, rather than attempting to solve</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the entire problem in one go. \\n\\nBy decomposing tasks, LLMs can leverage their language understanding capabilities</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">more effectively, ensuring that they handle specific aspects of a problem with greater accuracy. For instance, in a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multi-step reasoning scenario, task decomposition allows the agent to first identify the key components of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problem, organize these components logically, and then address them sequentially. This strategy not only improves </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the clarity of the solution but also enables the model to provide coherent and structured responses. \\n\\nMoreover, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task decomposition can facilitate collaboration among multiple LLM agents, where each agent takes on different </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">subtasks, leading to faster and more efficient completion of the overall task. This approach mirrors human </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problem-solving strategies, making LLM agents more versatile and capable in a variety of applications, from natural</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language processing to complex decision-making tasks.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, more manageable components that can be addressed individually. This approach enhances the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiency and effectiveness of LLMs in executing multifaceted requests by structuring the workflow into distinct </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">stages or subtasks. \\n\\nFor instance, if an LLM is tasked with summarizing a lengthy article, task decomposition </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">would involve identifying key elements such as main ideas, supporting arguments, and conclusions. By processing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">each of these components separately, the model can produce a coherent and concise summary that captures the essence</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of the article without losing important details. \\n\\nAdditionally, task decomposition allows LLM agents to leverage</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">their capabilities in a more targeted manner, enabling more accurate responses and reducing the cognitive load on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the model. This method is particularly beneficial when dealing with intricate tasks that require critical thinking,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">creativity, or problem-solving, as it allows the model to focus on one aspect at a time, improving overall accuracy</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and quality of the output. Ultimately, effective task decomposition is a vital strategy for enhancing the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance and utility of LLM agents in diverse applications.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hyde_embeddings'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00799526</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01970467</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.04962153</span>, <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01382141</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00146945</span>,\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01720253</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM agents refers to the process of breaking down large and complex tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into smaller, manageable subgoals, which allows the agent to handle the tasks more efficiently. This method </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhances the overall performance of the model by utilizing a technique known as Chain of Thought (CoT), where the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent is prompted to \"think step by step.\" This approach not only transforms big tasks into simpler components but </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">also provides insights into the model\\'s thought process. Additionally, task decomposition can be achieved through </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">various methods, including simple prompting, task-specific instructions, or human inputs. Overall, task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition enables a structured approach to problem-solving within LLM-powered autonomous agents.'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'What is task decomposition for LLM agents?'\u001b[0m,\n",
       "    \u001b[32m'generated_documents'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'Task decomposition for large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into simpler, more manageable sub-tasks that can be tackled individually. This technique enhances the \u001b[0m\n",
       "\u001b[32mefficiency and effectiveness of LLMs by allowing them to focus on specific components of a problem rather than \u001b[0m\n",
       "\u001b[32mattempting to solve it all at once. For instance, if an LLM is tasked with writing a research paper, task \u001b[0m\n",
       "\u001b[32mdecomposition would involve identifying and delineating various stages such as topic selection, literature review, \u001b[0m\n",
       "\u001b[32mdata analysis, and drafting. By addressing each stage separately, the LLM can generate more coherent and focused \u001b[0m\n",
       "\u001b[32moutputs, ultimately leading to a higher quality end result. Task decomposition not only aids in organizational \u001b[0m\n",
       "\u001b[32mclarity but also allows for better resource allocation and error management, ensuring that each sub-task receives \u001b[0m\n",
       "\u001b[32mthe appropriate attention and expertise needed to achieve optimal performance.'\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, more manageable subtasks to enhance problem-solving efficiency and effectiveness. This approach\u001b[0m\n",
       "\u001b[32mallows LLMs to tackle intricate challenges by addressing each subtask individually, rather than attempting to solve\u001b[0m\n",
       "\u001b[32mthe entire problem in one go. \\n\\nBy decomposing tasks, LLMs can leverage their language understanding capabilities\u001b[0m\n",
       "\u001b[32mmore effectively, ensuring that they handle specific aspects of a problem with greater accuracy. For instance, in a\u001b[0m\n",
       "\u001b[32mmulti-step reasoning scenario, task decomposition allows the agent to first identify the key components of the \u001b[0m\n",
       "\u001b[32mproblem, organize these components logically, and then address them sequentially. This strategy not only improves \u001b[0m\n",
       "\u001b[32mthe clarity of the solution but also enables the model to provide coherent and structured responses. \\n\\nMoreover, \u001b[0m\n",
       "\u001b[32mtask decomposition can facilitate collaboration among multiple LLM agents, where each agent takes on different \u001b[0m\n",
       "\u001b[32msubtasks, leading to faster and more efficient completion of the overall task. This approach mirrors human \u001b[0m\n",
       "\u001b[32mproblem-solving strategies, making LLM agents more versatile and capable in a variety of applications, from natural\u001b[0m\n",
       "\u001b[32mlanguage processing to complex decision-making tasks.'\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, more manageable components that can be addressed individually. This approach enhances the \u001b[0m\n",
       "\u001b[32mefficiency and effectiveness of LLMs in executing multifaceted requests by structuring the workflow into distinct \u001b[0m\n",
       "\u001b[32mstages or subtasks. \\n\\nFor instance, if an LLM is tasked with summarizing a lengthy article, task decomposition \u001b[0m\n",
       "\u001b[32mwould involve identifying key elements such as main ideas, supporting arguments, and conclusions. By processing \u001b[0m\n",
       "\u001b[32meach of these components separately, the model can produce a coherent and concise summary that captures the essence\u001b[0m\n",
       "\u001b[32mof the article without losing important details. \\n\\nAdditionally, task decomposition allows LLM agents to leverage\u001b[0m\n",
       "\u001b[32mtheir capabilities in a more targeted manner, enabling more accurate responses and reducing the cognitive load on \u001b[0m\n",
       "\u001b[32mthe model. This method is particularly beneficial when dealing with intricate tasks that require critical thinking,\u001b[0m\n",
       "\u001b[32mcreativity, or problem-solving, as it allows the model to focus on one aspect at a time, improving overall accuracy\u001b[0m\n",
       "\u001b[32mand quality of the output. Ultimately, effective task decomposition is a vital strategy for enhancing the \u001b[0m\n",
       "\u001b[32mperformance and utility of LLM agents in diverse applications.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'hyde_embeddings'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.00799526\u001b[0m, \u001b[1;36m0.01970467\u001b[0m, \u001b[1;36m0.04962153\u001b[0m, \u001b[33m...\u001b[0m, \u001b[1;36m0.01382141\u001b[0m, \u001b[1;36m0.00146945\u001b[0m,\n",
       "       \u001b[1;36m0.01720253\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'Task decomposition for LLM agents refers to the process of breaking down large and complex tasks \u001b[0m\n",
       "\u001b[32minto smaller, manageable subgoals, which allows the agent to handle the tasks more efficiently. This method \u001b[0m\n",
       "\u001b[32menhances the overall performance of the model by utilizing a technique known as Chain of Thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, where the \u001b[0m\n",
       "\u001b[32magent is prompted to \"think step by step.\" This approach not only transforms big tasks into simpler components but \u001b[0m\n",
       "\u001b[32malso provides insights into the model\\'s thought process. Additionally, task decomposition can be achieved through \u001b[0m\n",
       "\u001b[32mvarious methods, including simple prompting, task-specific instructions, or human inputs. Overall, task \u001b[0m\n",
       "\u001b[32mdecomposition enables a structured approach to problem-solving within LLM-powered autonomous agents.'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task decomposition for LLM agents refers to the process of breaking down large and complex tasks into smaller,     \n",
       "manageable subgoals, which allows the agent to handle the tasks more efficiently. This method enhances the overall \n",
       "performance of the model by utilizing a technique known as Chain of Thought (CoT), where the agent is prompted to  \n",
       "\"think step by step.\" This approach not only transforms big tasks into simpler components but also provides        \n",
       "insights into the model's thought process. Additionally, task decomposition can be achieved through various        \n",
       "methods, including simple prompting, task-specific instructions, or human inputs. Overall, task decomposition      \n",
       "enables a structured approach to problem-solving within LLM-powered autonomous agents.                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Task decomposition for LLM agents refers to the process of breaking down large and complex tasks into smaller,     \n",
       "manageable subgoals, which allows the agent to handle the tasks more efficiently. This method enhances the overall \n",
       "performance of the model by utilizing a technique known as Chain of Thought (CoT), where the agent is prompted to  \n",
       "\"think step by step.\" This approach not only transforms big tasks into simpler components but also provides        \n",
       "insights into the model's thought process. Additionally, task decomposition can be achieved through various        \n",
       "methods, including simple prompting, task-specific instructions, or human inputs. Overall, task decomposition      \n",
       "enables a structured approach to problem-solving within LLM-powered autonomous agents.                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(query)\n",
    "\n",
    "response = graph.invoke({\"question\": query})\n",
    "\n",
    "display(Pretty(response, max_depth=2))\n",
    "display(Markdown(response[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dfd34b0-bb3d-43a1-9764-5708bd93ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is task decomposition for LLM agents?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is task decomposition for LLM agents?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generated_documents'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"Task decomposition for large language model (LLM) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, manageable sub-tasks that can be addressed more effectively by the model. This technique </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhances the model's ability to tackle multifaceted problems by simplifying them into discrete components that are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">easier to understand and solve. \\n\\nIn practice, task decomposition involves identifying the various elements that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contribute to the overall goal and analyzing their relationships. For example, if the main task is to write a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">research paper, task decomposition might include sub-tasks such as conducting literature review, formulating a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thesis statement, creating an outline, drafting sections, and editing the final document. By tackling each sub-task</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">individually, the LLM can provide more targeted responses and improve the quality of the output.\\n\\nThis approach </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">also allows for leveraging the strengths of the LLM more effectively, as it can draw upon its vast knowledge base </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to address specific inquiries related to each smaller task. Furthermore, task decomposition makes it easier for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">human collaborators to guide the LLM, provide feedback, and ensure that the overall task stays aligned with the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">intended objectives. Ultimately, effective task decomposition can lead to more coherent, comprehensive, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">high-quality responses from LLM agents.\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"Task decomposition for large language model (LLM) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, more manageable subtasks that can be more easily addressed by the model. This strategy helps </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">maximize the efficiency and effectiveness of the LLM in handling intricate problems or queries that may be beyond </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">its immediate processing capabilities. \\n\\nBy segmenting a task into its constituent parts, LLM agents can focus on</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">each segment individually, thereby ensuring that they generate more accurate and relevant responses. For example, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">if an LLM is tasked with creating a research report, task decomposition would involve identifying initial steps </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">such as conducting background research, outlining the report’s structure, drafting individual sections, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ultimately reviewing and editing the final output. \\n\\nThis structured approach not only allows for parallel </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">processing of subtasks—where different aspects of the task can be addressed simultaneously—but also facilitates </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">better organization and clarity in the model's outputs. Furthermore, task decomposition enables iterative </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">refinement, where the results of one subtask can inform and improve subsequent tasks, leading to a cohesive final </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">product. Overall, task decomposition enhances the capability of LLM agents to tackle large and complex inquiries by</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transforming them into simpler, actionable components.\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"Task decomposition for Large Language Model (LLM) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, more manageable subtasks that can be handled individually. This technique leverages the LLM's </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capabilities to understand and generate human-like text, enabling it to tackle multifaceted problems in a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">systematic way. By dissecting a larger objective into discrete elements, LLM agents can focus on each component, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">apply relevant knowledge or reasoning, and generate clearer, more effective responses.\\n\\nFor instance, if an LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent is assigned the task of drafting a research paper, task decomposition would involve identifying the key steps</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">necessary for completion, such as conducting a literature review, outlining the structure, writing individual </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sections, and formatting the final document. By approaching the task in this segmented manner, the agent can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">improve its efficiency and enhance the quality of the output, as it can utilize its deep understanding of each </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">subtask independently before synthesizing them into a cohesive final product. This method not only clarifies the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">overall objectives but also allows for incremental checks and adjustments, ensuring that the agent remains on track</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">toward achieving the overall goal.\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, manageable subtasks that can be more easily tackled by the model. This approach enhances the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiency and effectiveness of the language model in generating solutions or responses, especially when confronted</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with multifaceted queries or objectives. By decomposing a task, the LLM can systematically address each component, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enabling it to utilize its capabilities more effectively.\\n\\nFor instance, if an LLM is tasked with writing a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">research paper, task decomposition might involve the following steps: identifying a research question, conducting a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">literature review, outlining the paper structure, drafting sections, and finally proofreading the content. Each of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">these subtasks can be addressed independently before synthesizing the results into a cohesive output.\\n\\nThis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">methodology allows for better organization of thought processes within the model and facilitates clearer, more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">coherent outputs. Additionally, it can help in managing the context more effectively, ensuring that the LLM stays </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">focused on the relevant aspects of the task at hand. Overall, task decomposition is a critical strategy for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing the performance of LLM agents, enabling them to handle more sophisticated tasks with greater precision </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and insight.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks or problems into smaller, more manageable sub-tasks that can be more easily addressed by the model. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">approach leverages the LLM's ability to generate human-like text and understand contextual information, allowing it</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to tackle intricate tasks step-by-step.\\n\\nBy segmenting a task into its constituent parts, LLM agents can focus on</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">each sub-task individually, facilitating improved accuracy and efficiency in generating responses. For example, if </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an agent is tasked with writing a research paper, it might first decompose this task into specific steps such as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conducting a literature review, outlining key points, drafting sections, and finally editing the content. Each of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">these stages can then be handled in sequence, with the model drawing on its extensive training to produce coherent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and relevant outputs at each step.\\n\\nTask decomposition not only aids in organizing the workflow for LLMs but also</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">allows for better error detection and correction, as the agent can reevaluate each sub-task independently before </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">moving on to the next. This strategy ultimately enhances the overall performance and versatility of LLM agents, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enabling them to tackle a wide range of complex tasks with greater effectiveness.\"</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hyde_embeddings'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01269984</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02164174</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05507778</span>, <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01497422</span>,\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.00026131</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01605932</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Task decomposition for LLM (large language model) agents involves breaking down large and complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks into smaller, manageable subgoals. This approach enhances the agent\\'s ability to handle complicated tasks by</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">allowing it to focus on simpler steps, facilitating a clearer planning and execution process. The technique, often </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">referred to as Chain of Thought (CoT), encourages the model to \"think step by step,\" promoting a more structured </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and interpretable thinking process. By decomposing tasks into smaller components, LLM agents can improve their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problem-solving efficiency and effectiveness.'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'What is task decomposition for LLM agents?'\u001b[0m,\n",
       "    \u001b[32m'generated_documents'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m\"Task decomposition for large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, manageable sub-tasks that can be addressed more effectively by the model. This technique \u001b[0m\n",
       "\u001b[32menhances the model's ability to tackle multifaceted problems by simplifying them into discrete components that are \u001b[0m\n",
       "\u001b[32measier to understand and solve. \\n\\nIn practice, task decomposition involves identifying the various elements that \u001b[0m\n",
       "\u001b[32mcontribute to the overall goal and analyzing their relationships. For example, if the main task is to write a \u001b[0m\n",
       "\u001b[32mresearch paper, task decomposition might include sub-tasks such as conducting literature review, formulating a \u001b[0m\n",
       "\u001b[32mthesis statement, creating an outline, drafting sections, and editing the final document. By tackling each sub-task\u001b[0m\n",
       "\u001b[32mindividually, the LLM can provide more targeted responses and improve the quality of the output.\\n\\nThis approach \u001b[0m\n",
       "\u001b[32malso allows for leveraging the strengths of the LLM more effectively, as it can draw upon its vast knowledge base \u001b[0m\n",
       "\u001b[32mto address specific inquiries related to each smaller task. Furthermore, task decomposition makes it easier for \u001b[0m\n",
       "\u001b[32mhuman collaborators to guide the LLM, provide feedback, and ensure that the overall task stays aligned with the \u001b[0m\n",
       "\u001b[32mintended objectives. Ultimately, effective task decomposition can lead to more coherent, comprehensive, and \u001b[0m\n",
       "\u001b[32mhigh-quality responses from LLM agents.\"\u001b[0m,\n",
       "        \u001b[32m\"Task decomposition for large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, more manageable subtasks that can be more easily addressed by the model. This strategy helps \u001b[0m\n",
       "\u001b[32mmaximize the efficiency and effectiveness of the LLM in handling intricate problems or queries that may be beyond \u001b[0m\n",
       "\u001b[32mits immediate processing capabilities. \\n\\nBy segmenting a task into its constituent parts, LLM agents can focus on\u001b[0m\n",
       "\u001b[32meach segment individually, thereby ensuring that they generate more accurate and relevant responses. For example, \u001b[0m\n",
       "\u001b[32mif an LLM is tasked with creating a research report, task decomposition would involve identifying initial steps \u001b[0m\n",
       "\u001b[32msuch as conducting background research, outlining the report’s structure, drafting individual sections, and \u001b[0m\n",
       "\u001b[32multimately reviewing and editing the final output. \\n\\nThis structured approach not only allows for parallel \u001b[0m\n",
       "\u001b[32mprocessing of subtasks—where different aspects of the task can be addressed simultaneously—but also facilitates \u001b[0m\n",
       "\u001b[32mbetter organization and clarity in the model's outputs. Furthermore, task decomposition enables iterative \u001b[0m\n",
       "\u001b[32mrefinement, where the results of one subtask can inform and improve subsequent tasks, leading to a cohesive final \u001b[0m\n",
       "\u001b[32mproduct. Overall, task decomposition enhances the capability of LLM agents to tackle large and complex inquiries by\u001b[0m\n",
       "\u001b[32mtransforming them into simpler, actionable components.\"\u001b[0m,\n",
       "        \u001b[32m\"Task decomposition for Large Language Model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, more manageable subtasks that can be handled individually. This technique leverages the LLM's \u001b[0m\n",
       "\u001b[32mcapabilities to understand and generate human-like text, enabling it to tackle multifaceted problems in a \u001b[0m\n",
       "\u001b[32msystematic way. By dissecting a larger objective into discrete elements, LLM agents can focus on each component, \u001b[0m\n",
       "\u001b[32mapply relevant knowledge or reasoning, and generate clearer, more effective responses.\\n\\nFor instance, if an LLM \u001b[0m\n",
       "\u001b[32magent is assigned the task of drafting a research paper, task decomposition would involve identifying the key steps\u001b[0m\n",
       "\u001b[32mnecessary for completion, such as conducting a literature review, outlining the structure, writing individual \u001b[0m\n",
       "\u001b[32msections, and formatting the final document. By approaching the task in this segmented manner, the agent can \u001b[0m\n",
       "\u001b[32mimprove its efficiency and enhance the quality of the output, as it can utilize its deep understanding of each \u001b[0m\n",
       "\u001b[32msubtask independently before synthesizing them into a cohesive final product. This method not only clarifies the \u001b[0m\n",
       "\u001b[32moverall objectives but also allows for incremental checks and adjustments, ensuring that the agent remains on track\u001b[0m\n",
       "\u001b[32mtoward achieving the overall goal.\"\u001b[0m,\n",
       "        \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, manageable subtasks that can be more easily tackled by the model. This approach enhances the \u001b[0m\n",
       "\u001b[32mefficiency and effectiveness of the language model in generating solutions or responses, especially when confronted\u001b[0m\n",
       "\u001b[32mwith multifaceted queries or objectives. By decomposing a task, the LLM can systematically address each component, \u001b[0m\n",
       "\u001b[32menabling it to utilize its capabilities more effectively.\\n\\nFor instance, if an LLM is tasked with writing a \u001b[0m\n",
       "\u001b[32mresearch paper, task decomposition might involve the following steps: identifying a research question, conducting a\u001b[0m\n",
       "\u001b[32mliterature review, outlining the paper structure, drafting sections, and finally proofreading the content. Each of \u001b[0m\n",
       "\u001b[32mthese subtasks can be addressed independently before synthesizing the results into a cohesive output.\\n\\nThis \u001b[0m\n",
       "\u001b[32mmethodology allows for better organization of thought processes within the model and facilitates clearer, more \u001b[0m\n",
       "\u001b[32mcoherent outputs. Additionally, it can help in managing the context more effectively, ensuring that the LLM stays \u001b[0m\n",
       "\u001b[32mfocused on the relevant aspects of the task at hand. Overall, task decomposition is a critical strategy for \u001b[0m\n",
       "\u001b[32menhancing the performance of LLM agents, enabling them to handle more sophisticated tasks with greater precision \u001b[0m\n",
       "\u001b[32mand insight.'\u001b[0m,\n",
       "        \u001b[32m\"Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents refers to the process of breaking down complex \u001b[0m\n",
       "\u001b[32mtasks or problems into smaller, more manageable sub-tasks that can be more easily addressed by the model. This \u001b[0m\n",
       "\u001b[32mapproach leverages the LLM's ability to generate human-like text and understand contextual information, allowing it\u001b[0m\n",
       "\u001b[32mto tackle intricate tasks step-by-step.\\n\\nBy segmenting a task into its constituent parts, LLM agents can focus on\u001b[0m\n",
       "\u001b[32meach sub-task individually, facilitating improved accuracy and efficiency in generating responses. For example, if \u001b[0m\n",
       "\u001b[32man agent is tasked with writing a research paper, it might first decompose this task into specific steps such as \u001b[0m\n",
       "\u001b[32mconducting a literature review, outlining key points, drafting sections, and finally editing the content. Each of \u001b[0m\n",
       "\u001b[32mthese stages can then be handled in sequence, with the model drawing on its extensive training to produce coherent \u001b[0m\n",
       "\u001b[32mand relevant outputs at each step.\\n\\nTask decomposition not only aids in organizing the workflow for LLMs but also\u001b[0m\n",
       "\u001b[32mallows for better error detection and correction, as the agent can reevaluate each sub-task independently before \u001b[0m\n",
       "\u001b[32mmoving on to the next. This strategy ultimately enhances the overall performance and versatility of LLM agents, \u001b[0m\n",
       "\u001b[32menabling them to tackle a wide range of complex tasks with greater effectiveness.\"\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'hyde_embeddings'\u001b[0m: \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.01269984\u001b[0m,  \u001b[1;36m0.02164174\u001b[0m,  \u001b[1;36m0.05507778\u001b[0m, \u001b[33m...\u001b[0m,  \u001b[1;36m0.01497422\u001b[0m,\n",
       "       \u001b[1;36m-0.00026131\u001b[0m,  \u001b[1;36m0.01605932\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'Task decomposition for LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agents involves breaking down large and complex \u001b[0m\n",
       "\u001b[32mtasks into smaller, manageable subgoals. This approach enhances the agent\\'s ability to handle complicated tasks by\u001b[0m\n",
       "\u001b[32mallowing it to focus on simpler steps, facilitating a clearer planning and execution process. The technique, often \u001b[0m\n",
       "\u001b[32mreferred to as Chain of Thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, encourages the model to \"think step by step,\" promoting a more structured \u001b[0m\n",
       "\u001b[32mand interpretable thinking process. By decomposing tasks into smaller components, LLM agents can improve their \u001b[0m\n",
       "\u001b[32mproblem-solving efficiency and effectiveness.'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task decomposition for LLM (large language model) agents involves breaking down large and complex tasks into       \n",
       "smaller, manageable subgoals. This approach enhances the agent's ability to handle complicated tasks by allowing it\n",
       "to focus on simpler steps, facilitating a clearer planning and execution process. The technique, often referred to \n",
       "as Chain of Thought (CoT), encourages the model to \"think step by step,\" promoting a more structured and           \n",
       "interpretable thinking process. By decomposing tasks into smaller components, LLM agents can improve their         \n",
       "problem-solving efficiency and effectiveness.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Task decomposition for LLM (large language model) agents involves breaking down large and complex tasks into       \n",
       "smaller, manageable subgoals. This approach enhances the agent's ability to handle complicated tasks by allowing it\n",
       "to focus on simpler steps, facilitating a clearer planning and execution process. The technique, often referred to \n",
       "as Chain of Thought (CoT), encourages the model to \"think step by step,\" promoting a more structured and           \n",
       "interpretable thinking process. By decomposing tasks into smaller components, LLM agents can improve their         \n",
       "problem-solving efficiency and effectiveness.                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(query)\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"generated_documents_count\": 5,   \n",
    "    }\n",
    "}\n",
    "response = graph.invoke({\"question\": query}, config=config)\n",
    "\n",
    "display(Pretty(response, max_depth=2))\n",
    "display(Markdown(response[\"answer\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-rag",
   "language": "python",
   "name": "llm-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
