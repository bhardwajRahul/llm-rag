{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9324f11-ac04-47f0-8857-8717d51a68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from IPython.display import display, Image\n",
    "from rich import print as rprint\n",
    "from rich.markdown import Markdown\n",
    "from rich.pretty import Pretty\n",
    "from rich.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7730cc92-3ec2-41d2-be1d-b470666127c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a12549cc-6c43-4430-aa70-7af07e5835da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG From Scratch: Part 15 (Retrieval - CRAG)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b60d17-f30f-44e5-b6b9-b7ecdbf8ceeb",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc86a5-f35d-4516-bbbe-9736d5435a7c",
   "metadata": {},
   "source": [
    "![](images/retrieval.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8889a307-fa3f-4d38-9127-d41e4686ae47",
   "metadata": {},
   "source": [
    "# Corrective RAG (CRAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ad1dc9-2115-4ed9-8b53-4af3960b7edc",
   "metadata": {},
   "source": [
    "![](images/15-crag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18b647e-2e7f-4397-bf07-354ef29897f7",
   "metadata": {},
   "source": [
    "![](images/15-crag-implementation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fd601f-39bd-454b-a21a-990a039811b8",
   "metadata": {},
   "source": [
    "## Configure components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24f2640-f366-4df2-afd9-e5a0fc5bc4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af2d609f-8904-4c41-a029-817d1871a233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_38647f5e19', 'id': 'chatcmpl-BQDgtAEm4y6znLvsmuLv4mmKKhaKn', 'finish_reason': 'stop', 'logprobs': None}, id='run-472d82bf-d8f4-48a0-a675-21c12dc0c08b-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=1\n",
    ")\n",
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "936c53fc-e31d-4948-8db0-c64072f2acf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "len(embeddings.embed_query(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5310364c-7f1b-4660-86f6-757f0cb81a42",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efdb52b7-6d03-402a-a9e8-349b6afb8b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33acb22b-4015-4cf8-b1ef-8341e607a598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=articles,\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef525ba0-bfd0-484f-82ec-4aa4ed213915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1a2d79a-83d1-4106-9b1f-9f9699cfb14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      Prompt Engineering\n",
      "    \n",
      "Date: March 15, 2023  |  Estimated Reading Time: 21 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\n",
      "This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\n",
      "[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b320811-4089-4590-a499-24d701fb9b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      Adversarial Attacks on LLMs\n",
      "    \n",
      "Date: October 25, 2023  |  Estimated Reading Time: 33 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\n",
      "A large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.\n",
      "There is also a branch of work on attackin\n"
     ]
    }
   ],
   "source": [
    "print(docs[2].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2efc2ed-bde8-4152-b867-a685b1543ddc",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "999dfbf7-07e8-4b7b-aeab-e3ad9f9b2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b89d7902-b90f-4918-a20f-c90315d6d708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00516264-bf6a-4972-b997-053aaf13c2a1",
   "metadata": {},
   "source": [
    "## Store documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2676ca99-2159-4026-9015-415fd3188e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5419c0e5-b712-41ae-82b9-c4a0a1a84fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 180)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = InMemoryVectorStore(embeddings)\n",
    "doc_ids = vectorstore.add_documents(documents=splits)\n",
    "len(doc_ids), len(vectorstore.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feb37e81-2999-480c-b504-7025ddf7a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3809144c-6bf0-4512-9fa3-520f981efd00",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31da3a96-cbb6-4749-b619-51b9cfed3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import chain\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e3ce2f0-8fa2-413f-b065-a9fe06132508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question based on this context:\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_prompt_template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "print(rag_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcffecf4-d9f4-437b-a014-82160a2b30fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a grader assessing relevance of a retrieved document to a user question. \n",
      "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
      "Give a binary score to indicate whether the document is relevant to the question.\n",
      "\n",
      "Retrieved document:\n",
      "{document}\n",
      "\n",
      "User question:\n",
      "{question}\n"
     ]
    }
   ],
   "source": [
    "grading_prompt_template = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
    "Give a binary score to indicate whether the document is relevant to the question.\n",
    "\n",
    "Retrieved document:\n",
    "{document}\n",
    "\n",
    "User question:\n",
    "{question}\"\"\"\n",
    "\n",
    "print(grading_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c94e2d5d-71e5-452e-bf4b-33c992e2b6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You a question re-writer that converts an input question to a better version that is optimized for web search. \n",
      "Look at the input and try to reason about the underlying semantic intent / meaning.\n",
      "\n",
      "Here is the initial question:\n",
      "{question}\n",
      "\n",
      "Formulate an improved question.\n"
     ]
    }
   ],
   "source": [
    "query_rewriting_prompt_template = \"\"\"You a question re-writer that converts an input question to a better version that is optimized for web search. \n",
    "Look at the input and try to reason about the underlying semantic intent / meaning.\n",
    "\n",
    "Here is the initial question:\n",
    "{question}\n",
    "\n",
    "Formulate an improved question.\"\"\"\n",
    "\n",
    "print(query_rewriting_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f97fba9c-f104-412f-8b87-897bce3dc0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentGrade(BaseModel):\n",
    "    \"\"\"Relevance check on retrieved document.\"\"\"\n",
    "    chain_of_thought: str = Field(\n",
    "        ..., description=\"Step by step reasoning to check if the document is relevant to the question\"\n",
    "    )\n",
    "    is_relevant: bool = Field(\n",
    "        description=\"Document is relevant to the question\"\n",
    "    )\n",
    "\n",
    "grader_llm = llm.with_structured_output(DocumentGrade, method=\"function_calling\")\n",
    "\n",
    "@chain\n",
    "def grade_document(document, question):\n",
    "    grading_prompt = grading_prompt_template.format(document=document, question=question)\n",
    "    response = grader_llm.invoke([HumanMessage(content=grading_prompt)])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd69b456-ff03-40d3-93fb-992d67037938",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebSearchQuery(BaseModel):\n",
    "    \"\"\"Question optimization for web search.\"\"\"\n",
    "    chain_of_thought: str = Field(\n",
    "        ..., description=\"Step by step reasoning to optimize query for web search\"\n",
    "    )\n",
    "    web_search_query: str = Field(\n",
    "        description=\"Optimized web search query\"\n",
    "    )\n",
    "\n",
    "web_search_llm = llm.with_structured_output(WebSearchQuery, method=\"function_calling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f0eb7d0-4d8b-4e67-b392-b5e75375d5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_266301/2226099129.py:2: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  rprint(web_search_tool.input_schema.schema())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Input for the Tavily tool.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'properties'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'search query to look up'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Query'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'string'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'required'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'query'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'TavilyInput'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'object'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'description'\u001b[0m: \u001b[32m'Input for the Tavily tool.'\u001b[0m,\n",
       "    \u001b[32m'properties'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'query'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'description'\u001b[0m: \u001b[32m'search query to look up'\u001b[0m, \u001b[32m'title'\u001b[0m: \u001b[32m'Query'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'string'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'required'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'query'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'title'\u001b[0m: \u001b[32m'TavilyInput'\u001b[0m,\n",
       "    \u001b[32m'type'\u001b[0m: \u001b[32m'object'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "web_search_tool = TavilySearchResults(k=4)\n",
    "rprint(web_search_tool.input_schema.schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba910aa4-c2e7-4274-82b0-e9a24fd88913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs: list[Document]) -> list[str]:\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9d13f6e-342d-4a51-87c7-a42dd91c9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    documents: list[Document]\n",
    "    grades: list[DocumentGrade]\n",
    "    is_web_search_required: bool\n",
    "    web_search_query: str\n",
    "    context: Annotated[list[Document], operator.add]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4330b73a-e93a-44a8-9671-92af99eae231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "def grade_documents(state: State):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    grades = grade_document.batch(\n",
    "        documents, question=question\n",
    "    )\n",
    "    filtered_documents = [document for (document, grade) in zip(documents, grades) if grade.is_relevant]\n",
    "    is_web_search_required = len(filtered_documents) < len(documents)\n",
    "            \n",
    "    return {\"context\": filtered_documents, \"grades\": grades, \"is_web_search_required\": is_web_search_required}\n",
    "\n",
    "\n",
    "def check_documents_relevance(state: State) -> Literal[\"rewrite_query\", \"generate_answer\"]:\n",
    "    is_web_search_required = state[\"is_web_search_required\"]\n",
    "\n",
    "    if is_web_search_required:\n",
    "        return \"rewrite_query\"\n",
    "    else:\n",
    "        return \"generate_answer\"\n",
    "\n",
    "\n",
    "def rewrite_query(state: State):\n",
    "    question = state[\"question\"]\n",
    "    query_rewriting_prompt = query_rewriting_prompt_template.format(question=question)\n",
    "    response = web_search_llm.invoke(query_rewriting_prompt)\n",
    "    return {\"web_search_query\": response.web_search_query}\n",
    "\n",
    "\n",
    "def web_search(state: State):\n",
    "    query = state[\"web_search_query\"]\n",
    "    results = web_search_tool.invoke({\"query\": query})\n",
    "    documents = [Document(page_content=result[\"content\"]) for result in results]\n",
    "    return {\"context\": documents}\n",
    "\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    docs_content = format_docs(state[\"context\"])\n",
    "    rag_prompt = rag_prompt_template.format(\n",
    "        question=state[\"question\"],\n",
    "        context=docs_content\n",
    "    )\n",
    "    response = llm.invoke([\n",
    "        HumanMessage(content=rag_prompt)\n",
    "    ])\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ead6e91-8dd8-45a6-a79a-0fab3fa8c36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7f35f0dd3bd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"grade_documents\", grade_documents)\n",
    "graph_builder.add_node(\"rewrite_query\", rewrite_query)\n",
    "graph_builder.add_node(\"web_search\", web_search)\n",
    "graph_builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(\"retrieve\", \"grade_documents\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"grade_documents\", \n",
    "    check_documents_relevance\n",
    ")\n",
    "graph_builder.add_edge(\"rewrite_query\", \"web_search\")\n",
    "graph_builder.add_edge(\"web_search\", \"generate_answer\")\n",
    "graph_builder.add_edge(\"generate_answer\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f12ae9ea-a596-4136-93f7-551f6933f8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What are common types of agent memory?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'documents'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'d98ef1ec-209b-4c0c-b377-ac51f533fca5'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Short-term memory: I would consider all the in-context learning (See Prompt Engineering) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capability to retain and recall (infinite) information over extended periods, often by leveraging an external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is missing from the model weights (often hard to change after pre-training), including current information, code </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">execution capability, access to proprietary information sources and more.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1f7e4957-8dd6-4ded-99c4-b40cd129d29c'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Memory stream: is a long-term memory module (external database) that records a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model: surfaces the context to inform the agent’s behavior, according to relevance, recency and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">higher-level summaries of past events (&lt;- note that this is a bit different from self-reflection above)'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'6e45bc8b-2550-4f2c-95d3-fe18ca564fa9'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cf43b2ec-9978-4407-bc88-721c5bb0d22f'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Sensory memory as learning embedding representations for raw inputs, including text, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">representation of information into a vector store database that can support fast maximum inner-product search </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">speedup.\\nA couple common choices of ANN algorithms for fast MIPS:'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'grades'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocumentGrade</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chain_of_thought</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The question asks about common types of agent memory. The document explicitly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mentions 'Short-term memory' and 'Long-term memory' in the context of agent memory, providing details about each </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">type. It directly addresses the question about types of agent memory, making it highly relevant.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_relevant</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocumentGrade</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chain_of_thought</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The user question asks about common types of agent memory. The document discusses </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'Memory stream' as a long-term memory module that records agent experiences, including observations and events. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">also describes mechanisms related to memory retrieval and reflection. While it does not provide a list of types </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">explicitly, it provides detailed information about a specific type of agent memory and related concepts. Hence, the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">document is related to the question as it covers the concept of agent memory and associated mechanisms, which can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">be considered as part of common memory types or functions in agents.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_relevant</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocumentGrade</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chain_of_thought</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The user question asks about common types of agent memory. The retrieved document </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discusses memory, specifically 'Types of Memory' such as Sensory Memory, Iconic Memory, Echoic Memory, and Haptic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Memory, which are related to human memory processes. While it primarily focuses on human brain memory types, these </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">are relevant to the concept of agent memory since agents often model or mimic types of human memory to function. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Hence, the document is relevant as it contains information about different types of memory applicable to agents.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_relevant</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocumentGrade</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chain_of_thought</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The user question asks about common types of agent memory. The retrieved document </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">explicitly mentions different types of memory for agents: sensory memory, short-term memory, and long-term memory. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">It also provides definitions or descriptions for each type. Therefore, the document is directly relevant to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question.'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_relevant</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'is_web_search_required'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'d98ef1ec-209b-4c0c-b377-ac51f533fca5'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Short-term memory: I would consider all the in-context learning (See Prompt Engineering) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capability to retain and recall (infinite) information over extended periods, often by leveraging an external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is missing from the model weights (often hard to change after pre-training), including current information, code </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">execution capability, access to proprietary information sources and more.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1f7e4957-8dd6-4ded-99c4-b40cd129d29c'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Memory stream: is a long-term memory module (external database) that records a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model: surfaces the context to inform the agent’s behavior, according to relevance, recency and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">higher-level summaries of past events (&lt;- note that this is a bit different from self-reflection above)'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'6e45bc8b-2550-4f2c-95d3-fe18ca564fa9'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cf43b2ec-9978-4407-bc88-721c5bb0d22f'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Sensory memory as learning embedding representations for raw inputs, including text, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">representation of information into a vector store database that can support fast maximum inner-product search </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">speedup.\\nA couple common choices of ANN algorithms for fast MIPS:'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Common types of agent memory include:\\n\\n1. **Sensory Memory**  \\n   - The earliest stage of memory </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that retains impressions of sensory information (visual, auditory, etc.) for a very short duration (a few seconds).</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\n   - In agents, this can correspond to learning embedding representations for raw inputs such as text, images, or</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">other modalities.\\n\\n2. **Short-term Memory**  \\n   - Corresponds to in-context learning, where the model utilizes </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the current context (prompt) to learn or adapt behavior temporarily.  \\n   - It is short and finite, limited by the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context window length of the Transformer model.\\n\\n3. **Long-term Memory**  \\n   - An external memory module, often</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">implemented as a vector store, that retains and allows retrieval of information over extended periods, beyond the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">immediate context.  \\n   - Supports fast retrieval methods such as Maximum Inner Product Search (MIPS) using </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">approximate nearest neighbors (ANN) algorithms to efficiently surface relevant memories during a query.\\n\\nThese </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory types enable an agent to acquire, store, retain, and recall information for improved performance in various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'What are common types of agent memory?'\u001b[0m,\n",
       "    \u001b[32m'documents'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'd98ef1ec-209b-4c0c-b377-ac51f533fca5'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Short-term memory: I would consider all the in-context learning \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSee Prompt Engineering\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mas utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the \u001b[0m\n",
       "\u001b[32mcapability to retain and recall \u001b[0m\u001b[32m(\u001b[0m\u001b[32minfinite\u001b[0m\u001b[32m)\u001b[0m\u001b[32m information over extended periods, often by leveraging an external \u001b[0m\n",
       "\u001b[32mvector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that\u001b[0m\n",
       "\u001b[32mis missing from the model weights \u001b[0m\u001b[32m(\u001b[0m\u001b[32moften hard to change after pre-training\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, including current information, code \u001b[0m\n",
       "\u001b[32mexecution capability, access to proprietary information sources and more.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'1f7e4957-8dd6-4ded-99c4-b40cd129d29c'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Memory stream: is a long-term memory module \u001b[0m\u001b[32m(\u001b[0m\u001b[32mexternal database\u001b[0m\u001b[32m)\u001b[0m\u001b[32m that records a \u001b[0m\n",
       "\u001b[32mcomprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly \u001b[0m\n",
       "\u001b[32mprovided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval \u001b[0m\n",
       "\u001b[32mmodel: surfaces the context to inform the agent’s behavior, according to relevance, recency and \u001b[0m\n",
       "\u001b[32mimportance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask \u001b[0m\n",
       "\u001b[32mLM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: \u001b[0m\n",
       "\u001b[32msynthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are \u001b[0m\n",
       "\u001b[32mhigher-level summaries of past events \u001b[0m\u001b[32m(\u001b[0m\u001b[32m<- note that this is a bit different from self-reflection above\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'6e45bc8b-2550-4f2c-95d3-fe18ca564fa9'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory \u001b[0m\n",
       "\u001b[32mand exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments \u001b[0m\n",
       "\u001b[32mand DQN for watermaze.\u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Laskin et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nComponent Two: Memory#\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mBig thank you to ChatGPT for \u001b[0m\n",
       "\u001b[32mhelping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my \u001b[0m\n",
       "\u001b[32mconversations with ChatGPT.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, \u001b[0m\n",
       "\u001b[32mretain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: \u001b[0m\n",
       "\u001b[32mThis is the earliest stage of memory, providing the ability to retain impressions of sensory information \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual, \u001b[0m\n",
       "\u001b[32mauditory, etc\u001b[0m\u001b[32m)\u001b[0m\u001b[32m after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. \u001b[0m\n",
       "\u001b[32mSubcategories include iconic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, echoic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mauditory\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and haptic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mtouch\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'cf43b2ec-9978-4407-bc88-721c5bb0d22f'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Sensory memory as learning embedding representations for raw inputs, including text, \u001b[0m\n",
       "\u001b[32mimage or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted \u001b[0m\n",
       "\u001b[32mby the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent \u001b[0m\n",
       "\u001b[32mcan attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMIPS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m#\\nThe external \u001b[0m\n",
       "\u001b[32mmemory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding \u001b[0m\n",
       "\u001b[32mrepresentation of information into a vector store database that can support fast maximum inner-product search \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mMIPS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. To optimize the retrieval speed, the common choice is the approximate nearest neighbors \u001b[0m\u001b[32m(\u001b[0m\u001b[32mANN\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\u200b \u001b[0m\n",
       "\u001b[32malgorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge \u001b[0m\n",
       "\u001b[32mspeedup.\\nA couple common choices of ANN algorithms for fast MIPS:'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'grades'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocumentGrade\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mchain_of_thought\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m question asks about common types of agent memory. The document explicitly \u001b[0m\n",
       "\u001b[32mmentions 'Short-term memory' and 'Long-term memory' in the context of agent memory, providing details about each \u001b[0m\n",
       "\u001b[32mtype. It directly addresses the question about types of agent memory, making it highly relevant.\"\u001b[0m,\n",
       "            \u001b[33mis_relevant\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocumentGrade\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mchain_of_thought\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m user question asks about common types of agent memory. The document discusses \u001b[0m\n",
       "\u001b[32m'Memory stream' as a long-term memory module that records agent experiences, including observations and events. It \u001b[0m\n",
       "\u001b[32malso describes mechanisms related to memory retrieval and reflection. While it does not provide a list of types \u001b[0m\n",
       "\u001b[32mexplicitly, it provides detailed information about a specific type of agent memory and related concepts. Hence, the\u001b[0m\n",
       "\u001b[32mdocument is related to the question as it covers the concept of agent memory and associated mechanisms, which can \u001b[0m\n",
       "\u001b[32mbe considered as part of common memory types or functions in agents.\"\u001b[0m,\n",
       "            \u001b[33mis_relevant\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocumentGrade\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mchain_of_thought\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m user question asks about common types of agent memory. The retrieved document \u001b[0m\n",
       "\u001b[32mdiscusses memory, specifically 'Types of Memory' such as Sensory Memory, Iconic Memory, Echoic Memory, and Haptic \u001b[0m\n",
       "\u001b[32mMemory, which are related to human memory processes. While it primarily focuses on human brain memory types, these \u001b[0m\n",
       "\u001b[32mare relevant to the concept of agent memory since agents often model or mimic types of human memory to function. \u001b[0m\n",
       "\u001b[32mHence, the document is relevant as it contains information about different types of memory applicable to agents.\"\u001b[0m,\n",
       "            \u001b[33mis_relevant\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocumentGrade\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mchain_of_thought\u001b[0m=\u001b[32m'The user question asks about common types of agent memory. The retrieved document \u001b[0m\n",
       "\u001b[32mexplicitly mentions different types of memory for agents: sensory memory, short-term memory, and long-term memory. \u001b[0m\n",
       "\u001b[32mIt also provides definitions or descriptions for each type. Therefore, the document is directly relevant to the \u001b[0m\n",
       "\u001b[32mquestion.'\u001b[0m,\n",
       "            \u001b[33mis_relevant\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'is_web_search_required'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'd98ef1ec-209b-4c0c-b377-ac51f533fca5'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Short-term memory: I would consider all the in-context learning \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSee Prompt Engineering\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mas utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the \u001b[0m\n",
       "\u001b[32mcapability to retain and recall \u001b[0m\u001b[32m(\u001b[0m\u001b[32minfinite\u001b[0m\u001b[32m)\u001b[0m\u001b[32m information over extended periods, often by leveraging an external \u001b[0m\n",
       "\u001b[32mvector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that\u001b[0m\n",
       "\u001b[32mis missing from the model weights \u001b[0m\u001b[32m(\u001b[0m\u001b[32moften hard to change after pre-training\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, including current information, code \u001b[0m\n",
       "\u001b[32mexecution capability, access to proprietary information sources and more.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'1f7e4957-8dd6-4ded-99c4-b40cd129d29c'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Memory stream: is a long-term memory module \u001b[0m\u001b[32m(\u001b[0m\u001b[32mexternal database\u001b[0m\u001b[32m)\u001b[0m\u001b[32m that records a \u001b[0m\n",
       "\u001b[32mcomprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly \u001b[0m\n",
       "\u001b[32mprovided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval \u001b[0m\n",
       "\u001b[32mmodel: surfaces the context to inform the agent’s behavior, according to relevance, recency and \u001b[0m\n",
       "\u001b[32mimportance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask \u001b[0m\n",
       "\u001b[32mLM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: \u001b[0m\n",
       "\u001b[32msynthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are \u001b[0m\n",
       "\u001b[32mhigher-level summaries of past events \u001b[0m\u001b[32m(\u001b[0m\u001b[32m<- note that this is a bit different from self-reflection above\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'6e45bc8b-2550-4f2c-95d3-fe18ca564fa9'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory \u001b[0m\n",
       "\u001b[32mand exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments \u001b[0m\n",
       "\u001b[32mand DQN for watermaze.\u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Laskin et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nComponent Two: Memory#\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mBig thank you to ChatGPT for \u001b[0m\n",
       "\u001b[32mhelping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my \u001b[0m\n",
       "\u001b[32mconversations with ChatGPT.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, \u001b[0m\n",
       "\u001b[32mretain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: \u001b[0m\n",
       "\u001b[32mThis is the earliest stage of memory, providing the ability to retain impressions of sensory information \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual, \u001b[0m\n",
       "\u001b[32mauditory, etc\u001b[0m\u001b[32m)\u001b[0m\u001b[32m after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. \u001b[0m\n",
       "\u001b[32mSubcategories include iconic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, echoic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mauditory\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and haptic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mtouch\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'cf43b2ec-9978-4407-bc88-721c5bb0d22f'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Sensory memory as learning embedding representations for raw inputs, including text, \u001b[0m\n",
       "\u001b[32mimage or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted \u001b[0m\n",
       "\u001b[32mby the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent \u001b[0m\n",
       "\u001b[32mcan attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMIPS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m#\\nThe external \u001b[0m\n",
       "\u001b[32mmemory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding \u001b[0m\n",
       "\u001b[32mrepresentation of information into a vector store database that can support fast maximum inner-product search \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mMIPS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. To optimize the retrieval speed, the common choice is the approximate nearest neighbors \u001b[0m\u001b[32m(\u001b[0m\u001b[32mANN\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\u200b \u001b[0m\n",
       "\u001b[32malgorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge \u001b[0m\n",
       "\u001b[32mspeedup.\\nA couple common choices of ANN algorithms for fast MIPS:'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'Common types of agent memory include:\\n\\n1. **Sensory Memory**  \\n   - The earliest stage of memory \u001b[0m\n",
       "\u001b[32mthat retains impressions of sensory information \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual, auditory, etc.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for a very short duration \u001b[0m\u001b[32m(\u001b[0m\u001b[32ma few seconds\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\u001b[0m\n",
       "\u001b[32m\\n   - In agents, this can correspond to learning embedding representations for raw inputs such as text, images, or\u001b[0m\n",
       "\u001b[32mother modalities.\\n\\n2. **Short-term Memory**  \\n   - Corresponds to in-context learning, where the model utilizes \u001b[0m\n",
       "\u001b[32mthe current context \u001b[0m\u001b[32m(\u001b[0m\u001b[32mprompt\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to learn or adapt behavior temporarily.  \\n   - It is short and finite, limited by the\u001b[0m\n",
       "\u001b[32mcontext window length of the Transformer model.\\n\\n3. **Long-term Memory**  \\n   - An external memory module, often\u001b[0m\n",
       "\u001b[32mimplemented as a vector store, that retains and allows retrieval of information over extended periods, beyond the \u001b[0m\n",
       "\u001b[32mimmediate context.  \\n   - Supports fast retrieval methods such as Maximum Inner Product Search \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMIPS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m using \u001b[0m\n",
       "\u001b[32mapproximate nearest neighbors \u001b[0m\u001b[32m(\u001b[0m\u001b[32mANN\u001b[0m\u001b[32m)\u001b[0m\u001b[32m algorithms to efficiently surface relevant memories during a query.\\n\\nThese \u001b[0m\n",
       "\u001b[32mmemory types enable an agent to acquire, store, retain, and recall information for improved performance in various \u001b[0m\n",
       "\u001b[32mtasks.'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Common types of agent memory include:                                                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Sensory Memory</span>                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>The earliest stage of memory that retains impressions of sensory information (visual, auditory, etc.) for a  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>very short duration (a few seconds).                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>In agents, this can correspond to learning embedding representations for raw inputs such as text, images, or \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>other modalities.                                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Short-term Memory</span>                                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Corresponds to in-context learning, where the model utilizes the current context (prompt) to learn or adapt  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>behavior temporarily.                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>It is short and finite, limited by the context window length of the Transformer model.                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Long-term Memory</span>                                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>An external memory module, often implemented as a vector store, that retains and allows retrieval of         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>information over extended periods, beyond the immediate context.                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Supports fast retrieval methods such as Maximum Inner Product Search (MIPS) using approximate nearest        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>neighbors (ANN) algorithms to efficiently surface relevant memories during a query.                          \n",
       "\n",
       "These memory types enable an agent to acquire, store, retain, and recall information for improved performance in   \n",
       "various tasks.                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Common types of agent memory include:                                                                              \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mSensory Memory\u001b[0m                                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mThe earliest stage of memory that retains impressions of sensory information (visual, auditory, etc.) for a  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mvery short duration (a few seconds).                                                                         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mIn agents, this can correspond to learning embedding representations for raw inputs such as text, images, or \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mother modalities.                                                                                            \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mShort-term Memory\u001b[0m                                                                                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mCorresponds to in-context learning, where the model utilizes the current context (prompt) to learn or adapt  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mbehavior temporarily.                                                                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mIt is short and finite, limited by the context window length of the Transformer model.                       \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mLong-term Memory\u001b[0m                                                                                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mAn external memory module, often implemented as a vector store, that retains and allows retrieval of         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0minformation over extended periods, beyond the immediate context.                                             \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mSupports fast retrieval methods such as Maximum Inner Product Search (MIPS) using approximate nearest        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mneighbors (ANN) algorithms to efficiently surface relevant memories during a query.                          \n",
       "\n",
       "These memory types enable an agent to acquire, store, retain, and recall information for improved performance in   \n",
       "various tasks.                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What are common types of agent memory?\"\n",
    "\n",
    "response = graph.invoke({\"question\": query})\n",
    "rprint(response)\n",
    "rprint(Markdown(response[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a4cc058-ed9e-4a91-8d6f-593dfd7f6cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What are main steps for collecting human data?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'documents'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'4c5405bf-80ee-4221-b156-0134c1a84ca7'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Casper et al. (2023) set up a human-in-the-loop red teaming process. The main difference </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from Perez et al. (2022) is that they explicitly set up a data sampling stage for the target model such that we can</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">collect human labels on them to train a task-specific red team classifier. There are three steps:'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'48e5c5ca-2d73-4cdc-bae5-fced9819183b'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"With the input and the inference results, the AI assistant needs to describe the process </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">straightforward manner. Then describe the task process and show your analysis and model inference results to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">user in the first person. If inference results contain a file path, must tell the user the complete file path.\"</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'5b2c0179-3048-4680-8279-217461c5765c'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks in the least number of steps.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fac5d7aa-9a90-4f13-b0c8-858028ffa9d9'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Question clustering: Embed questions and run $k$-means for clustering.\\nDemonstration </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">selection: Select a set of representative questions from each cluster; i.e. one demonstration from one cluster. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Samples in each cluster are sorted by distance to the cluster centroid and those closer to the centroid are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">selected first.\\nRationale generation: Use zero-shot CoT to generate reasoning chains for selected questions and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">construct few-shot prompt to run inference.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'grades'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocumentGrade</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chain_of_thought</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The retrieved document mentions a human-in-the-loop red teaming process by Casper et </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">al. (2023) and highlights that they explicitly set up a data sampling stage to collect human labels for training a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task-specific red team classifier. The document then starts listing 'There are three steps:', presumably outlining </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the main steps for the data collection process. This is directly relevant to the user question asking about the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">main steps for collecting human data as it describes a process involving human data collection steps.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_relevant</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocumentGrade</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chain_of_thought</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The document describes a process involving user input, task planning, model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">selection, and task execution, but it relates to how an AI assistant processes inference and responses rather than </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the specific steps for collecting human data. There is no mention of data collection, human data, or related steps </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in the document content. Therefore, it does not address the user's question about the main steps for collecting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">human data.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_relevant</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocumentGrade</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chain_of_thought</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The user question is about the main steps for collecting human data. The retrieved </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">document mentions resources such as internet access, long term memory management, GPT-3.5 powered agents, and file </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output, as well as performance evaluation methods like reviewing actions, self-criticism, reflection, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiency. However, it does not mention anything specifically about collecting human data or relevant steps for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data collection related to humans. Therefore, the document is not relevant to the user's question.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_relevant</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocumentGrade</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chain_of_thought</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The user question asks about the main steps for collecting human data. The retrieved </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">document content discusses steps involving question clustering, demonstration selection, and rationale generation, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">which are related to organizing and utilizing question data, possibly as part of a data collection or machine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning process. Since the user question is about collecting human data and the document details steps on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">organizing questions and demonstrations which could be part of collecting or preparing such data, it is relevant to</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the user question.'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_relevant</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'is_web_search_required'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'web_search_query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'main steps and methods for collecting human data in research'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'4c5405bf-80ee-4221-b156-0134c1a84ca7'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Casper et al. (2023) set up a human-in-the-loop red teaming process. The main difference </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from Perez et al. (2022) is that they explicitly set up a data sampling stage for the target model such that we can</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">collect human labels on them to train a task-specific red team classifier. There are three steps:'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fac5d7aa-9a90-4f13-b0c8-858028ffa9d9'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Question clustering: Embed questions and run $k$-means for clustering.\\nDemonstration </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">selection: Select a set of representative questions from each cluster; i.e. one demonstration from one cluster. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Samples in each cluster are sorted by distance to the cluster centroid and those closer to the centroid are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">selected first.\\nRationale generation: Use zero-shot CoT to generate reasoning chains for selected questions and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">construct few-shot prompt to run inference.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The\\xa0aim of the research\\nThe type of data that you will collect\\nThe methods\\xa0and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">procedures you will use to collect, store, and process the data\\n\\nTo collect high-quality data that is relevant to</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">your purposes, follow these four steps.\\nTable of contents\\n\\nStep 1: Define the aim of your research\\nStep 2: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Choose your data collection method\\nStep 3: Plan your data collection procedures\\nStep 4: Collect the data\\nOther </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interesting articles\\nFrequently asked questions about data collection [...] Carefully consider what method you </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">will use to gather data that helps you directly answer your research questions.\\nData collection methods\\n| Method </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">| When to use | How to collect data |\\n| --- | --- | --- |\\n| Experiment | To test a causal relationship. | </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Manipulate variables and measure their effects on others. |\\n| Survey | To understand the general characteristics </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">or opinions of a group of people. | Distribute a list of questions to a sample online, in person or over-the-phone.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">| [...] Step 1: Define the aim of your research\\nBefore you start the process of data collection, you need to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identify exactly what you want to achieve. You can start by writing a problem statement: what is the practical or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scientific issue that you want to address and why does it matter?\\nNext, formulate one or more research questions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that precisely define what you want to find out. Depending on your research questions, you might need to collect </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quantitative or qualitative data:'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Data Collection Methods and Tools for Research ;\\nA Step -by -Step Guide to Choose Data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Collection\\nTechnique for Academic and Business Research\\nProject s\\nAuthors \\nHamed Taherdoost \\nUniversity Canada</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">West \\nhamed.taherdoost@gmail.com \\nVancouver, Canada \\nAbstract \\nOne of the main stages in a research study is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data collection that enables the researcher to find \\nanswers to research questions. Data collection is the process</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of collecting data aiming to gain insights [...] 33 \\n3.1.14. Statistical Method \\nThese methods are a combination </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of processes including data collection, summarizing the information, \\nanalyzing them, and reporting the findings </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as quantitative data. The data collection step includes \\ndeciding what should be observed and making observations </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to address the questions using samples that \\nshould represent the whole population and be adequate in number. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarization process includes [...] is also possible. Nevertheless, these methods also can face unexpected </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">differences and some difficulties as \\nthe implementation and inv estigation capacity are limited in these methods.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">These approaches use \\ndifferent methods such as experiments and structured interviews for data collection which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">are discussed \\nin the data collection methods section. \\nIII. DATA COLLECTION METHODS \\nGenerally, data collection</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">methods are divided to two main categories of Primary Data Collection'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Maintaining Compliance with Data Collection Procedures: 1. Think through the process for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the collection and use of research data and prepare a standard operating procedure (SOP) that can be easily </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">followed. Make sure this SOP addresses the following: a. Detailed methods for handling all forms of data (i.e., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">paper signed consent forms, electronic Excel spreadsheets, audio recordings, etc.) b. Storage of all forms of data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">including separate storage of data with identifiers such as master lists, [...] description of the measures that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">will be taken to maintain the confidentiality of the study participant’s data in the informed consent form, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information sheet or oral consent transcript as applicable. Here are some steps you can take to de-identify </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">research data: • Remove direct identifiers • Reduce precision/detail of direct and/or indirect identifiers through </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aggregation • Instead of using date of birth use the year, decade, or date of service • Research involving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interviews or focus group [...] encrypted server that is available to all Wayne State University faculty, students </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and staff. • Collect only the minimum data necessary for your data analysis, • If your research requires the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">collection of identifiable data, then code the data as described below and store the master list in a different </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">location from the coded data, o Limit the accessibility of the master list among members of the research team to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">only those who will need to de-code. • Recorded interviews and focus group'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Top six data collection methods: Interviews, Questionnaires and surveys, Observations, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Documents and records, Focus groups, Oral histories. 6.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1. Observation. Observational methods focus on examining things and collecting data about</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">them. · 2. Survey. Survey methods focus on gathering'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The main steps for collecting human data, based on the provided context, are:\\n\\n1. **Define the aim</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of your research**  \\n   - Identify exactly what you want to achieve.  \\n   - Write a problem statement describing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the practical or scientific issue you want to address and why it matters.  \\n   - Formulate clear research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">questions to guide data collection.  \\n\\n2. **Choose your data collection method**  \\n   - Select an appropriate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">method based on your research questions, such as experiments, surveys, interviews, observations, focus groups, etc.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\n   - Ensure the chosen method effectively helps answer your research questions.  \\n\\n3. **Plan your data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">collection procedures**  \\n   - Develop a detailed plan or standard operating procedure (SOP) outlining how you </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">will collect, handle, and store data.  \\n   - Address handling of different data forms (paper, electronic, audio, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">etc.).  \\n   - Plan for maintaining confidentiality and data security (e.g., de-identification, encryption, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">restricted access).  \\n\\n4. **Collect the data**  \\n   - Implement your planned data collection process following </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the SOP.  \\n   - Collect only the minimum necessary data to answer your questions.  \\n   - Ensure data are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">collected ethically, maintaining participant confidentiality and data integrity.  \\n\\nThese steps align with good </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">research practice and ensure that human data collection is systematic, ethical, and useful for answering research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">questions.'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'What are main steps for collecting human data?'\u001b[0m,\n",
       "    \u001b[32m'documents'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'4c5405bf-80ee-4221-b156-0134c1a84ca7'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Casper et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m set up a human-in-the-loop red teaming process. The main difference \u001b[0m\n",
       "\u001b[32mfrom Perez et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is that they explicitly set up a data sampling stage for the target model such that we can\u001b[0m\n",
       "\u001b[32mcollect human labels on them to train a task-specific red team classifier. There are three steps:'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'48e5c5ca-2d73-4cdc-bae5-fced9819183b'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m\"With\u001b[0m\u001b[32m the input and the inference results, the AI assistant needs to describe the process \u001b[0m\n",
       "\u001b[32mand results. The previous stages can be formed as - User Input: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m User Input \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Task Planning: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Tasks \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Model\u001b[0m\n",
       "\u001b[32mSelection: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Model Assignment \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Task Execution: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Predictions \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. You must first answer the user's request in a\u001b[0m\n",
       "\u001b[32mstraightforward manner. Then describe the task process and show your analysis and model inference results to the \u001b[0m\n",
       "\u001b[32muser in the first person. If inference results contain a file path, must tell the user the complete file path.\"\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'5b2c0179-3048-4680-8279-217461c5765c'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term \u001b[0m\n",
       "\u001b[32mmemory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance \u001b[0m\n",
       "\u001b[32mEvaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your \u001b[0m\n",
       "\u001b[32mabilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions \u001b[0m\n",
       "\u001b[32mand strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete \u001b[0m\n",
       "\u001b[32mtasks in the least number of steps.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'fac5d7aa-9a90-4f13-b0c8-858028ffa9d9'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Question clustering: Embed questions and run $k$-means for clustering.\\nDemonstration \u001b[0m\n",
       "\u001b[32mselection: Select a set of representative questions from each cluster; i.e. one demonstration from one cluster. \u001b[0m\n",
       "\u001b[32mSamples in each cluster are sorted by distance to the cluster centroid and those closer to the centroid are \u001b[0m\n",
       "\u001b[32mselected first.\\nRationale generation: Use zero-shot CoT to generate reasoning chains for selected questions and \u001b[0m\n",
       "\u001b[32mconstruct few-shot prompt to run inference.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'grades'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocumentGrade\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mchain_of_thought\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m retrieved document mentions a human-in-the-loop red teaming process by Casper et \u001b[0m\n",
       "\u001b[32mal. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and highlights that they explicitly set up a data sampling stage to collect human labels for training a \u001b[0m\n",
       "\u001b[32mtask-specific red team classifier. The document then starts listing 'There are three steps:', presumably outlining \u001b[0m\n",
       "\u001b[32mthe main steps for the data collection process. This is directly relevant to the user question asking about the \u001b[0m\n",
       "\u001b[32mmain steps for collecting human data as it describes a process involving human data collection steps.\"\u001b[0m,\n",
       "            \u001b[33mis_relevant\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocumentGrade\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mchain_of_thought\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m document describes a process involving user input, task planning, model \u001b[0m\n",
       "\u001b[32mselection, and task execution, but it relates to how an AI assistant processes inference and responses rather than \u001b[0m\n",
       "\u001b[32mthe specific steps for collecting human data. There is no mention of data collection, human data, or related steps \u001b[0m\n",
       "\u001b[32min the document content. Therefore, it does not address the user's question about the main steps for collecting \u001b[0m\n",
       "\u001b[32mhuman data.\"\u001b[0m,\n",
       "            \u001b[33mis_relevant\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocumentGrade\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mchain_of_thought\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m user question is about the main steps for collecting human data. The retrieved \u001b[0m\n",
       "\u001b[32mdocument mentions resources such as internet access, long term memory management, GPT-3.5 powered agents, and file \u001b[0m\n",
       "\u001b[32moutput, as well as performance evaluation methods like reviewing actions, self-criticism, reflection, and \u001b[0m\n",
       "\u001b[32mefficiency. However, it does not mention anything specifically about collecting human data or relevant steps for \u001b[0m\n",
       "\u001b[32mdata collection related to humans. Therefore, the document is not relevant to the user's question.\"\u001b[0m,\n",
       "            \u001b[33mis_relevant\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocumentGrade\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mchain_of_thought\u001b[0m=\u001b[32m'The user question asks about the main steps for collecting human data. The retrieved \u001b[0m\n",
       "\u001b[32mdocument content discusses steps involving question clustering, demonstration selection, and rationale generation, \u001b[0m\n",
       "\u001b[32mwhich are related to organizing and utilizing question data, possibly as part of a data collection or machine \u001b[0m\n",
       "\u001b[32mlearning process. Since the user question is about collecting human data and the document details steps on \u001b[0m\n",
       "\u001b[32morganizing questions and demonstrations which could be part of collecting or preparing such data, it is relevant to\u001b[0m\n",
       "\u001b[32mthe user question.'\u001b[0m,\n",
       "            \u001b[33mis_relevant\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'is_web_search_required'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'web_search_query'\u001b[0m: \u001b[32m'main steps and methods for collecting human data in research'\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'4c5405bf-80ee-4221-b156-0134c1a84ca7'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Casper et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m set up a human-in-the-loop red teaming process. The main difference \u001b[0m\n",
       "\u001b[32mfrom Perez et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is that they explicitly set up a data sampling stage for the target model such that we can\u001b[0m\n",
       "\u001b[32mcollect human labels on them to train a task-specific red team classifier. There are three steps:'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'fac5d7aa-9a90-4f13-b0c8-858028ffa9d9'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Question clustering: Embed questions and run $k$-means for clustering.\\nDemonstration \u001b[0m\n",
       "\u001b[32mselection: Select a set of representative questions from each cluster; i.e. one demonstration from one cluster. \u001b[0m\n",
       "\u001b[32mSamples in each cluster are sorted by distance to the cluster centroid and those closer to the centroid are \u001b[0m\n",
       "\u001b[32mselected first.\\nRationale generation: Use zero-shot CoT to generate reasoning chains for selected questions and \u001b[0m\n",
       "\u001b[32mconstruct few-shot prompt to run inference.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'The\\xa0aim of the research\\nThe type of data that you will collect\\nThe methods\\xa0and \u001b[0m\n",
       "\u001b[32mprocedures you will use to collect, store, and process the data\\n\\nTo collect high-quality data that is relevant to\u001b[0m\n",
       "\u001b[32myour purposes, follow these four steps.\\nTable of contents\\n\\nStep 1: Define the aim of your research\\nStep 2: \u001b[0m\n",
       "\u001b[32mChoose your data collection method\\nStep 3: Plan your data collection procedures\\nStep 4: Collect the data\\nOther \u001b[0m\n",
       "\u001b[32minteresting articles\\nFrequently asked questions about data collection \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Carefully consider what method you \u001b[0m\n",
       "\u001b[32mwill use to gather data that helps you directly answer your research questions.\\nData collection methods\\n| Method \u001b[0m\n",
       "\u001b[32m| When to use | How to collect data |\\n| --- | --- | --- |\\n| Experiment | To test a causal relationship. | \u001b[0m\n",
       "\u001b[32mManipulate variables and measure their effects on others. |\\n| Survey | To understand the general characteristics \u001b[0m\n",
       "\u001b[32mor opinions of a group of people. | Distribute a list of questions to a sample online, in person or over-the-phone.\u001b[0m\n",
       "\u001b[32m| \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Step 1: Define the aim of your research\\nBefore you start the process of data collection, you need to \u001b[0m\n",
       "\u001b[32midentify exactly what you want to achieve. You can start by writing a problem statement: what is the practical or \u001b[0m\n",
       "\u001b[32mscientific issue that you want to address and why does it matter?\\nNext, formulate one or more research questions \u001b[0m\n",
       "\u001b[32mthat precisely define what you want to find out. Depending on your research questions, you might need to collect \u001b[0m\n",
       "\u001b[32mquantitative or qualitative data:'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Data Collection Methods and Tools for Research ;\\nA Step -by -Step Guide to Choose Data \u001b[0m\n",
       "\u001b[32mCollection\\nTechnique for Academic and Business Research\\nProject s\\nAuthors \\nHamed Taherdoost \\nUniversity Canada\u001b[0m\n",
       "\u001b[32mWest \\nhamed.taherdoost@gmail.com \\nVancouver, Canada \\nAbstract \\nOne of the main stages in a research study is \u001b[0m\n",
       "\u001b[32mdata collection that enables the researcher to find \\nanswers to research questions. Data collection is the process\u001b[0m\n",
       "\u001b[32mof collecting data aiming to gain insights \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m 33 \\n3.1.14. Statistical Method \\nThese methods are a combination \u001b[0m\n",
       "\u001b[32mof processes including data collection, summarizing the information, \\nanalyzing them, and reporting the findings \u001b[0m\n",
       "\u001b[32mas quantitative data. The data collection step includes \\ndeciding what should be observed and making observations \u001b[0m\n",
       "\u001b[32mto address the questions using samples that \\nshould represent the whole population and be adequate in number. The \u001b[0m\n",
       "\u001b[32msummarization process includes \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m is also possible. Nevertheless, these methods also can face unexpected \u001b[0m\n",
       "\u001b[32mdifferences and some difficulties as \\nthe implementation and inv estigation capacity are limited in these methods.\u001b[0m\n",
       "\u001b[32mThese approaches use \\ndifferent methods such as experiments and structured interviews for data collection which \u001b[0m\n",
       "\u001b[32mare discussed \\nin the data collection methods section. \\nIII. DATA COLLECTION METHODS \\nGenerally, data collection\u001b[0m\n",
       "\u001b[32mmethods are divided to two main categories of Primary Data Collection'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Maintaining Compliance with Data Collection Procedures: 1. Think through the process for \u001b[0m\n",
       "\u001b[32mthe collection and use of research data and prepare a standard operating procedure \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSOP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m that can be easily \u001b[0m\n",
       "\u001b[32mfollowed. Make sure this SOP addresses the following: a. Detailed methods for handling all forms of data \u001b[0m\u001b[32m(\u001b[0m\u001b[32mi.e., \u001b[0m\n",
       "\u001b[32mpaper signed consent forms, electronic Excel spreadsheets, audio recordings, etc.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m b. Storage of all forms of data \u001b[0m\n",
       "\u001b[32mincluding separate storage of data with identifiers such as master lists, \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m description of the measures that \u001b[0m\n",
       "\u001b[32mwill be taken to maintain the confidentiality of the study participant’s data in the informed consent form, \u001b[0m\n",
       "\u001b[32minformation sheet or oral consent transcript as applicable. Here are some steps you can take to de-identify \u001b[0m\n",
       "\u001b[32mresearch data: • Remove direct identifiers • Reduce precision/detail of direct and/or indirect identifiers through \u001b[0m\n",
       "\u001b[32maggregation • Instead of using date of birth use the year, decade, or date of service • Research involving \u001b[0m\n",
       "\u001b[32minterviews or focus group \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m encrypted server that is available to all Wayne State University faculty, students \u001b[0m\n",
       "\u001b[32mand staff. • Collect only the minimum data necessary for your data analysis, • If your research requires the \u001b[0m\n",
       "\u001b[32mcollection of identifiable data, then code the data as described below and store the master list in a different \u001b[0m\n",
       "\u001b[32mlocation from the coded data, o Limit the accessibility of the master list among members of the research team to \u001b[0m\n",
       "\u001b[32monly those who will need to de-code. • Recorded interviews and focus group'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Top six data collection methods: Interviews, Questionnaires and surveys, Observations, \u001b[0m\n",
       "\u001b[32mDocuments and records, Focus groups, Oral histories. 6.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'1. Observation. Observational methods focus on examining things and collecting data about\u001b[0m\n",
       "\u001b[32mthem. · 2. Survey. Survey methods focus on gathering'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'The main steps for collecting human data, based on the provided context, are:\\n\\n1. **Define the aim\u001b[0m\n",
       "\u001b[32mof your research**  \\n   - Identify exactly what you want to achieve.  \\n   - Write a problem statement describing \u001b[0m\n",
       "\u001b[32mthe practical or scientific issue you want to address and why it matters.  \\n   - Formulate clear research \u001b[0m\n",
       "\u001b[32mquestions to guide data collection.  \\n\\n2. **Choose your data collection method**  \\n   - Select an appropriate \u001b[0m\n",
       "\u001b[32mmethod based on your research questions, such as experiments, surveys, interviews, observations, focus groups, etc.\u001b[0m\n",
       "\u001b[32m\\n   - Ensure the chosen method effectively helps answer your research questions.  \\n\\n3. **Plan your data \u001b[0m\n",
       "\u001b[32mcollection procedures**  \\n   - Develop a detailed plan or standard operating procedure \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSOP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m outlining how you \u001b[0m\n",
       "\u001b[32mwill collect, handle, and store data.  \\n   - Address handling of different data forms \u001b[0m\u001b[32m(\u001b[0m\u001b[32mpaper, electronic, audio, \u001b[0m\n",
       "\u001b[32metc.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.  \\n   - Plan for maintaining confidentiality and data security \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., de-identification, encryption, \u001b[0m\n",
       "\u001b[32mrestricted access\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.  \\n\\n4. **Collect the data**  \\n   - Implement your planned data collection process following \u001b[0m\n",
       "\u001b[32mthe SOP.  \\n   - Collect only the minimum necessary data to answer your questions.  \\n   - Ensure data are \u001b[0m\n",
       "\u001b[32mcollected ethically, maintaining participant confidentiality and data integrity.  \\n\\nThese steps align with good \u001b[0m\n",
       "\u001b[32mresearch practice and ensure that human data collection is systematic, ethical, and useful for answering research \u001b[0m\n",
       "\u001b[32mquestions.'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The main steps for collecting human data, based on the provided context, are:                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Define the aim of your research</span>                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Identify exactly what you want to achieve.                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Write a problem statement describing the practical or scientific issue you want to address and why it        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>matters.                                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Formulate clear research questions to guide data collection.                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Choose your data collection method</span>                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Select an appropriate method based on your research questions, such as experiments, surveys, interviews,     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>observations, focus groups, etc.                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Ensure the chosen method effectively helps answer your research questions.                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Plan your data collection procedures</span>                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Develop a detailed plan or standard operating procedure (SOP) outlining how you will collect, handle, and    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>store data.                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Address handling of different data forms (paper, electronic, audio, etc.).                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Plan for maintaining confidentiality and data security (e.g., de-identification, encryption, restricted      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>access).                                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">Collect the data</span>                                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Implement your planned data collection process following the SOP.                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Collect only the minimum necessary data to answer your questions.                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Ensure data are collected ethically, maintaining participant confidentiality and data integrity.             \n",
       "\n",
       "These steps align with good research practice and ensure that human data collection is systematic, ethical, and    \n",
       "useful for answering research questions.                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "The main steps for collecting human data, based on the provided context, are:                                      \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mDefine the aim of your research\u001b[0m                                                                                 \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mIdentify exactly what you want to achieve.                                                                   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mWrite a problem statement describing the practical or scientific issue you want to address and why it        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mmatters.                                                                                                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mFormulate clear research questions to guide data collection.                                                 \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mChoose your data collection method\u001b[0m                                                                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mSelect an appropriate method based on your research questions, such as experiments, surveys, interviews,     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mobservations, focus groups, etc.                                                                             \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mEnsure the chosen method effectively helps answer your research questions.                                   \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mPlan your data collection procedures\u001b[0m                                                                            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mDevelop a detailed plan or standard operating procedure (SOP) outlining how you will collect, handle, and    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mstore data.                                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mAddress handling of different data forms (paper, electronic, audio, etc.).                                   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mPlan for maintaining confidentiality and data security (e.g., de-identification, encryption, restricted      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0maccess).                                                                                                     \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1mCollect the data\u001b[0m                                                                                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mImplement your planned data collection process following the SOP.                                            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mCollect only the minimum necessary data to answer your questions.                                            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mEnsure data are collected ethically, maintaining participant confidentiality and data integrity.             \n",
       "\n",
       "These steps align with good research practice and ensure that human data collection is systematic, ethical, and    \n",
       "useful for answering research questions.                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What are main steps for collecting human data?\"\n",
    "\n",
    "response = graph.invoke({\"question\": query})\n",
    "rprint(response)\n",
    "rprint(Markdown(response[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d74222a1-7085-4ecc-adc8-df307f7178e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'How does the AlphaCodium paper work?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'documents'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'375e96e9-9bdd-4118-b23c-bd132675a3b6'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Case Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is provided with a list of tool names, descriptions of their utility, and details about the expected </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'9b7dfc8c-7b4a-4a25-9892-752f5475cc97'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Effectiveness is measured by attack objective functions designed for different </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experiments:\\n- In text-to-image experiment, they used Q16 (Schramowski et al. 2022) and NudeNet </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(https://github.com/notAI-tech/NudeNet).\\n- text-to-text experiment: TOXIGEN\\nDiversity is measured by pairwise </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dissimilarity, in form of $\\\\sum_{(\\\\mathbf{x}_i, \\\\mathbf{x}_j) \\\\in \\\\text{All pairs}} [1 - </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\text{sim}(\\\\mathbf{x}_i, \\\\mathbf{x}_j)]$\\nLow-toxicity is measured by Perspective API.\\n\\n\\nScoring-LIFO: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Combine LIFO and Scoring strategies and force to update the last entry if the queue hasn’t been updated for a long </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">time.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2e721529-44bb-4ba8-b9f1-f55e8bc667e0'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 9. Average attack success rate on \"HB (harmful behavior)\" instructions, averaging 5 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">prompts. Two baselines are \"HB\" prompt only or HB prompt followed by `\"Sure here\\'s\"` as a suffix. \"Concatenation\" </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">combines several adversarial suffixes to construct a more powerful attack with a significantly higher success rate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in some cases. \"Ensemble\" tracks if any of 5 prompts and the concatenated one succeeded. (Image source: Zou et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2023)\\nARCA (“Autoregressive Randomized Coordinate Ascent”; Jones et al. 2023) considers a broader set of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">optimization problems to find input-output pairs $(\\\\mathbf{x}, \\\\mathbf{y})$ that match certain behavior pattern; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">such as non-toxic input starting with \"Barack Obama\" but leading to toxic output. Given an auditing objective </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">$\\\\phi: \\\\mathcal{X} \\\\times \\\\mathcal{Y} \\\\to \\\\mathbb{R}$ that maps a pair of (input prompt, output completion) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into scores. Examples of behavior patterns captured by $\\\\phi$ are as follows:'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'353ce5dd-accf-45c9-aa64-98025d088ecb'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">than inefficient planning in AlfWorld. (Image source: Shinn &amp; Labash, 2023)'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'grades'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocumentGrade</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chain_of_thought</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The user question asks about the workings of the AlphaCodium paper. The retrieved </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">document talks about ChemCrow, an LLM augmented with expert-designed tools for tasks in organic synthesis, drug </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discovery, and materials design. It mentions LangChain, ReAct, MRKLs, and CoT reasoning, but makes no mention of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AlphaCodium or any paper connected to it. Therefore, the document content is unrelated to the AlphaCodium paper </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question.'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_relevant</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocumentGrade</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chain_of_thought</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The user question asks about how the AlphaCodium paper works. The retrieved document </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discusses effectiveness measures and scoring strategies related to experiments in text-to-image, text-to-text, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">diversity, and low-toxicity, mentioning some tools and metrics like Q16, NudeNet, TOXIGEN, and Perspective API, as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">well as a scoring strategy called Scoring-LIFO. However, there is no mention or discussion about AlphaCodium or its</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">methodology, purpose, or experiments directly related to the AlphaCodium paper. The content does not relate to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">user's question about AlphaCodium's working mechanism.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_relevant</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocumentGrade</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chain_of_thought</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The retrieved document discusses attack success rates on harmful behavior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">instructions, mentioning techniques like concatenation and ensemble for adversarial suffixes, and a method called </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ARCA for optimization to find input-output pairs exhibiting certain behavior patterns. However, the user's question</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is about how the AlphaCodium paper works, which is not mentioned or related in the retrieved document. There is no </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information or keywords related to AlphaCodium in the retrieved document content. Therefore, the document is not </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relevant to the user's question.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_relevant</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocumentGrade</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chain_of_thought</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The user question asks about how the AlphaCodium paper works, which pertains to a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specific paper likely discussing a method or system named AlphaCodium. The retrieved document discusses experiments</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on AlfWorld Env and HotpotQA, focusing on hallucination and planning inefficiencies. There is no mention or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">semantic relation to AlphaCodium or its working principles. Hence, the document is not relevant to answering the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">user's question.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_relevant</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'is_web_search_required'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'web_search_query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'How does the AlphaCodium research paper work? Summary, methodology, and key findings of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AlphaCodium'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'6. Conclusions In this paper, we introduced AlphaCodium, a code-oriented flow that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">iteratively runs and fixes a generated code against input-output tests. The flow is divided into two main phases: a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pre-processing phase, where AlphaCodium rea-sons about the problem in natural language, and a code iter-ations </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">phase, in which AlphaCodium iterates on public and AI-generated tests. [...] In this paper, we present AlphaCodium,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a code-oriented flow that revolves around an iterative process where we re-peatedly run and fix a generated code </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">against input-output tests. Two key elements for AlphaCodium flow are (a) gen-erating additional data, such as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problem reflection and test reasoning, to aid the iterative process, and (b) enrichment of public tests with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">additional AI-generated tests. The pro-posed flow, which is depicted in Figure 1, is divided into two main phases: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a [...] In this work, we propose a new approach to code generation by LLMs, which we call AlphaCodium - a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-based, multi-stage, code-oriented iterative flow, that improves the perfor-mances of LLMs on code problems. We</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tested AlphaCodium on a challenging code generation dataset called CodeCon-tests, which includes competitive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">programming problems from platforms such as Codeforces. The proposed flow con-sistently and significantly improves </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results. On the valida-tion set, for example, GPT-4 accuracy'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AlphaCodium’s unique methodology comprises two main phases: pre-processing and code </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">iterations. In the pre-processing phase, the tool analyzes the problem, generates potential solutions, and ranks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">them based on complexity and robustness. The subsequent code iteration phase involves running on AI-generated test </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cases, iteratively fixing errors until a flawless solution emerges. The result is 12-15% higher accuracy with a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">significantly reduced computational budget. [...] K.C. Sabreena Basheer Last Updated : 23 Jan, 2024\\n2 min </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">read\\n0\\nIn the rapidly evolving landscape of artificial intelligence, CodiumAI has unveiled AlphaCodium, an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">open-source AI code-generation tool that challenges the status quo. This revolutionary approach, showcased in a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">recent arXiv paper, introduces a flow engineering method to enhance code generation accuracy by up to 44%. Let’s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">delve into the intricacies of AlphaCodium and its potential impact on the field. [...] In a landscape where </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">breakthroughs are often hailed prematurely, AlphaCodium stands out as a genuine advancement in AI code generation. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">By embracing a flow engineering approach, it goes beyond conventional prompting techniques, addressing the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limitations faced by previous models. The significance of self-reflection, additional AI tests, and a meticulous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">iterative process cannot be overstated.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'6 Conclusions\\nIn this paper, we introduced AlphaCodium, a code-oriented flow that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">iteratively runs and fixes a generated code against input-output tests. The flow is divided into two main phases: a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pre-processing phase, where AlphaCodium reasons about the problem in natural language, and a code iterations phase,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in which AlphaCodium iterates on public and AI-generated tests. [...] In this paper, we present AlphaCodium, a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">code-oriented flow that revolves around an iterative process where we repeatedly run and fix a generated code </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">against input-output tests. Two key elements for AlphaCodium flow are (a) generating additional data, such as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problem reflection and test reasoning, to aid the iterative process, and (b) enrichment of public tests with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">additional AI-generated tests. The proposed flow, which is depicted in Figure\\xa01, is divided into two main </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">phases: a [...] LLMs, which we call AlphaCodium - a test-based, multi-stage, code-oriented iterative flow, that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">improves the performances of LLMs on code problems. We tested AlphaCodium on a challenging code generation dataset </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">called CodeContests, which includes competitive programming problems from platforms such as Codeforces. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">proposed flow consistently and significantly improves results. On the validation set, for example, GPT-4 accuracy </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(pass@5) increased from 19% with a single well-designed direct'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Having a well-defined problem specification.\\nBetter understanding of the problem at </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">hand.\\nRigorous testing.\\nUtilizing a divide and conquer approach, breaking down complex code generation into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">simpler subtasks, similar to a chain of thought but tailored for the specific domain.\\n\\nThe AlphaCodium approach </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">incorporates several techniques to implement these principles, although they are not explicitly mentioned: [...] </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">They generate additional AI-generated tests to complement the existing public tests.\\n\\n\\nWith improved </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specifications, natural language solution candidates, and enhanced testing, they proceed to the final code </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generation iteration.\\n\\nThey utilize a language model to generate actual code from the solution candidates, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">running the code and addressing any errors until the tests pass or a designated limit is reached. [...] The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experiments conducted in the paper yield very convincing results. Using the proposed workflow, GPT-4 achieves a 44%</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pass@5 score for the validation set of the challenging CodeContests dataset, compared to a baseline of 19%.\\nThis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">paper highlights the fact that English (prompting) can be considered a higher-level programming language. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">proposed workflow essentially presents an effective algorithm for leveraging large language models.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The images used in this article are from the paper, the introductory slides, or were </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">created based on them.\\nProposed code generation method called AlphaCodium\\nThe content of this paper is\"Improving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the Code Generation Capability ofLLMs by a Technique Called AlphaCodium.\\nThe key points of this study are as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">follows [...] In other words, AlphaCodium, a unique code generation method, was able to improve LLM\\'s performance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in the programming area.\\nIncidentally, AlphaCodium has succeeded in significantly improving code generation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance by using generic language models (GPT, DeepSeek, etc.) without additional training and applying </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dedicated flows.\\nThis is a method that can be applied to a wide variety of language models without requiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">additional data or a computationally expensive training phase. [...] This article introduced research on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AlphaCodium, a new code generation method specifically designed for competition programming problems.\\nThis is an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">important study that demonstrates a significant improvement in LLM code generation performance.\\nThree limitations </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of this study include the following three points'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The AlphaCodium paper proposes a novel method to improve code generation by large language models </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(LLMs) through a structured, iterative workflow centered on test-based refinement. The approach is divided into two</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">main phases:\\n\\n1. **Pre-processing Phase**:  \\n   - AlphaCodium begins by thoroughly reasoning about the problem </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in natural language.  \\n   - It generates multiple potential solution candidates described in natural language and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ranks them based on criteria like complexity and robustness.  \\n   - This phase emphasizes better understanding and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problem specification, breaking down complex problems into simpler subtasks (utilizing a divide and conquer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">strategy akin to chain-of-thought reasoning but tailored for code generation).\\n\\n2. **Code Iterations Phase**:  \\n</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">- From the solution candidates, AlphaCodium uses language models to generate actual code implementations.  \\n   - </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">It runs these generated codes against *both* existing public tests and additional AI-generated test cases, which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhance coverage and test diversity.  \\n   - AlphaCodium iteratively analyzes test failures, fixes errors, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reruns the code until all tests pass or iteration limits are reached.  \\n   - This iterative testing and fixing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cycle ensures a progressively refined, more accurate solution.\\n\\n**Key elements enabling the flow to work </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectively include**:  \\n- Generating additional data such as problem reflections and test reasoning to aid </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">iterative debugging.  \\n- Enriching the test suite by adding AI-generated tests alongside public tests, increasing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the rigor and coverage of validation.  \\n- Treating natural language prompting as a higher-level programming layer,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectively guiding language models through a multi-stage iterative algorithm without additional model training.  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\n- Reducing computational cost while improving accuracy, enabling significant performance gains (e.g., improving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GPT-4’s accuracy on a competitive programming dataset from 19% to 44% pass@5).\\n\\n**In summary**, AlphaCodium works</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">by combining careful problem understanding, multi-stage code generation, and rigorous iterative testing and fixing.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This flow engineering approach transforms prompting strategies into an effective algorithmic process, significantly</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing code generation quality without extra model training or expensive computations.'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'question'\u001b[0m: \u001b[32m'How does the AlphaCodium paper work?'\u001b[0m,\n",
       "    \u001b[32m'documents'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'375e96e9-9bdd-4118-b23c-bd132675a3b6'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Case Studies#\\nScientific Discovery Agent#\\nChemCrow \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBran et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is a \u001b[0m\n",
       "\u001b[32mdomain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic \u001b[0m\n",
       "\u001b[32msynthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was \u001b[0m\n",
       "\u001b[32mpreviously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM\u001b[0m\n",
       "\u001b[32mis provided with a list of tool names, descriptions of their utility, and details about the expected \u001b[0m\n",
       "\u001b[32minput/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The \u001b[0m\n",
       "\u001b[32minstruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'9b7dfc8c-7b4a-4a25-9892-752f5475cc97'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Effectiveness is measured by attack objective functions designed for different \u001b[0m\n",
       "\u001b[32mexperiments:\\n- In text-to-image experiment, they used Q16 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSchramowski et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and NudeNet \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mhttps://github.com/notAI-tech/NudeNet\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n- text-to-text experiment: TOXIGEN\\nDiversity is measured by pairwise \u001b[0m\n",
       "\u001b[32mdissimilarity, in form of $\\\\sum_\u001b[0m\u001b[32m{\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\mathbf\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m_i, \\\\mathbf\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m_j\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\\\in \\\\text\u001b[0m\u001b[32m{\u001b[0m\u001b[32mAll pairs\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m1 - \u001b[0m\n",
       "\u001b[32m\\\\text\u001b[0m\u001b[32m{\u001b[0m\u001b[32msim\u001b[0m\u001b[32m}\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\mathbf\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m_i, \\\\mathbf\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m_j\u001b[0m\u001b[32m)\u001b[0m\u001b[32m]\u001b[0m\u001b[32m$\\nLow-toxicity is measured by Perspective API.\\n\\n\\nScoring-LIFO: \u001b[0m\n",
       "\u001b[32mCombine LIFO and Scoring strategies and force to update the last entry if the queue hasn’t been updated for a long \u001b[0m\n",
       "\u001b[32mtime.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'2e721529-44bb-4ba8-b9f1-f55e8bc667e0'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 9. Average attack success rate on \"HB \u001b[0m\u001b[32m(\u001b[0m\u001b[32mharmful behavior\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\" instructions, averaging 5 \u001b[0m\n",
       "\u001b[32mprompts. Two baselines are \"HB\" prompt only or HB prompt followed by `\"Sure here\\'s\"` as a suffix. \"Concatenation\" \u001b[0m\n",
       "\u001b[32mcombines several adversarial suffixes to construct a more powerful attack with a significantly higher success rate \u001b[0m\n",
       "\u001b[32min some cases. \"Ensemble\" tracks if any of 5 prompts and the concatenated one succeeded. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Zou et al. \u001b[0m\n",
       "\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nARCA \u001b[0m\u001b[32m(\u001b[0m\u001b[32m“Autoregressive Randomized Coordinate Ascent”; Jones et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m considers a broader set of \u001b[0m\n",
       "\u001b[32moptimization problems to find input-output pairs $\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\mathbf\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \\\\mathbf\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m$ that match certain behavior pattern; \u001b[0m\n",
       "\u001b[32msuch as non-toxic input starting with \"Barack Obama\" but leading to toxic output. Given an auditing objective \u001b[0m\n",
       "\u001b[32m$\\\\phi: \\\\mathcal\u001b[0m\u001b[32m{\u001b[0m\u001b[32mX\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\times \\\\mathcal\u001b[0m\u001b[32m{\u001b[0m\u001b[32mY\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\to \\\\mathbb\u001b[0m\u001b[32m{\u001b[0m\u001b[32mR\u001b[0m\u001b[32m}\u001b[0m\u001b[32m$ that maps a pair of \u001b[0m\u001b[32m(\u001b[0m\u001b[32minput prompt, output completion\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32minto scores. Examples of behavior patterns captured by $\\\\phi$ are as follows:'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'353ce5dd-accf-45c9-aa64-98025d088ecb'\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure \u001b[0m\n",
       "\u001b[32mthan inefficient planning in AlfWorld. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Shinn & Labash, 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'grades'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocumentGrade\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mchain_of_thought\u001b[0m=\u001b[32m'The user question asks about the workings of the AlphaCodium paper. The retrieved \u001b[0m\n",
       "\u001b[32mdocument talks about ChemCrow, an LLM augmented with expert-designed tools for tasks in organic synthesis, drug \u001b[0m\n",
       "\u001b[32mdiscovery, and materials design. It mentions LangChain, ReAct, MRKLs, and CoT reasoning, but makes no mention of \u001b[0m\n",
       "\u001b[32mAlphaCodium or any paper connected to it. Therefore, the document content is unrelated to the AlphaCodium paper \u001b[0m\n",
       "\u001b[32mquestion.'\u001b[0m,\n",
       "            \u001b[33mis_relevant\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocumentGrade\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mchain_of_thought\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m user question asks about how the AlphaCodium paper works. The retrieved document \u001b[0m\n",
       "\u001b[32mdiscusses effectiveness measures and scoring strategies related to experiments in text-to-image, text-to-text, \u001b[0m\n",
       "\u001b[32mdiversity, and low-toxicity, mentioning some tools and metrics like Q16, NudeNet, TOXIGEN, and Perspective API, as \u001b[0m\n",
       "\u001b[32mwell as a scoring strategy called Scoring-LIFO. However, there is no mention or discussion about AlphaCodium or its\u001b[0m\n",
       "\u001b[32mmethodology, purpose, or experiments directly related to the AlphaCodium paper. The content does not relate to the \u001b[0m\n",
       "\u001b[32muser's question about AlphaCodium's working mechanism.\"\u001b[0m,\n",
       "            \u001b[33mis_relevant\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocumentGrade\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mchain_of_thought\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m retrieved document discusses attack success rates on harmful behavior \u001b[0m\n",
       "\u001b[32minstructions, mentioning techniques like concatenation and ensemble for adversarial suffixes, and a method called \u001b[0m\n",
       "\u001b[32mARCA for optimization to find input-output pairs exhibiting certain behavior patterns. However, the user's question\u001b[0m\n",
       "\u001b[32mis about how the AlphaCodium paper works, which is not mentioned or related in the retrieved document. There is no \u001b[0m\n",
       "\u001b[32minformation or keywords related to AlphaCodium in the retrieved document content. Therefore, the document is not \u001b[0m\n",
       "\u001b[32mrelevant to the user's question.\"\u001b[0m,\n",
       "            \u001b[33mis_relevant\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocumentGrade\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mchain_of_thought\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m user question asks about how the AlphaCodium paper works, which pertains to a \u001b[0m\n",
       "\u001b[32mspecific paper likely discussing a method or system named AlphaCodium. The retrieved document discusses experiments\u001b[0m\n",
       "\u001b[32mon AlfWorld Env and HotpotQA, focusing on hallucination and planning inefficiencies. There is no mention or \u001b[0m\n",
       "\u001b[32msemantic relation to AlphaCodium or its working principles. Hence, the document is not relevant to answering the \u001b[0m\n",
       "\u001b[32muser's question.\"\u001b[0m,\n",
       "            \u001b[33mis_relevant\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'is_web_search_required'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'web_search_query'\u001b[0m: \u001b[32m'How does the AlphaCodium research paper work? Summary, methodology, and key findings of \u001b[0m\n",
       "\u001b[32mAlphaCodium'\u001b[0m,\n",
       "    \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'6. Conclusions In this paper, we introduced AlphaCodium, a code-oriented flow that \u001b[0m\n",
       "\u001b[32miteratively runs and fixes a generated code against input-output tests. The flow is divided into two main phases: a\u001b[0m\n",
       "\u001b[32mpre-processing phase, where AlphaCodium rea-sons about the problem in natural language, and a code iter-ations \u001b[0m\n",
       "\u001b[32mphase, in which AlphaCodium iterates on public and AI-generated tests. \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In this paper, we present AlphaCodium,\u001b[0m\n",
       "\u001b[32ma code-oriented flow that revolves around an iterative process where we re-peatedly run and fix a generated code \u001b[0m\n",
       "\u001b[32magainst input-output tests. Two key elements for AlphaCodium flow are \u001b[0m\u001b[32m(\u001b[0m\u001b[32ma\u001b[0m\u001b[32m)\u001b[0m\u001b[32m gen-erating additional data, such as \u001b[0m\n",
       "\u001b[32mproblem reflection and test reasoning, to aid the iterative process, and \u001b[0m\u001b[32m(\u001b[0m\u001b[32mb\u001b[0m\u001b[32m)\u001b[0m\u001b[32m enrichment of public tests with \u001b[0m\n",
       "\u001b[32madditional AI-generated tests. The pro-posed flow, which is depicted in Figure 1, is divided into two main phases: \u001b[0m\n",
       "\u001b[32ma \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In this work, we propose a new approach to code generation by LLMs, which we call AlphaCodium - a \u001b[0m\n",
       "\u001b[32mtest-based, multi-stage, code-oriented iterative flow, that improves the perfor-mances of LLMs on code problems. We\u001b[0m\n",
       "\u001b[32mtested AlphaCodium on a challenging code generation dataset called CodeCon-tests, which includes competitive \u001b[0m\n",
       "\u001b[32mprogramming problems from platforms such as Codeforces. The proposed flow con-sistently and significantly improves \u001b[0m\n",
       "\u001b[32mresults. On the valida-tion set, for example, GPT-4 accuracy'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'AlphaCodium’s unique methodology comprises two main phases: pre-processing and code \u001b[0m\n",
       "\u001b[32miterations. In the pre-processing phase, the tool analyzes the problem, generates potential solutions, and ranks \u001b[0m\n",
       "\u001b[32mthem based on complexity and robustness. The subsequent code iteration phase involves running on AI-generated test \u001b[0m\n",
       "\u001b[32mcases, iteratively fixing errors until a flawless solution emerges. The result is 12-15% higher accuracy with a \u001b[0m\n",
       "\u001b[32msignificantly reduced computational budget. \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m K.C. Sabreena Basheer Last Updated : 23 Jan, 2024\\n2 min \u001b[0m\n",
       "\u001b[32mread\\n0\\nIn the rapidly evolving landscape of artificial intelligence, CodiumAI has unveiled AlphaCodium, an \u001b[0m\n",
       "\u001b[32mopen-source AI code-generation tool that challenges the status quo. This revolutionary approach, showcased in a \u001b[0m\n",
       "\u001b[32mrecent arXiv paper, introduces a flow engineering method to enhance code generation accuracy by up to 44%. Let’s \u001b[0m\n",
       "\u001b[32mdelve into the intricacies of AlphaCodium and its potential impact on the field. \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In a landscape where \u001b[0m\n",
       "\u001b[32mbreakthroughs are often hailed prematurely, AlphaCodium stands out as a genuine advancement in AI code generation. \u001b[0m\n",
       "\u001b[32mBy embracing a flow engineering approach, it goes beyond conventional prompting techniques, addressing the \u001b[0m\n",
       "\u001b[32mlimitations faced by previous models. The significance of self-reflection, additional AI tests, and a meticulous \u001b[0m\n",
       "\u001b[32miterative process cannot be overstated.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'6 Conclusions\\nIn this paper, we introduced AlphaCodium, a code-oriented flow that \u001b[0m\n",
       "\u001b[32miteratively runs and fixes a generated code against input-output tests. The flow is divided into two main phases: a\u001b[0m\n",
       "\u001b[32mpre-processing phase, where AlphaCodium reasons about the problem in natural language, and a code iterations phase,\u001b[0m\n",
       "\u001b[32min which AlphaCodium iterates on public and AI-generated tests. \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In this paper, we present AlphaCodium, a \u001b[0m\n",
       "\u001b[32mcode-oriented flow that revolves around an iterative process where we repeatedly run and fix a generated code \u001b[0m\n",
       "\u001b[32magainst input-output tests. Two key elements for AlphaCodium flow are \u001b[0m\u001b[32m(\u001b[0m\u001b[32ma\u001b[0m\u001b[32m)\u001b[0m\u001b[32m generating additional data, such as \u001b[0m\n",
       "\u001b[32mproblem reflection and test reasoning, to aid the iterative process, and \u001b[0m\u001b[32m(\u001b[0m\u001b[32mb\u001b[0m\u001b[32m)\u001b[0m\u001b[32m enrichment of public tests with \u001b[0m\n",
       "\u001b[32madditional AI-generated tests. The proposed flow, which is depicted in Figure\\xa01, is divided into two main \u001b[0m\n",
       "\u001b[32mphases: a \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m LLMs, which we call AlphaCodium - a test-based, multi-stage, code-oriented iterative flow, that \u001b[0m\n",
       "\u001b[32mimproves the performances of LLMs on code problems. We tested AlphaCodium on a challenging code generation dataset \u001b[0m\n",
       "\u001b[32mcalled CodeContests, which includes competitive programming problems from platforms such as Codeforces. The \u001b[0m\n",
       "\u001b[32mproposed flow consistently and significantly improves results. On the validation set, for example, GPT-4 accuracy \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mpass@5\u001b[0m\u001b[32m)\u001b[0m\u001b[32m increased from 19% with a single well-designed direct'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Having a well-defined problem specification.\\nBetter understanding of the problem at \u001b[0m\n",
       "\u001b[32mhand.\\nRigorous testing.\\nUtilizing a divide and conquer approach, breaking down complex code generation into \u001b[0m\n",
       "\u001b[32msimpler subtasks, similar to a chain of thought but tailored for the specific domain.\\n\\nThe AlphaCodium approach \u001b[0m\n",
       "\u001b[32mincorporates several techniques to implement these principles, although they are not explicitly mentioned: \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mThey generate additional AI-generated tests to complement the existing public tests.\\n\\n\\nWith improved \u001b[0m\n",
       "\u001b[32mspecifications, natural language solution candidates, and enhanced testing, they proceed to the final code \u001b[0m\n",
       "\u001b[32mgeneration iteration.\\n\\nThey utilize a language model to generate actual code from the solution candidates, \u001b[0m\n",
       "\u001b[32mrunning the code and addressing any errors until the tests pass or a designated limit is reached. \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m The \u001b[0m\n",
       "\u001b[32mexperiments conducted in the paper yield very convincing results. Using the proposed workflow, GPT-4 achieves a 44%\u001b[0m\n",
       "\u001b[32mpass@5 score for the validation set of the challenging CodeContests dataset, compared to a baseline of 19%.\\nThis \u001b[0m\n",
       "\u001b[32mpaper highlights the fact that English \u001b[0m\u001b[32m(\u001b[0m\u001b[32mprompting\u001b[0m\u001b[32m)\u001b[0m\u001b[32m can be considered a higher-level programming language. The \u001b[0m\n",
       "\u001b[32mproposed workflow essentially presents an effective algorithm for leveraging large language models.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'The images used in this article are from the paper, the introductory slides, or were \u001b[0m\n",
       "\u001b[32mcreated based on them.\\nProposed code generation method called AlphaCodium\\nThe content of this paper is\"Improving \u001b[0m\n",
       "\u001b[32mthe Code Generation Capability ofLLMs by a Technique Called AlphaCodium.\\nThe key points of this study are as \u001b[0m\n",
       "\u001b[32mfollows \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In other words, AlphaCodium, a unique code generation method, was able to improve LLM\\'s performance \u001b[0m\n",
       "\u001b[32min the programming area.\\nIncidentally, AlphaCodium has succeeded in significantly improving code generation \u001b[0m\n",
       "\u001b[32mperformance by using generic language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGPT, DeepSeek, etc.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m without additional training and applying \u001b[0m\n",
       "\u001b[32mdedicated flows.\\nThis is a method that can be applied to a wide variety of language models without requiring \u001b[0m\n",
       "\u001b[32madditional data or a computationally expensive training phase. \u001b[0m\u001b[32m[\u001b[0m\u001b[32m...\u001b[0m\u001b[32m]\u001b[0m\u001b[32m This article introduced research on \u001b[0m\n",
       "\u001b[32mAlphaCodium, a new code generation method specifically designed for competition programming problems.\\nThis is an \u001b[0m\n",
       "\u001b[32mimportant study that demonstrates a significant improvement in LLM code generation performance.\\nThree limitations \u001b[0m\n",
       "\u001b[32mof this study include the following three points'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'The AlphaCodium paper proposes a novel method to improve code generation by large language models \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m through a structured, iterative workflow centered on test-based refinement. The approach is divided into two\u001b[0m\n",
       "\u001b[32mmain phases:\\n\\n1. **Pre-processing Phase**:  \\n   - AlphaCodium begins by thoroughly reasoning about the problem \u001b[0m\n",
       "\u001b[32min natural language.  \\n   - It generates multiple potential solution candidates described in natural language and \u001b[0m\n",
       "\u001b[32mranks them based on criteria like complexity and robustness.  \\n   - This phase emphasizes better understanding and\u001b[0m\n",
       "\u001b[32mproblem specification, breaking down complex problems into simpler subtasks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mutilizing a divide and conquer \u001b[0m\n",
       "\u001b[32mstrategy akin to chain-of-thought reasoning but tailored for code generation\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\n2. **Code Iterations Phase**:  \\n\u001b[0m\n",
       "\u001b[32m- From the solution candidates, AlphaCodium uses language models to generate actual code implementations.  \\n   - \u001b[0m\n",
       "\u001b[32mIt runs these generated codes against *both* existing public tests and additional AI-generated test cases, which \u001b[0m\n",
       "\u001b[32menhance coverage and test diversity.  \\n   - AlphaCodium iteratively analyzes test failures, fixes errors, and \u001b[0m\n",
       "\u001b[32mreruns the code until all tests pass or iteration limits are reached.  \\n   - This iterative testing and fixing \u001b[0m\n",
       "\u001b[32mcycle ensures a progressively refined, more accurate solution.\\n\\n**Key elements enabling the flow to work \u001b[0m\n",
       "\u001b[32meffectively include**:  \\n- Generating additional data such as problem reflections and test reasoning to aid \u001b[0m\n",
       "\u001b[32miterative debugging.  \\n- Enriching the test suite by adding AI-generated tests alongside public tests, increasing \u001b[0m\n",
       "\u001b[32mthe rigor and coverage of validation.  \\n- Treating natural language prompting as a higher-level programming layer,\u001b[0m\n",
       "\u001b[32meffectively guiding language models through a multi-stage iterative algorithm without additional model training.  \u001b[0m\n",
       "\u001b[32m\\n- Reducing computational cost while improving accuracy, enabling significant performance gains \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., improving \u001b[0m\n",
       "\u001b[32mGPT-4’s accuracy on a competitive programming dataset from 19% to 44% pass@5\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\n**In summary**, AlphaCodium works\u001b[0m\n",
       "\u001b[32mby combining careful problem understanding, multi-stage code generation, and rigorous iterative testing and fixing.\u001b[0m\n",
       "\u001b[32mThis flow engineering approach transforms prompting strategies into an effective algorithmic process, significantly\u001b[0m\n",
       "\u001b[32menhancing code generation quality without extra model training or expensive computations.'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The AlphaCodium paper proposes a novel method to improve code generation by large language models (LLMs) through a \n",
       "structured, iterative workflow centered on test-based refinement. The approach is divided into two main phases:    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Pre-processing Phase</span>:                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>AlphaCodium begins by thoroughly reasoning about the problem in natural language.                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>It generates multiple potential solution candidates described in natural language and ranks them based on    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>criteria like complexity and robustness.                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>This phase emphasizes better understanding and problem specification, breaking down complex problems into    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>simpler subtasks (utilizing a divide and conquer strategy akin to chain-of-thought reasoning but tailored for\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>code generation).                                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Code Iterations Phase</span>:                                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>From the solution candidates, AlphaCodium uses language models to generate actual code implementations.      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>It runs these generated codes against <span style=\"font-style: italic\">both</span> existing public tests and additional AI-generated test cases,     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>which enhance coverage and test diversity.                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>AlphaCodium iteratively analyzes test failures, fixes errors, and reruns the code until all tests pass or    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>iteration limits are reached.                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>This iterative testing and fixing cycle ensures a progressively refined, more accurate solution.             \n",
       "\n",
       "<span style=\"font-weight: bold\">Key elements enabling the flow to work effectively include</span>:                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Generating additional data such as problem reflections and test reasoning to aid iterative debugging.           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Enriching the test suite by adding AI-generated tests alongside public tests, increasing the rigor and coverage \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>of validation.                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Treating natural language prompting as a higher-level programming layer, effectively guiding language models    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>through a multi-stage iterative algorithm without additional model training.                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Reducing computational cost while improving accuracy, enabling significant performance gains (e.g., improving   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>GPT-4’s accuracy on a competitive programming dataset from 19% to 44% pass@5).                                  \n",
       "\n",
       "<span style=\"font-weight: bold\">In summary</span>, AlphaCodium works by combining careful problem understanding, multi-stage code generation, and rigorous\n",
       "iterative testing and fixing. This flow engineering approach transforms prompting strategies into an effective     \n",
       "algorithmic process, significantly enhancing code generation quality without extra model training or expensive     \n",
       "computations.                                                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "The AlphaCodium paper proposes a novel method to improve code generation by large language models (LLMs) through a \n",
       "structured, iterative workflow centered on test-based refinement. The approach is divided into two main phases:    \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mPre-processing Phase\u001b[0m:                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mAlphaCodium begins by thoroughly reasoning about the problem in natural language.                            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mIt generates multiple potential solution candidates described in natural language and ranks them based on    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mcriteria like complexity and robustness.                                                                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mThis phase emphasizes better understanding and problem specification, breaking down complex problems into    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0msimpler subtasks (utilizing a divide and conquer strategy akin to chain-of-thought reasoning but tailored for\n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mcode generation).                                                                                            \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mCode Iterations Phase\u001b[0m:                                                                                          \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mFrom the solution candidates, AlphaCodium uses language models to generate actual code implementations.      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mIt runs these generated codes against \u001b[3mboth\u001b[0m existing public tests and additional AI-generated test cases,     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mwhich enhance coverage and test diversity.                                                                   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mAlphaCodium iteratively analyzes test failures, fixes errors, and reruns the code until all tests pass or    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0miteration limits are reached.                                                                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mThis iterative testing and fixing cycle ensures a progressively refined, more accurate solution.             \n",
       "\n",
       "\u001b[1mKey elements enabling the flow to work effectively include\u001b[0m:                                                        \n",
       "\n",
       "\u001b[1;33m • \u001b[0mGenerating additional data such as problem reflections and test reasoning to aid iterative debugging.           \n",
       "\u001b[1;33m • \u001b[0mEnriching the test suite by adding AI-generated tests alongside public tests, increasing the rigor and coverage \n",
       "\u001b[1;33m   \u001b[0mof validation.                                                                                                  \n",
       "\u001b[1;33m • \u001b[0mTreating natural language prompting as a higher-level programming layer, effectively guiding language models    \n",
       "\u001b[1;33m   \u001b[0mthrough a multi-stage iterative algorithm without additional model training.                                    \n",
       "\u001b[1;33m • \u001b[0mReducing computational cost while improving accuracy, enabling significant performance gains (e.g., improving   \n",
       "\u001b[1;33m   \u001b[0mGPT-4’s accuracy on a competitive programming dataset from 19% to 44% pass@5).                                  \n",
       "\n",
       "\u001b[1mIn summary\u001b[0m, AlphaCodium works by combining careful problem understanding, multi-stage code generation, and rigorous\n",
       "iterative testing and fixing. This flow engineering approach transforms prompting strategies into an effective     \n",
       "algorithmic process, significantly enhancing code generation quality without extra model training or expensive     \n",
       "computations.                                                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"How does the AlphaCodium paper work?\"\n",
    "\n",
    "response = graph.invoke({\"question\": query})\n",
    "rprint(response)\n",
    "rprint(Markdown(response[\"answer\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
