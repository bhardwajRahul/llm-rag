{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9185900c-873b-40c8-a671-bdf5e6c6e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from IPython.display import display\n",
    "from rich import print as rprint\n",
    "from rich.markdown import Markdown\n",
    "from rich.pretty import Pretty\n",
    "from rich.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0309a6a1-b78c-477b-9d29-a7f17b05618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2576e0c-f570-4a57-a0f5-df782bf9daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG From Scratch: Part 7-1 (Query Translation - Decomposition (Recursive))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063500a-216e-4dbe-9b45-3e6aae8442b1",
   "metadata": {},
   "source": [
    "# Query translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674c047-61f4-419d-a017-1470e251914f",
   "metadata": {},
   "source": [
    "![](images/query-translation-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2860bf1a-57f6-427b-9977-7604a3685902",
   "metadata": {},
   "source": [
    "![](images/query-translation-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989a6c3d-e97c-496d-b583-88e72baeb4c3",
   "metadata": {},
   "source": [
    "# Part 7-1: Decomposition (Recursive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31247214-b065-4d17-a986-c8240376a110",
   "metadata": {},
   "source": [
    "![](images/07-01-decomposition-recursive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800589d2-7c6e-4aac-a83a-f0ec36049cb6",
   "metadata": {},
   "source": [
    "## Configure components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f553f7a7-3ff3-4197-80a5-cfdf604a9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f86ab48-b98f-4543-a6c6-4c972b84b152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3267753c5d', 'finish_reason': 'stop', 'logprobs': None}, id='run-55a3f578-0e30-41aa-bc53-e209bf82179e-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1\n",
    ")\n",
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7dc8587-e9c0-4b5e-944c-72e7d267b4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "len(embeddings.embed_query(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bc159-dede-4260-b2ff-100990d63dbb",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc65ba7f-09c3-4c99-9a49-2a2f6cb7ef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd74a494-1b65-489c-a370-7e41049b8be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3111212-eab1-4691-ad6f-c7f6ea632155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b9af7-a2f9-45b8-854c-410b8c4e67bc",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1955089c-5fa3-43a2-a16e-3e0682fae53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aa35b9e-5bd5-423b-b17d-38bd60aa9060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49e5f6a-3722-47c4-be2e-69601f16f637",
   "metadata": {},
   "source": [
    "## Store documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f1600ad-ae95-4e1d-8cee-d7ce8a977d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f672034b-b010-4b4b-aae9-583a87c45803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = InMemoryVectorStore(embeddings)\n",
    "doc_ids = vectorstore.add_documents(documents=splits)\n",
    "len(doc_ids), len(vectorstore.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf4fa9a1-71a5-42d1-8070-8e2a4953af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839bda8b-7070-443c-afbc-1eab80ad5300",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "277799eb-70ca-4d70-b93b-ac62ee4c62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a77538-ddbe-4202-8e50-6184996df3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant that generates multiple sub-questions related to an input question.\n",
      "The goal is to break down the input into a set of sub-problems / sub-questions that can be answered sequentially.\n",
      "Generate multiple search queries related to: {question}\n"
     ]
    }
   ],
   "source": [
    "decomposition_prompt_template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question.\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answered sequentially.\n",
    "Generate multiple search queries related to: {question}\"\"\"\n",
    "print(decomposition_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6e05179-def7-4723-9215-ba6ef4dd65a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the question you need to answer:\n",
      "<question>\n",
      "{question}\n",
      "</question>\n",
      "\n",
      "Here are any available background question + answer pairs:\n",
      "<question_answer_pairs>\n",
      "{qa_pairs}\n",
      "</question_answer_pairs>\n",
      "\n",
      "Here is additional context relevant to the question: \n",
      "<context>\n",
      "{context}\n",
      "</context>\n",
      "\n",
      "Use the above context and any background question + answer pairs to answer the question:\n",
      "<question>\n",
      "{question}\n",
      "</question>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recursive_prompt_template = \"\"\"Here is the question you need to answer:\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Here are any available background question + answer pairs:\n",
    "<question_answer_pairs>\n",
    "{qa_pairs}\n",
    "</question_answer_pairs>\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question:\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\"\"\"\n",
    "print(recursive_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ef22081-7982-419b-80ed-16c3ca2b3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_pair(question, answer):\n",
    "    return f\"Question: {question}  \\nAnswer:\\n{answer}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf754a56-99a7-4d87-bf7b-99f425305284",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the main components of an LLM-powered autonomous agent system?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78609718-3a1a-4f11-b063-52ed7f695a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    all_questions: list[str]\n",
    "    current_question_idx: int\n",
    "    qa_pairs: list[str]\n",
    "    context: list[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8545d97-c61b-48bd-9659-09870773bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sub_questions(state: State, config: RunnableConfig) -> list[str]:\n",
    "    max_generated_sub_questions_count = config['configurable'].get(\"max_generated_sub_questions_count\", 3)\n",
    "    query = state['question']\n",
    "    \n",
    "    class SubQuestionsGenerator(BaseModel):\n",
    "        sub_questions: list[str] = Field(\n",
    "            ..., \n",
    "            description=\"List of generated sub-problems / sub-questions\",\n",
    "            max_items=max_generated_sub_questions_count\n",
    "        )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(SubQuestionsGenerator, method=\"function_calling\")\n",
    "    decomposition_prompt = decomposition_prompt_template.format(\n",
    "        question=query\n",
    "    )\n",
    "    response = structured_llm.invoke([\n",
    "        HumanMessage(content=decomposition_prompt)\n",
    "    ])\n",
    "    questions = response.sub_questions + [query]\n",
    "    \n",
    "    return {\"all_questions\": questions, \"current_question_idx\": 0}\n",
    "\n",
    "\n",
    "def retrieve_docs(state: State):\n",
    "    question = state[\"all_questions\"][state[\"current_question_idx\"]]\n",
    "    retrieved_docs = vectorstore.similarity_search(question)\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    question = state[\"all_questions\"][state[\"current_question_idx\"]]\n",
    "    recursive_prompt = recursive_prompt_template.format(\n",
    "        question=question,\n",
    "        qa_pairs=state.get(\"qa_pairs\", \"\"),\n",
    "        context=state[\"context\"]\n",
    "    )\n",
    "    answer = llm.invoke([\n",
    "        HumanMessage(content=recursive_prompt)\n",
    "    ])\n",
    "    qa_pair = format_qa_pair(question, answer.content)\n",
    "    qa_pairs = state.get(\"qa_pairs\", \"\") + qa_pair\n",
    "\n",
    "    if state[\"current_question_idx\"] == len(state['all_questions']) - 1:\n",
    "        return {\"answer\": answer.content}\n",
    "    else:\n",
    "        return {\"qa_pairs\": qa_pairs, \"current_question_idx\": state[\"current_question_idx\"] + 1}\n",
    "\n",
    "\n",
    "def check_answer_status(state: State) -> Literal[\"Next sub-question\", \"Final answer\"]:\n",
    "    if state.get(\"answer\"):\n",
    "        return \"Final answer\"\n",
    "    else:\n",
    "        return \"Next sub-question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f60d3431-881f-4c8e-b1e5-f1dbc827ff78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7f8106b54990>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"generate_sub_questions\", generate_sub_questions)\n",
    "graph_builder.add_node(\"retrieve_docs\", retrieve_docs)\n",
    "graph_builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "graph_builder.add_edge(START, \"generate_sub_questions\")\n",
    "graph_builder.add_edge(\"generate_sub_questions\", \"retrieve_docs\")\n",
    "graph_builder.add_edge(\"retrieve_docs\", \"generate_answer\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"generate_answer\", \n",
    "    check_answer_status, \n",
    "    {\n",
    "        \"Next sub-question\": \"retrieve_docs\",\n",
    "        \"Final answer\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "822a2d07-f777-45f6-ab99-15ea783f9319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_sub_questions'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'all_questions'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What is a large language model (LLM) and how does it function?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What are the essential components required for building an autonomous agent system?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'How do LLMs integrate with other technologies in an autonomous system?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What are the main components of an LLM-powered autonomous agent system?'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'current_question_idx'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_sub_questions'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'all_questions'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'What is a large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and how does it function?'\u001b[0m,\n",
       "            \u001b[32m'What are the essential components required for building an autonomous agent system?'\u001b[0m,\n",
       "            \u001b[32m'How do LLMs integrate with other technologies in an autonomous system?'\u001b[0m,\n",
       "            \u001b[32m'What are the main components of an LLM-powered autonomous agent system?'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'current_question_idx'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve_docs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'722e6b6b-580c-4ac0-9e9c-9377b0d6914f'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1b77dabd-3592-4f6d-b49d-f8f5e3dc85bf'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'(4) Response generation: LLM receives the execution results and provides summarized </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outputs and external model services.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'3b61645a-2b61-420b-bd43-6aeac6004146'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'They did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details in the “External APIs” section of Prompt Engineering.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'8c6aba8b-17dc-44df-b269-f2de039f9e2b'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language as an interface between LLMs and external components such as memory and tools. However, the reliability of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve_docs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'722e6b6b-580c-4ac0-9e9c-9377b0d6914f'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: \u001b[0m\n",
       "\u001b[32m31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a \u001b[0m\n",
       "\u001b[32mcool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'1b77dabd-3592-4f6d-b49d-f8f5e3dc85bf'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m(\u001b[0m\u001b[32m4\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Response generation: LLM receives the execution results and provides summarized \u001b[0m\n",
       "\u001b[32mresults to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Efficiency \u001b[0m\n",
       "\u001b[32mimprovement is needed as both LLM inference rounds and interactions with other models slow down the process; \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m It\u001b[0m\n",
       "\u001b[32mrelies on a long context window to communicate over complicated task content; \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Stability improvement of LLM \u001b[0m\n",
       "\u001b[32moutputs and external model services.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'3b61645a-2b61-420b-bd43-6aeac6004146'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'They did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a\u001b[0m\n",
       "\u001b[32mtest case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math \u001b[0m\n",
       "\u001b[32mproblems because LLMs \u001b[0m\u001b[32m(\u001b[0m\u001b[32m7B Jurassic1-large model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m failed to extract the right arguments for the basic arithmetic \u001b[0m\n",
       "\u001b[32mreliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use \u001b[0m\n",
       "\u001b[32mthe tools are crucial, determined by the LLM capability.\\nBoth TALM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mTool Augmented Language Models; Parisi et al. \u001b[0m\n",
       "\u001b[32m2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and Toolformer \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSchick et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m fine-tune a LM to learn to use external tool APIs. The dataset is \u001b[0m\n",
       "\u001b[32mexpanded based on whether a newly added API call annotation can improve the quality of model outputs. See more \u001b[0m\n",
       "\u001b[32mdetails in the “External APIs” section of Prompt Engineering.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'8c6aba8b-17dc-44df-b269-f2de039f9e2b'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural \u001b[0m\n",
       "\u001b[32mlanguage as an interface between LLMs and external components such as memory and tools. However, the reliability of\u001b[0m\n",
       "\u001b[32mmodel outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. refuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LLM) is an advanced artificial intelligence system designed to understand and generate human-like text based on the input it receives. It functions by utilizing deep learning techniques, particularly neural networks, to analyze vast amounts of text data, which allows it to learn language patterns, grammar, facts, and various forms of knowledge. \n",
      "\n",
      "LLMs operate on the principles of probabilistic modeling, where they calculate the probability of a word or phrase occurring in a given context and generate responses accordingly. They are often used in various applications such as text generation, translation, summarization, and even problem-solving tasks.\n",
      "\n",
      "In an LLM-powered autonomous agent system, the LLM acts as the core controller or \"brain\" of the agent. It is complemented by several key components, including:\n",
      "\n",
      "1. **Planning**: The LLM can break down large tasks into smaller, manageable subgoals, allowing it to tackle complex tasks more efficiently.\n",
      "   \n",
      "2. **Reflection and Refinement**: The model has the capability for self-criticism and reflection, enabling it to learn from past actions and improve future outputs.\n",
      "\n",
      "3. **Response Generation**: After performing tasks, the LLM summarizes the execution results for the user, facilitating clear communication of outcomes.\n",
      "\n",
      "Despite their capabilities, LLMs face challenges, such as ensuring reliability in their outputs and effectively managing interactions with external tools and APIs. Issues like formatting errors and inconsistent behavior can arise, necessitating careful design of the systems that incorporate these models. Overall, LLMs represent a powerful computational tool for various natural language processing tasks and beyond."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_answer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'qa_pairs'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Question: What is a large language model (LLM) and how does it function?  \\nAnswer:\\nA large </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language model (LLM) is an advanced artificial intelligence system designed to understand and generate human-like </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">text based on the input it receives. It functions by utilizing deep learning techniques, particularly neural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">networks, to analyze vast amounts of text data, which allows it to learn language patterns, grammar, facts, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">various forms of knowledge. \\n\\nLLMs operate on the principles of probabilistic modeling, where they calculate the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">probability of a word or phrase occurring in a given context and generate responses accordingly. They are often </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">used in various applications such as text generation, translation, summarization, and even problem-solving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\n\\nIn an LLM-powered autonomous agent system, the LLM acts as the core controller or \"brain\" of the agent. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">It is complemented by several key components, including:\\n\\n1. **Planning**: The LLM can break down large tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into smaller, manageable subgoals, allowing it to tackle complex tasks more efficiently.\\n   \\n2. **Reflection and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Refinement**: The model has the capability for self-criticism and reflection, enabling it to learn from past </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">actions and improve future outputs.\\n\\n3. **Response Generation**: After performing tasks, the LLM summarizes the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">execution results for the user, facilitating clear communication of outcomes.\\n\\nDespite their capabilities, LLMs </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">face challenges, such as ensuring reliability in their outputs and effectively managing interactions with external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tools and APIs. Issues like formatting errors and inconsistent behavior can arise, necessitating careful design of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the systems that incorporate these models. Overall, LLMs represent a powerful computational tool for various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">natural language processing tasks and beyond.\\n\\n'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'current_question_idx'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_answer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'qa_pairs'\u001b[0m: \u001b[32m'Question: What is a large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and how does it function?  \\nAnswer:\\nA large \u001b[0m\n",
       "\u001b[32mlanguage model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is an advanced artificial intelligence system designed to understand and generate human-like \u001b[0m\n",
       "\u001b[32mtext based on the input it receives. It functions by utilizing deep learning techniques, particularly neural \u001b[0m\n",
       "\u001b[32mnetworks, to analyze vast amounts of text data, which allows it to learn language patterns, grammar, facts, and \u001b[0m\n",
       "\u001b[32mvarious forms of knowledge. \\n\\nLLMs operate on the principles of probabilistic modeling, where they calculate the \u001b[0m\n",
       "\u001b[32mprobability of a word or phrase occurring in a given context and generate responses accordingly. They are often \u001b[0m\n",
       "\u001b[32mused in various applications such as text generation, translation, summarization, and even problem-solving \u001b[0m\n",
       "\u001b[32mtasks.\\n\\nIn an LLM-powered autonomous agent system, the LLM acts as the core controller or \"brain\" of the agent. \u001b[0m\n",
       "\u001b[32mIt is complemented by several key components, including:\\n\\n1. **Planning**: The LLM can break down large tasks \u001b[0m\n",
       "\u001b[32minto smaller, manageable subgoals, allowing it to tackle complex tasks more efficiently.\\n   \\n2. **Reflection and \u001b[0m\n",
       "\u001b[32mRefinement**: The model has the capability for self-criticism and reflection, enabling it to learn from past \u001b[0m\n",
       "\u001b[32mactions and improve future outputs.\\n\\n3. **Response Generation**: After performing tasks, the LLM summarizes the \u001b[0m\n",
       "\u001b[32mexecution results for the user, facilitating clear communication of outcomes.\\n\\nDespite their capabilities, LLMs \u001b[0m\n",
       "\u001b[32mface challenges, such as ensuring reliability in their outputs and effectively managing interactions with external \u001b[0m\n",
       "\u001b[32mtools and APIs. Issues like formatting errors and inconsistent behavior can arise, necessitating careful design of \u001b[0m\n",
       "\u001b[32mthe systems that incorporate these models. Overall, LLMs represent a powerful computational tool for various \u001b[0m\n",
       "\u001b[32mnatural language processing tasks and beyond.\\n\\n'\u001b[0m,\n",
       "        \u001b[32m'current_question_idx'\u001b[0m: \u001b[1;36m1\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve_docs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'c8dba136-1894-422b-990e-9e2ffd92fb9c'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'5302075d-9342-43b9-936e-4db7b2c4423f'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'722e6b6b-580c-4ac0-9e9c-9377b0d6914f'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'c2912f4c-7160-4374-81f0-fc7258c6f5eb'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents, I start to see a couple common limitations:'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve_docs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'c8dba136-1894-422b-990e-9e2ffd92fb9c'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'5302075d-9342-43b9-936e-4db7b2c4423f'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 13. The generative agent architecture. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Park et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThis \u001b[0m\n",
       "\u001b[32mfun simulation results in emergent social behavior, such as information diffusion, relationship memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. two \u001b[0m\n",
       "\u001b[32magents continuing the conversation topic\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and coordination of social events \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. host a party and invite many \u001b[0m\n",
       "\u001b[32mothers\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up \u001b[0m\n",
       "\u001b[32mautonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural \u001b[0m\n",
       "\u001b[32mlanguage interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format \u001b[0m\n",
       "\u001b[32mparsing.\\nHere is the system message used by AutoGPT, where \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m...\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m are user inputs:\\nYou are \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mai-name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser-provided AI bot description\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.\\nYour decisions must always be made independently without seeking user \u001b[0m\n",
       "\u001b[32massistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'722e6b6b-580c-4ac0-9e9c-9377b0d6914f'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: \u001b[0m\n",
       "\u001b[32m31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a \u001b[0m\n",
       "\u001b[32mcool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'c2912f4c-7160-4374-81f0-fc7258c6f5eb'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered \u001b[0m\n",
       "\u001b[32magents, I start to see a couple common limitations:'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To build an autonomous agent system, several essential components are required:\n",
      "\n",
      "1. **Planning**: The agent must be capable of breaking down complex tasks into smaller, manageable subgoals. This involves task decomposition, often enhanced through techniques like the chain of thought (CoT) prompting, which encourages the model to think step by step during the execution of tasks.\n",
      "\n",
      "2. **Reflection and Refinement**: The agent should possess the ability to self-reflect on its past actions, learn from mistakes, and refine its future strategies. This self-critical capability improves the quality and effectiveness of the agent's outputs over time.\n",
      "\n",
      "3. **Memory**: Maintaining a memory system is crucial for remembering past interactions and decisions, allowing the agent to have context and continuity in its actions. This component aids in enhancing conversations and task management by recalling previous states and objectives.\n",
      "\n",
      "4. **Response Generation**: After completing tasks, the agent needs to generate clear and concise responses or summaries of its actions. This helps communicate the outcomes effectively to users or other systems.\n",
      "\n",
      "Incorporating these components allows for the creation of sophisticated autonomous agents that can perform tasks independently, adaptively, and in a context-aware manner."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_answer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'qa_pairs'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Question: What is a large language model (LLM) and how does it function?  \\nAnswer:\\nA large </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language model (LLM) is an advanced artificial intelligence system designed to understand and generate human-like </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">text based on the input it receives. It functions by utilizing deep learning techniques, particularly neural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">networks, to analyze vast amounts of text data, which allows it to learn language patterns, grammar, facts, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">various forms of knowledge. \\n\\nLLMs operate on the principles of probabilistic modeling, where they calculate the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">probability of a word or phrase occurring in a given context and generate responses accordingly. They are often </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">used in various applications such as text generation, translation, summarization, and even problem-solving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\n\\nIn an LLM-powered autonomous agent system, the LLM acts as the core controller or \"brain\" of the agent. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">It is complemented by several key components, including:\\n\\n1. **Planning**: The LLM can break down large tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into smaller, manageable subgoals, allowing it to tackle complex tasks more efficiently.\\n   \\n2. **Reflection and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Refinement**: The model has the capability for self-criticism and reflection, enabling it to learn from past </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">actions and improve future outputs.\\n\\n3. **Response Generation**: After performing tasks, the LLM summarizes the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">execution results for the user, facilitating clear communication of outcomes.\\n\\nDespite their capabilities, LLMs </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">face challenges, such as ensuring reliability in their outputs and effectively managing interactions with external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tools and APIs. Issues like formatting errors and inconsistent behavior can arise, necessitating careful design of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the systems that incorporate these models. Overall, LLMs represent a powerful computational tool for various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">natural language processing tasks and beyond.\\n\\nQuestion: What are the essential components required for building </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an autonomous agent system?  \\nAnswer:\\nTo build an autonomous agent system, several essential components are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">required:\\n\\n1. **Planning**: The agent must be capable of breaking down complex tasks into smaller, manageable </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">subgoals. This involves task decomposition, often enhanced through techniques like the chain of thought (CoT) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">prompting, which encourages the model to think step by step during the execution of tasks.\\n\\n2. **Reflection and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Refinement**: The agent should possess the ability to self-reflect on its past actions, learn from mistakes, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">refine its future strategies. This self-critical capability improves the quality and effectiveness of the agent\\'s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outputs over time.\\n\\n3. **Memory**: Maintaining a memory system is crucial for remembering past interactions and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decisions, allowing the agent to have context and continuity in its actions. This component aids in enhancing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conversations and task management by recalling previous states and objectives.\\n\\n4. **Response Generation**: After</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">completing tasks, the agent needs to generate clear and concise responses or summaries of its actions. This helps </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">communicate the outcomes effectively to users or other systems.\\n\\nIncorporating these components allows for the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">creation of sophisticated autonomous agents that can perform tasks independently, adaptively, and in a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context-aware manner.\\n\\n'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'current_question_idx'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_answer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'qa_pairs'\u001b[0m: \u001b[32m'Question: What is a large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and how does it function?  \\nAnswer:\\nA large \u001b[0m\n",
       "\u001b[32mlanguage model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is an advanced artificial intelligence system designed to understand and generate human-like \u001b[0m\n",
       "\u001b[32mtext based on the input it receives. It functions by utilizing deep learning techniques, particularly neural \u001b[0m\n",
       "\u001b[32mnetworks, to analyze vast amounts of text data, which allows it to learn language patterns, grammar, facts, and \u001b[0m\n",
       "\u001b[32mvarious forms of knowledge. \\n\\nLLMs operate on the principles of probabilistic modeling, where they calculate the \u001b[0m\n",
       "\u001b[32mprobability of a word or phrase occurring in a given context and generate responses accordingly. They are often \u001b[0m\n",
       "\u001b[32mused in various applications such as text generation, translation, summarization, and even problem-solving \u001b[0m\n",
       "\u001b[32mtasks.\\n\\nIn an LLM-powered autonomous agent system, the LLM acts as the core controller or \"brain\" of the agent. \u001b[0m\n",
       "\u001b[32mIt is complemented by several key components, including:\\n\\n1. **Planning**: The LLM can break down large tasks \u001b[0m\n",
       "\u001b[32minto smaller, manageable subgoals, allowing it to tackle complex tasks more efficiently.\\n   \\n2. **Reflection and \u001b[0m\n",
       "\u001b[32mRefinement**: The model has the capability for self-criticism and reflection, enabling it to learn from past \u001b[0m\n",
       "\u001b[32mactions and improve future outputs.\\n\\n3. **Response Generation**: After performing tasks, the LLM summarizes the \u001b[0m\n",
       "\u001b[32mexecution results for the user, facilitating clear communication of outcomes.\\n\\nDespite their capabilities, LLMs \u001b[0m\n",
       "\u001b[32mface challenges, such as ensuring reliability in their outputs and effectively managing interactions with external \u001b[0m\n",
       "\u001b[32mtools and APIs. Issues like formatting errors and inconsistent behavior can arise, necessitating careful design of \u001b[0m\n",
       "\u001b[32mthe systems that incorporate these models. Overall, LLMs represent a powerful computational tool for various \u001b[0m\n",
       "\u001b[32mnatural language processing tasks and beyond.\\n\\nQuestion: What are the essential components required for building \u001b[0m\n",
       "\u001b[32man autonomous agent system?  \\nAnswer:\\nTo build an autonomous agent system, several essential components are \u001b[0m\n",
       "\u001b[32mrequired:\\n\\n1. **Planning**: The agent must be capable of breaking down complex tasks into smaller, manageable \u001b[0m\n",
       "\u001b[32msubgoals. This involves task decomposition, often enhanced through techniques like the chain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mprompting, which encourages the model to think step by step during the execution of tasks.\\n\\n2. **Reflection and \u001b[0m\n",
       "\u001b[32mRefinement**: The agent should possess the ability to self-reflect on its past actions, learn from mistakes, and \u001b[0m\n",
       "\u001b[32mrefine its future strategies. This self-critical capability improves the quality and effectiveness of the agent\\'s \u001b[0m\n",
       "\u001b[32moutputs over time.\\n\\n3. **Memory**: Maintaining a memory system is crucial for remembering past interactions and \u001b[0m\n",
       "\u001b[32mdecisions, allowing the agent to have context and continuity in its actions. This component aids in enhancing \u001b[0m\n",
       "\u001b[32mconversations and task management by recalling previous states and objectives.\\n\\n4. **Response Generation**: After\u001b[0m\n",
       "\u001b[32mcompleting tasks, the agent needs to generate clear and concise responses or summaries of its actions. This helps \u001b[0m\n",
       "\u001b[32mcommunicate the outcomes effectively to users or other systems.\\n\\nIncorporating these components allows for the \u001b[0m\n",
       "\u001b[32mcreation of sophisticated autonomous agents that can perform tasks independently, adaptively, and in a \u001b[0m\n",
       "\u001b[32mcontext-aware manner.\\n\\n'\u001b[0m,\n",
       "        \u001b[32m'current_question_idx'\u001b[0m: \u001b[1;36m2\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve_docs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'722e6b6b-580c-4ac0-9e9c-9377b0d6914f'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'c8dba136-1894-422b-990e-9e2ffd92fb9c'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'8c6aba8b-17dc-44df-b269-f2de039f9e2b'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language as an interface between LLMs and external components such as memory and tools. However, the reliability of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'479fea7b-64f8-4e1f-b448-72c05a7f7660'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve_docs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'722e6b6b-580c-4ac0-9e9c-9377b0d6914f'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: \u001b[0m\n",
       "\u001b[32m31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a \u001b[0m\n",
       "\u001b[32mcool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'c8dba136-1894-422b-990e-9e2ffd92fb9c'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'8c6aba8b-17dc-44df-b269-f2de039f9e2b'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural \u001b[0m\n",
       "\u001b[32mlanguage as an interface between LLMs and external components such as memory and tools. However, the reliability of\u001b[0m\n",
       "\u001b[32mmodel outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. refuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'479fea7b-64f8-4e1f-b448-72c05a7f7660'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Another quite distinct approach, LLM+P \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLiu et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, involves relying on an \u001b[0m\n",
       "\u001b[32mexternal classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition \u001b[0m\n",
       "\u001b[32mLanguage \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPDDL\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as an intermediate interface to describe the planning problem. In this process, LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m translates \u001b[0m\n",
       "\u001b[32mthe problem into “Problem PDDL”, then \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m requests a classical planner to generate a PDDL plan based on an existing\u001b[0m\n",
       "\u001b[32m“Domain PDDL”, and finally \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m translates the PDDL plan back into natural language. Essentially, the planning step \u001b[0m\n",
       "\u001b[32mis outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which \u001b[0m\n",
       "\u001b[32mis common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital \u001b[0m\n",
       "\u001b[32maspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting \u001b[0m\n",
       "\u001b[32mprevious mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models (LLMs) integrate with other technologies in an autonomous system by serving as the core controller—often referred to as the \"brain\"—and collaborating with various essential components that enhance the system's capabilities. This integration is foundational in enabling the autonomous agents to perform complex tasks effectively. Here are key ways LLMs integrate with other technologies in such systems:\n",
      "\n",
      "1. **Planning**: LLMs enable task decomposition, breaking down complex goals into smaller, manageable subgoals. This is often achieved using techniques like the Chain of Thought (CoT) prompting, which encourages the model to think step-by-step. Additionally, LLMs can interface with external planning tools. For instance, they can utilize classical planning methods through the Planning Domain Definition Language (PDDL), where an LLM translates a problem into PDDL, requests a classical planner to generate a plan, and then translates that plan back into natural language.\n",
      "\n",
      "2. **Reflection and Refinement**: LLMs are equipped with self-reflection functionalities, allowing them to learn from past actions and refine their future strategies. This iterative improvement process is crucial for adapting to new challenges and correcting previous mistakes, thus enhancing the system's overall performance.\n",
      "\n",
      "3. **Memory Systems**: To maintain context and continuity, LLMs may integrate with memory technologies. These systems keep track of past interactions, decisions, and states, providing the LLM with the necessary context to make informed decisions as it engages in tasks.\n",
      "\n",
      "4. **Response Generation and Communication**: After completing tasks, LLMs are responsible for generating clear and concise summaries or responses. This communication capability is vital for allowing users or other systems to understand the outcomes of the agent's actions effectively.\n",
      "\n",
      "5. **Reliability and Integration with External Tools**: The integration of LLMs with other components also involves addressing reliability concerns. Since the natural language outputs of LLMs can sometimes be prone to errors, careful design is needed to parse and manage these outputs effectively, ensuring that the LLM can interact reliably with external tools and APIs.\n",
      "\n",
      "In summary, LLMs in autonomous systems serve as central units that collaborate with planning mechanisms, memory systems, and other technologies to create adaptable, context-aware agents capable of performing complex tasks autonomously."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_answer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'qa_pairs'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Question: What is a large language model (LLM) and how does it function?  \\nAnswer:\\nA large </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language model (LLM) is an advanced artificial intelligence system designed to understand and generate human-like </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">text based on the input it receives. It functions by utilizing deep learning techniques, particularly neural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">networks, to analyze vast amounts of text data, which allows it to learn language patterns, grammar, facts, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">various forms of knowledge. \\n\\nLLMs operate on the principles of probabilistic modeling, where they calculate the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">probability of a word or phrase occurring in a given context and generate responses accordingly. They are often </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">used in various applications such as text generation, translation, summarization, and even problem-solving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\n\\nIn an LLM-powered autonomous agent system, the LLM acts as the core controller or \"brain\" of the agent. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">It is complemented by several key components, including:\\n\\n1. **Planning**: The LLM can break down large tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into smaller, manageable subgoals, allowing it to tackle complex tasks more efficiently.\\n   \\n2. **Reflection and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Refinement**: The model has the capability for self-criticism and reflection, enabling it to learn from past </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">actions and improve future outputs.\\n\\n3. **Response Generation**: After performing tasks, the LLM summarizes the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">execution results for the user, facilitating clear communication of outcomes.\\n\\nDespite their capabilities, LLMs </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">face challenges, such as ensuring reliability in their outputs and effectively managing interactions with external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tools and APIs. Issues like formatting errors and inconsistent behavior can arise, necessitating careful design of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the systems that incorporate these models. Overall, LLMs represent a powerful computational tool for various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">natural language processing tasks and beyond.\\n\\nQuestion: What are the essential components required for building </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an autonomous agent system?  \\nAnswer:\\nTo build an autonomous agent system, several essential components are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">required:\\n\\n1. **Planning**: The agent must be capable of breaking down complex tasks into smaller, manageable </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">subgoals. This involves task decomposition, often enhanced through techniques like the chain of thought (CoT) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">prompting, which encourages the model to think step by step during the execution of tasks.\\n\\n2. **Reflection and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Refinement**: The agent should possess the ability to self-reflect on its past actions, learn from mistakes, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">refine its future strategies. This self-critical capability improves the quality and effectiveness of the agent\\'s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outputs over time.\\n\\n3. **Memory**: Maintaining a memory system is crucial for remembering past interactions and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decisions, allowing the agent to have context and continuity in its actions. This component aids in enhancing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conversations and task management by recalling previous states and objectives.\\n\\n4. **Response Generation**: After</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">completing tasks, the agent needs to generate clear and concise responses or summaries of its actions. This helps </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">communicate the outcomes effectively to users or other systems.\\n\\nIncorporating these components allows for the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">creation of sophisticated autonomous agents that can perform tasks independently, adaptively, and in a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context-aware manner.\\n\\nQuestion: How do LLMs integrate with other technologies in an autonomous system?  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\nAnswer:\\nLarge language models (LLMs) integrate with other technologies in an autonomous system by serving as the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">core controller—often referred to as the \"brain\"—and collaborating with various essential components that enhance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the system\\'s capabilities. This integration is foundational in enabling the autonomous agents to perform complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks effectively. Here are key ways LLMs integrate with other technologies in such systems:\\n\\n1. **Planning**: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLMs enable task decomposition, breaking down complex goals into smaller, manageable subgoals. This is often </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">achieved using techniques like the Chain of Thought (CoT) prompting, which encourages the model to think </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">step-by-step. Additionally, LLMs can interface with external planning tools. For instance, they can utilize </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">classical planning methods through the Planning Domain Definition Language (PDDL), where an LLM translates a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problem into PDDL, requests a classical planner to generate a plan, and then translates that plan back into natural</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language.\\n\\n2. **Reflection and Refinement**: LLMs are equipped with self-reflection functionalities, allowing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">them to learn from past actions and refine their future strategies. This iterative improvement process is crucial </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for adapting to new challenges and correcting previous mistakes, thus enhancing the system\\'s overall </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance.\\n\\n3. **Memory Systems**: To maintain context and continuity, LLMs may integrate with memory </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">technologies. These systems keep track of past interactions, decisions, and states, providing the LLM with the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">necessary context to make informed decisions as it engages in tasks.\\n\\n4. **Response Generation and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Communication**: After completing tasks, LLMs are responsible for generating clear and concise summaries or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">responses. This communication capability is vital for allowing users or other systems to understand the outcomes of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the agent\\'s actions effectively.\\n\\n5. **Reliability and Integration with External Tools**: The integration of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLMs with other components also involves addressing reliability concerns. Since the natural language outputs of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLMs can sometimes be prone to errors, careful design is needed to parse and manage these outputs effectively, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ensuring that the LLM can interact reliably with external tools and APIs.\\n\\nIn summary, LLMs in autonomous systems</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">serve as central units that collaborate with planning mechanisms, memory systems, and other technologies to create </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">adaptable, context-aware agents capable of performing complex tasks autonomously.\\n\\n'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'current_question_idx'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_answer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'qa_pairs'\u001b[0m: \u001b[32m'Question: What is a large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and how does it function?  \\nAnswer:\\nA large \u001b[0m\n",
       "\u001b[32mlanguage model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is an advanced artificial intelligence system designed to understand and generate human-like \u001b[0m\n",
       "\u001b[32mtext based on the input it receives. It functions by utilizing deep learning techniques, particularly neural \u001b[0m\n",
       "\u001b[32mnetworks, to analyze vast amounts of text data, which allows it to learn language patterns, grammar, facts, and \u001b[0m\n",
       "\u001b[32mvarious forms of knowledge. \\n\\nLLMs operate on the principles of probabilistic modeling, where they calculate the \u001b[0m\n",
       "\u001b[32mprobability of a word or phrase occurring in a given context and generate responses accordingly. They are often \u001b[0m\n",
       "\u001b[32mused in various applications such as text generation, translation, summarization, and even problem-solving \u001b[0m\n",
       "\u001b[32mtasks.\\n\\nIn an LLM-powered autonomous agent system, the LLM acts as the core controller or \"brain\" of the agent. \u001b[0m\n",
       "\u001b[32mIt is complemented by several key components, including:\\n\\n1. **Planning**: The LLM can break down large tasks \u001b[0m\n",
       "\u001b[32minto smaller, manageable subgoals, allowing it to tackle complex tasks more efficiently.\\n   \\n2. **Reflection and \u001b[0m\n",
       "\u001b[32mRefinement**: The model has the capability for self-criticism and reflection, enabling it to learn from past \u001b[0m\n",
       "\u001b[32mactions and improve future outputs.\\n\\n3. **Response Generation**: After performing tasks, the LLM summarizes the \u001b[0m\n",
       "\u001b[32mexecution results for the user, facilitating clear communication of outcomes.\\n\\nDespite their capabilities, LLMs \u001b[0m\n",
       "\u001b[32mface challenges, such as ensuring reliability in their outputs and effectively managing interactions with external \u001b[0m\n",
       "\u001b[32mtools and APIs. Issues like formatting errors and inconsistent behavior can arise, necessitating careful design of \u001b[0m\n",
       "\u001b[32mthe systems that incorporate these models. Overall, LLMs represent a powerful computational tool for various \u001b[0m\n",
       "\u001b[32mnatural language processing tasks and beyond.\\n\\nQuestion: What are the essential components required for building \u001b[0m\n",
       "\u001b[32man autonomous agent system?  \\nAnswer:\\nTo build an autonomous agent system, several essential components are \u001b[0m\n",
       "\u001b[32mrequired:\\n\\n1. **Planning**: The agent must be capable of breaking down complex tasks into smaller, manageable \u001b[0m\n",
       "\u001b[32msubgoals. This involves task decomposition, often enhanced through techniques like the chain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mprompting, which encourages the model to think step by step during the execution of tasks.\\n\\n2. **Reflection and \u001b[0m\n",
       "\u001b[32mRefinement**: The agent should possess the ability to self-reflect on its past actions, learn from mistakes, and \u001b[0m\n",
       "\u001b[32mrefine its future strategies. This self-critical capability improves the quality and effectiveness of the agent\\'s \u001b[0m\n",
       "\u001b[32moutputs over time.\\n\\n3. **Memory**: Maintaining a memory system is crucial for remembering past interactions and \u001b[0m\n",
       "\u001b[32mdecisions, allowing the agent to have context and continuity in its actions. This component aids in enhancing \u001b[0m\n",
       "\u001b[32mconversations and task management by recalling previous states and objectives.\\n\\n4. **Response Generation**: After\u001b[0m\n",
       "\u001b[32mcompleting tasks, the agent needs to generate clear and concise responses or summaries of its actions. This helps \u001b[0m\n",
       "\u001b[32mcommunicate the outcomes effectively to users or other systems.\\n\\nIncorporating these components allows for the \u001b[0m\n",
       "\u001b[32mcreation of sophisticated autonomous agents that can perform tasks independently, adaptively, and in a \u001b[0m\n",
       "\u001b[32mcontext-aware manner.\\n\\nQuestion: How do LLMs integrate with other technologies in an autonomous system?  \u001b[0m\n",
       "\u001b[32m\\nAnswer:\\nLarge language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m integrate with other technologies in an autonomous system by serving as the\u001b[0m\n",
       "\u001b[32mcore controller—often referred to as the \"brain\"—and collaborating with various essential components that enhance \u001b[0m\n",
       "\u001b[32mthe system\\'s capabilities. This integration is foundational in enabling the autonomous agents to perform complex \u001b[0m\n",
       "\u001b[32mtasks effectively. Here are key ways LLMs integrate with other technologies in such systems:\\n\\n1. **Planning**: \u001b[0m\n",
       "\u001b[32mLLMs enable task decomposition, breaking down complex goals into smaller, manageable subgoals. This is often \u001b[0m\n",
       "\u001b[32machieved using techniques like the Chain of Thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m prompting, which encourages the model to think \u001b[0m\n",
       "\u001b[32mstep-by-step. Additionally, LLMs can interface with external planning tools. For instance, they can utilize \u001b[0m\n",
       "\u001b[32mclassical planning methods through the Planning Domain Definition Language \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPDDL\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, where an LLM translates a \u001b[0m\n",
       "\u001b[32mproblem into PDDL, requests a classical planner to generate a plan, and then translates that plan back into natural\u001b[0m\n",
       "\u001b[32mlanguage.\\n\\n2. **Reflection and Refinement**: LLMs are equipped with self-reflection functionalities, allowing \u001b[0m\n",
       "\u001b[32mthem to learn from past actions and refine their future strategies. This iterative improvement process is crucial \u001b[0m\n",
       "\u001b[32mfor adapting to new challenges and correcting previous mistakes, thus enhancing the system\\'s overall \u001b[0m\n",
       "\u001b[32mperformance.\\n\\n3. **Memory Systems**: To maintain context and continuity, LLMs may integrate with memory \u001b[0m\n",
       "\u001b[32mtechnologies. These systems keep track of past interactions, decisions, and states, providing the LLM with the \u001b[0m\n",
       "\u001b[32mnecessary context to make informed decisions as it engages in tasks.\\n\\n4. **Response Generation and \u001b[0m\n",
       "\u001b[32mCommunication**: After completing tasks, LLMs are responsible for generating clear and concise summaries or \u001b[0m\n",
       "\u001b[32mresponses. This communication capability is vital for allowing users or other systems to understand the outcomes of\u001b[0m\n",
       "\u001b[32mthe agent\\'s actions effectively.\\n\\n5. **Reliability and Integration with External Tools**: The integration of \u001b[0m\n",
       "\u001b[32mLLMs with other components also involves addressing reliability concerns. Since the natural language outputs of \u001b[0m\n",
       "\u001b[32mLLMs can sometimes be prone to errors, careful design is needed to parse and manage these outputs effectively, \u001b[0m\n",
       "\u001b[32mensuring that the LLM can interact reliably with external tools and APIs.\\n\\nIn summary, LLMs in autonomous systems\u001b[0m\n",
       "\u001b[32mserve as central units that collaborate with planning mechanisms, memory systems, and other technologies to create \u001b[0m\n",
       "\u001b[32madaptable, context-aware agents capable of performing complex tasks autonomously.\\n\\n'\u001b[0m,\n",
       "        \u001b[32m'current_question_idx'\u001b[0m: \u001b[1;36m3\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve_docs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'722e6b6b-580c-4ac0-9e9c-9377b0d6914f'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'c8dba136-1894-422b-990e-9e2ffd92fb9c'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'8c6aba8b-17dc-44df-b269-f2de039f9e2b'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language as an interface between LLMs and external components such as memory and tools. However, the reliability of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'5302075d-9342-43b9-936e-4db7b2c4423f'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve_docs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'722e6b6b-580c-4ac0-9e9c-9377b0d6914f'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: \u001b[0m\n",
       "\u001b[32m31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a \u001b[0m\n",
       "\u001b[32mcool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'c8dba136-1894-422b-990e-9e2ffd92fb9c'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'8c6aba8b-17dc-44df-b269-f2de039f9e2b'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural \u001b[0m\n",
       "\u001b[32mlanguage as an interface between LLMs and external components such as memory and tools. However, the reliability of\u001b[0m\n",
       "\u001b[32mmodel outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. refuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'5302075d-9342-43b9-936e-4db7b2c4423f'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 13. The generative agent architecture. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Park et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThis \u001b[0m\n",
       "\u001b[32mfun simulation results in emergent social behavior, such as information diffusion, relationship memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. two \u001b[0m\n",
       "\u001b[32magents continuing the conversation topic\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and coordination of social events \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. host a party and invite many \u001b[0m\n",
       "\u001b[32mothers\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up \u001b[0m\n",
       "\u001b[32mautonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural \u001b[0m\n",
       "\u001b[32mlanguage interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format \u001b[0m\n",
       "\u001b[32mparsing.\\nHere is the system message used by AutoGPT, where \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m...\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m are user inputs:\\nYou are \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mai-name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser-provided AI bot description\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.\\nYour decisions must always be made independently without seeking user \u001b[0m\n",
       "\u001b[32massistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main components of an LLM-powered autonomous agent system are:\n",
      "\n",
      "1. **Planning**: This component allows the agent to break down complex tasks into smaller, manageable subgoals. Techniques such as the Chain of Thought (CoT) prompting help in achieving this, enabling the agent to think step-by-step and approach tasks systematically.\n",
      "\n",
      "2. **Reflection and Refinement**: The agent possesses the ability to reflect on its past actions, learn from mistakes, and refine its strategies for future tasks. This self-critical capability improves the quality and effectiveness of the agent's output over time.\n",
      "\n",
      "3. **Memory**: A memory system is essential for maintaining context and continuity in the agent's actions. This allows the agent to remember past interactions and decisions, enhancing its ability to manage tasks and engage in conversations.\n",
      "\n",
      "4. **Response Generation**: After completing tasks, the agent generates clear and concise summaries of its actions. This communication capability is vital for effectively conveying outcomes to users or other systems.\n",
      "\n",
      "Each of these components plays a significant role in creating a sophisticated and adaptable autonomous agent that can perform tasks independently and contextually."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_answer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"The main components of an LLM-powered autonomous agent system are:\\n\\n1. **Planning**: This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">component allows the agent to break down complex tasks into smaller, manageable subgoals. Techniques such as the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Chain of Thought (CoT) prompting help in achieving this, enabling the agent to think step-by-step and approach </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks systematically.\\n\\n2. **Reflection and Refinement**: The agent possesses the ability to reflect on its past </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">actions, learn from mistakes, and refine its strategies for future tasks. This self-critical capability improves </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the quality and effectiveness of the agent's output over time.\\n\\n3. **Memory**: A memory system is essential for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">maintaining context and continuity in the agent's actions. This allows the agent to remember past interactions and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decisions, enhancing its ability to manage tasks and engage in conversations.\\n\\n4. **Response Generation**: After </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">completing tasks, the agent generates clear and concise summaries of its actions. This communication capability is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">vital for effectively conveying outcomes to users or other systems.\\n\\nEach of these components plays a significant</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">role in creating a sophisticated and adaptable autonomous agent that can perform tasks independently and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contextually.\"</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_answer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'answer'\u001b[0m: \u001b[32m\"The main components of an LLM-powered autonomous agent system are:\\n\\n1. **Planning**: This \u001b[0m\n",
       "\u001b[32mcomponent allows the agent to break down complex tasks into smaller, manageable subgoals. Techniques such as the \u001b[0m\n",
       "\u001b[32mChain of Thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m prompting help in achieving this, enabling the agent to think step-by-step and approach \u001b[0m\n",
       "\u001b[32mtasks systematically.\\n\\n2. **Reflection and Refinement**: The agent possesses the ability to reflect on its past \u001b[0m\n",
       "\u001b[32mactions, learn from mistakes, and refine its strategies for future tasks. This self-critical capability improves \u001b[0m\n",
       "\u001b[32mthe quality and effectiveness of the agent's output over time.\\n\\n3. **Memory**: A memory system is essential for \u001b[0m\n",
       "\u001b[32mmaintaining context and continuity in the agent's actions. This allows the agent to remember past interactions and \u001b[0m\n",
       "\u001b[32mdecisions, enhancing its ability to manage tasks and engage in conversations.\\n\\n4. **Response Generation**: After \u001b[0m\n",
       "\u001b[32mcompleting tasks, the agent generates clear and concise summaries of its actions. This communication capability is \u001b[0m\n",
       "\u001b[32mvital for effectively conveying outcomes to users or other systems.\\n\\nEach of these components plays a significant\u001b[0m\n",
       "\u001b[32mrole in creating a sophisticated and adaptable autonomous agent that can perform tasks independently and \u001b[0m\n",
       "\u001b[32mcontextually.\"\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The main components of an LLM-powered autonomous agent system are:                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Planning</span>: This component allows the agent to break down complex tasks into smaller, manageable subgoals.        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>Techniques such as the Chain of Thought (CoT) prompting help in achieving this, enabling the agent to think     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>step-by-step and approach tasks systematically.                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Reflection and Refinement</span>: The agent possesses the ability to reflect on its past actions, learn from mistakes, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and refine its strategies for future tasks. This self-critical capability improves the quality and effectiveness\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>of the agent's output over time.                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Memory</span>: A memory system is essential for maintaining context and continuity in the agent's actions. This allows \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>the agent to remember past interactions and decisions, enhancing its ability to manage tasks and engage in      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>conversations.                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">Response Generation</span>: After completing tasks, the agent generates clear and concise summaries of its actions.    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>This communication capability is vital for effectively conveying outcomes to users or other systems.            \n",
       "\n",
       "Each of these components plays a significant role in creating a sophisticated and adaptable autonomous agent that  \n",
       "can perform tasks independently and contextually.                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "The main components of an LLM-powered autonomous agent system are:                                                 \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mPlanning\u001b[0m: This component allows the agent to break down complex tasks into smaller, manageable subgoals.        \n",
       "\u001b[1;33m   \u001b[0mTechniques such as the Chain of Thought (CoT) prompting help in achieving this, enabling the agent to think     \n",
       "\u001b[1;33m   \u001b[0mstep-by-step and approach tasks systematically.                                                                 \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mReflection and Refinement\u001b[0m: The agent possesses the ability to reflect on its past actions, learn from mistakes, \n",
       "\u001b[1;33m   \u001b[0mand refine its strategies for future tasks. This self-critical capability improves the quality and effectiveness\n",
       "\u001b[1;33m   \u001b[0mof the agent's output over time.                                                                                \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mMemory\u001b[0m: A memory system is essential for maintaining context and continuity in the agent's actions. This allows \n",
       "\u001b[1;33m   \u001b[0mthe agent to remember past interactions and decisions, enhancing its ability to manage tasks and engage in      \n",
       "\u001b[1;33m   \u001b[0mconversations.                                                                                                  \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1mResponse Generation\u001b[0m: After completing tasks, the agent generates clear and concise summaries of its actions.    \n",
       "\u001b[1;33m   \u001b[0mThis communication capability is vital for effectively conveying outcomes to users or other systems.            \n",
       "\n",
       "Each of these components plays a significant role in creating a sophisticated and adaptable autonomous agent that  \n",
       "can perform tasks independently and contextually.                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"max_generated_sub_questions_count\": 3\n",
    "    }\n",
    "}\n",
    "\n",
    "for stream_mode, event in graph.stream(\n",
    "    {\"question\": query}, \n",
    "    stream_mode=[\"messages\", \"updates\"],\n",
    "    config=config\n",
    "):\n",
    "    match stream_mode:\n",
    "        case \"messages\":\n",
    "            message, metadata = event\n",
    "            print(message.content, end=\"\", flush=True)\n",
    "        case \"updates\":\n",
    "            rprint(event)\n",
    "\n",
    "display(Markdown(event['generate_answer']['answer']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-rag",
   "language": "python",
   "name": "llm-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
