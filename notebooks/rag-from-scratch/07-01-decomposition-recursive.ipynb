{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9185900c-873b-40c8-a671-bdf5e6c6e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from IPython.display import display\n",
    "from rich import print as rprint\n",
    "from rich.markdown import Markdown\n",
    "from rich.pretty import Pretty\n",
    "from rich.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0309a6a1-b78c-477b-9d29-a7f17b05618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2576e0c-f570-4a57-a0f5-df782bf9daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG From Scratch: Part 7-1 (Query Translation - Decomposition (Recursive))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063500a-216e-4dbe-9b45-3e6aae8442b1",
   "metadata": {},
   "source": [
    "# Query translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674c047-61f4-419d-a017-1470e251914f",
   "metadata": {},
   "source": [
    "![](images/query-translation-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2860bf1a-57f6-427b-9977-7604a3685902",
   "metadata": {},
   "source": [
    "![](images/query-translation-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989a6c3d-e97c-496d-b583-88e72baeb4c3",
   "metadata": {},
   "source": [
    "# Part 7-1: Decomposition (Recursive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31247214-b065-4d17-a986-c8240376a110",
   "metadata": {},
   "source": [
    "![](images/07-01-decomposition-recursive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800589d2-7c6e-4aac-a83a-f0ec36049cb6",
   "metadata": {},
   "source": [
    "## Configure components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f553f7a7-3ff3-4197-80a5-cfdf604a9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f86ab48-b98f-4543-a6c6-4c972b84b152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-71dd424a-2902-4a56-ba74-40d05e39dc94-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1\n",
    ")\n",
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7dc8587-e9c0-4b5e-944c-72e7d267b4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "len(embeddings.embed_query(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bc159-dede-4260-b2ff-100990d63dbb",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc65ba7f-09c3-4c99-9a49-2a2f6cb7ef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd74a494-1b65-489c-a370-7e41049b8be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3111212-eab1-4691-ad6f-c7f6ea632155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b9af7-a2f9-45b8-854c-410b8c4e67bc",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1955089c-5fa3-43a2-a16e-3e0682fae53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aa35b9e-5bd5-423b-b17d-38bd60aa9060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49e5f6a-3722-47c4-be2e-69601f16f637",
   "metadata": {},
   "source": [
    "## Store documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f1600ad-ae95-4e1d-8cee-d7ce8a977d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f672034b-b010-4b4b-aae9-583a87c45803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = InMemoryVectorStore(embeddings)\n",
    "doc_ids = vectorstore.add_documents(documents=splits)\n",
    "len(doc_ids), len(vectorstore.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf4fa9a1-71a5-42d1-8070-8e2a4953af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839bda8b-7070-443c-afbc-1eab80ad5300",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5ac14e1-163e-4c58-9c0a-330fef9e8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a77538-ddbe-4202-8e50-6184996df3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are a helpful assistant that generates multiple sub-questions related to an input question.\n",
      "The goal is to break down the input into a set of sub-problems / sub-questions that can be answered sequentially.\n",
      "Generate multiple search queries related to: \u001b[33;1m\u001b[1;3m{question}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "decomposition_prompt_template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question.\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answered sequentially.\n",
    "Generate multiple search queries related to: {question}\"\"\"\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(decomposition_prompt_template)\n",
    "decomposition_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6e05179-def7-4723-9215-ba6ef4dd65a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Here is the question you need to answer:\n",
      "<question>\n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "</question>\n",
      "\n",
      "Here are any available background question + answer pairs:\n",
      "<question_answer_pairs>\n",
      "\u001b[33;1m\u001b[1;3m{qa_pairs}\u001b[0m\n",
      "</question_answer_pairs>\n",
      "\n",
      "Here is additional context relevant to the question: \n",
      "<context>\n",
      "\u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "</context>\n",
      "\n",
      "Use the above context and any background question + answer pairs to answer the question:\n",
      "<question>\n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "</question>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recursive_prompt_template = \"\"\"Here is the question you need to answer:\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Here are any available background question + answer pairs:\n",
    "<question_answer_pairs>\n",
    "{qa_pairs}\n",
    "</question_answer_pairs>\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question:\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\"\"\"\n",
    "\n",
    "recursive_prompt = ChatPromptTemplate.from_template(recursive_prompt_template)\n",
    "recursive_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "210c7aab-6d66-4167-8b30-a2101628e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "\n",
      "    You are a helpful assistant that generates multiple sub-questions related to an input question.\n",
      "    The goal is to break down the input into a set of sub-problems / sub-questions that can be answered sequentially.\n",
      "    Generate multiple search queries related to: {question}\n",
      "====================================================================================================\n",
      "You are a helpful assistant that generates multiple sub-questions related to an input question.\n",
      "The goal is to break down the input into a set of sub-problems / sub-questions that can be answered sequentially.\n",
      "Generate multiple search queries related to: {question}\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def print_prompts():\n",
    "    print('=' * 100)\n",
    "    prompt_template = \"\"\"\n",
    "    You are a helpful assistant that generates multiple sub-questions related to an input question.\n",
    "    The goal is to break down the input into a set of sub-problems / sub-questions that can be answered sequentially.\n",
    "    Generate multiple search queries related to: {question}\"\"\"\n",
    "    print(prompt_template)\n",
    "\n",
    "    print('=' * 100)\n",
    "    \n",
    "    prompt_template = textwrap.dedent(\"\"\"\n",
    "    You are a helpful assistant that generates multiple sub-questions related to an input question.\n",
    "    The goal is to break down the input into a set of sub-problems / sub-questions that can be answered sequentially.\n",
    "    Generate multiple search queries related to: {question}\"\"\").strip()\n",
    "    print(prompt_template)\n",
    "    print('=' * 100)\n",
    "    \n",
    "print_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ef22081-7982-419b-80ed-16c3ca2b3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_pair(question, answer):\n",
    "    return f\"Question: {question}  \\nAnswer:\\n{answer}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf754a56-99a7-4d87-bf7b-99f425305284",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the main components of an LLM-powered autonomous agent system?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec051b-3c2c-4c4f-bb41-b2b9da20fa69",
   "metadata": {},
   "source": [
    "### LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "578eac35-5f3b-49e0-8747-4e4615d1a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import chain, RunnableConfig\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8cc70a-e3ea-454f-aed0-9db67974d091",
   "metadata": {},
   "source": [
    "#### Generate queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aedf1042-e1c0-4a4c-882a-f474a37131b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'What is a large language model (LLM) and how does it function?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'What are the key components that make up an autonomous agent system?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'How do LLMs integrate with other technologies in an autonomous agent system?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'What are the main components of an LLM-powered autonomous agent system?'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'What is a large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and how does it function?'\u001b[0m,\n",
       "    \u001b[32m'What are the key components that make up an autonomous agent system?'\u001b[0m,\n",
       "    \u001b[32m'How do LLMs integrate with other technologies in an autonomous agent system?'\u001b[0m,\n",
       "    \u001b[32m'What are the main components of an LLM-powered autonomous agent system?'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@chain\n",
    "def generate_sub_questions(query: str, config: RunnableConfig) -> list[str]:\n",
    "    max_generated_sub_questions_count = config['configurable'].get(\"max_generated_sub_questions_count\", 3)\n",
    "    \n",
    "    class SubQuestionsGenerator(BaseModel):\n",
    "        sub_questions: list[str] = Field(\n",
    "            ..., \n",
    "            description=\"List of generated sub-problems / sub-questions\",\n",
    "            max_items=max_generated_sub_questions_count\n",
    "        )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(SubQuestionsGenerator, method=\"function_calling\")\n",
    "    chain = (\n",
    "        decomposition_prompt\n",
    "        | structured_llm\n",
    "    )\n",
    "    response = chain.invoke(query)\n",
    "    questions = response.sub_questions + [query]\n",
    "    \n",
    "    return questions\n",
    "\n",
    "questions = generate_sub_questions.invoke(query)\n",
    "rprint(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "268e4f73-a2f1-4f18-89fd-6047e032a6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'What is an LLM (Large Language Model) and how does it work?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'What are the essential components of an autonomous agent system?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'How do LLMs integrate with other components in an autonomous agent system?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'What role does natural language understanding play in LLM-powered autonomous agents?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'How do decision-making algorithms function within LLM-powered autonomous agents?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'What are the main components of an LLM-powered autonomous agent system?'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'What is an LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLarge Language Model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and how does it work?'\u001b[0m,\n",
       "    \u001b[32m'What are the essential components of an autonomous agent system?'\u001b[0m,\n",
       "    \u001b[32m'How do LLMs integrate with other components in an autonomous agent system?'\u001b[0m,\n",
       "    \u001b[32m'What role does natural language understanding play in LLM-powered autonomous agents?'\u001b[0m,\n",
       "    \u001b[32m'How do decision-making algorithms function within LLM-powered autonomous agents?'\u001b[0m,\n",
       "    \u001b[32m'What are the main components of an LLM-powered autonomous agent system?'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(generate_sub_questions.with_config(max_generated_sub_questions_count=5).invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ca8efb-a1d0-409e-a500-a9fc0e665b52",
   "metadata": {},
   "source": [
    "#### Define RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f739209-9186-4b0d-b6af-fef867a99aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What is a large language model (LLM) and how does it function?                                           \n",
       "Answer: A large language model (LLM) is an advanced type of artificial intelligence designed to understand,        \n",
       "generate, and manipulate human language in a coherent manner. It functions by using statistical patterns learned   \n",
       "from extensive datasets, which enable it to generate text that is contextually relevant and syntactically correct. \n",
       "\n",
       "Here's how an LLM operates:                                                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Training Process</span>: LLMs are trained on vast amounts of text data from books, articles, websites, and other       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>sources. During this training process, they learn to predict the next word in a sentence given the previous     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>words, which allows them to develop an understanding of language structure, semantics, and context.             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Tokenization</span>: When processing text, LLMs convert input sentences into tokens, which are the basic units of      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>meaning. This tokenization allows the model to effectively analyze and generate language.                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Contextual Understanding</span>: LLMs utilize mechanisms like attention mechanisms, which help them focus on relevant  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>portions of the input text to understand the meaning and generate appropriate responses. The size of the model  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>(number of parameters) typically enhances its capacity to retain context over larger spans of text.             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">Response Generation</span>: After processing the input, the LLM generates a response by predicting the most probable   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>continuation or relevant information based on its learned patterns. It can also handle tasks like summarization,\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>translation, and answering questions.                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span><span style=\"font-weight: bold\">Task Management and Problem Solving</span>: In advanced applications, LLMs can also function as agents that manage     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>complex tasks. They are capable of breaking down tasks into smaller subgoals, reflecting on their performance,  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and refining their approaches for improved results. This is exemplified in systems where LLMs serve as the core \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>controller in autonomous agents, which can respond to user queries or execute multi-step tasks by interacting   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>with external tools and APIs.                                                                                   \n",
       "\n",
       "In summary, LLMs are powerful AI models that leverage vast amounts of data and sophisticated algorithms to perform \n",
       "various language-related tasks, making them essential in numerous applications ranging from chatbots to autonomous \n",
       "systems. However, they can have limitations, such as inconsistencies or challenges in reliability, which are active\n",
       "areas of research.                                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What is a large language model (LLM) and how does it function?                                           \n",
       "Answer: A large language model (LLM) is an advanced type of artificial intelligence designed to understand,        \n",
       "generate, and manipulate human language in a coherent manner. It functions by using statistical patterns learned   \n",
       "from extensive datasets, which enable it to generate text that is contextually relevant and syntactically correct. \n",
       "\n",
       "Here's how an LLM operates:                                                                                        \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mTraining Process\u001b[0m: LLMs are trained on vast amounts of text data from books, articles, websites, and other       \n",
       "\u001b[1;33m   \u001b[0msources. During this training process, they learn to predict the next word in a sentence given the previous     \n",
       "\u001b[1;33m   \u001b[0mwords, which allows them to develop an understanding of language structure, semantics, and context.             \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mTokenization\u001b[0m: When processing text, LLMs convert input sentences into tokens, which are the basic units of      \n",
       "\u001b[1;33m   \u001b[0mmeaning. This tokenization allows the model to effectively analyze and generate language.                       \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mContextual Understanding\u001b[0m: LLMs utilize mechanisms like attention mechanisms, which help them focus on relevant  \n",
       "\u001b[1;33m   \u001b[0mportions of the input text to understand the meaning and generate appropriate responses. The size of the model  \n",
       "\u001b[1;33m   \u001b[0m(number of parameters) typically enhances its capacity to retain context over larger spans of text.             \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1mResponse Generation\u001b[0m: After processing the input, the LLM generates a response by predicting the most probable   \n",
       "\u001b[1;33m   \u001b[0mcontinuation or relevant information based on its learned patterns. It can also handle tasks like summarization,\n",
       "\u001b[1;33m   \u001b[0mtranslation, and answering questions.                                                                           \n",
       "\u001b[1;33m 5 \u001b[0m\u001b[1mTask Management and Problem Solving\u001b[0m: In advanced applications, LLMs can also function as agents that manage     \n",
       "\u001b[1;33m   \u001b[0mcomplex tasks. They are capable of breaking down tasks into smaller subgoals, reflecting on their performance,  \n",
       "\u001b[1;33m   \u001b[0mand refining their approaches for improved results. This is exemplified in systems where LLMs serve as the core \n",
       "\u001b[1;33m   \u001b[0mcontroller in autonomous agents, which can respond to user queries or execute multi-step tasks by interacting   \n",
       "\u001b[1;33m   \u001b[0mwith external tools and APIs.                                                                                   \n",
       "\n",
       "In summary, LLMs are powerful AI models that leverage vast amounts of data and sophisticated algorithms to perform \n",
       "various language-related tasks, making them essential in numerous applications ranging from chatbots to autonomous \n",
       "systems. However, they can have limitations, such as inconsistencies or challenges in reliability, which are active\n",
       "areas of research.                                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What are the key components that make up an autonomous agent system?                                     \n",
       "Answer: The key components that make up an autonomous agent system, particularly those powered by a large language \n",
       "model (LLM), include:                                                                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Planning</span>: The agent needs to plan its actions systematically, especially for complex tasks that involve multiple\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>steps. This includes:                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Task Decomposition</span>: The ability to break down large tasks into smaller, manageable subgoals. This is often   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>facilitated through techniques like chain of thought (CoT), which encourages the agent to think step-by-step.\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Reflection and Refinement</span>: The agent can self-evaluate its past actions, learn from mistakes, and refine its    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>approach for future tasks. This self-criticism aids in improving the quality of its results over time.          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Memory</span>: An effective autonomous agent system often includes a memory component that helps the agent retain      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>information from past interactions and tasks, allowing it to refer back to previous knowledge and experiences to\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>inform current decisions.                                                                                       \n",
       "\n",
       "These components work together to enable the autonomous agent to operate effectively, manage complex tasks, and    \n",
       "adapt based on its experiences.                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What are the key components that make up an autonomous agent system?                                     \n",
       "Answer: The key components that make up an autonomous agent system, particularly those powered by a large language \n",
       "model (LLM), include:                                                                                              \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mPlanning\u001b[0m: The agent needs to plan its actions systematically, especially for complex tasks that involve multiple\n",
       "\u001b[1;33m   \u001b[0msteps. This includes:                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mTask Decomposition\u001b[0m: The ability to break down large tasks into smaller, manageable subgoals. This is often   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mfacilitated through techniques like chain of thought (CoT), which encourages the agent to think step-by-step.\n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mReflection and Refinement\u001b[0m: The agent can self-evaluate its past actions, learn from mistakes, and refine its    \n",
       "\u001b[1;33m   \u001b[0mapproach for future tasks. This self-criticism aids in improving the quality of its results over time.          \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mMemory\u001b[0m: An effective autonomous agent system often includes a memory component that helps the agent retain      \n",
       "\u001b[1;33m   \u001b[0minformation from past interactions and tasks, allowing it to refer back to previous knowledge and experiences to\n",
       "\u001b[1;33m   \u001b[0minform current decisions.                                                                                       \n",
       "\n",
       "These components work together to enable the autonomous agent to operate effectively, manage complex tasks, and    \n",
       "adapt based on its experiences.                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How do LLMs integrate with other technologies in an autonomous agent system?                             \n",
       "Answer: Large language models (LLMs) integrate with other technologies in an autonomous agent system by serving as \n",
       "the core controller that drives decision-making and task execution. Here are the key ways LLMs interact with other \n",
       "components and technologies within such systems:                                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Planning and Task Management</span>: LLMs are central to planning processes within the autonomous agent. They leverage \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>their ability to break down complex tasks into smaller, manageable subgoals through techniques like chain of    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>thought (CoT) prompting. This enables the agent to systematically approach multi-step tasks, providing a        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>structured way to handle complexity.                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Reflection and Refinement</span>: LLMs can engage in self-reflection and self-criticism of their decisions, learning   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>from past actions to improve future performance. This capability allows the agent to refine its approach based  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>on experiences, leading to enhanced problem-solving outcomes.                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Natural Language Interface</span>: LLMs often act as the natural language interface between the user and various       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>external components, such as memory systems and tools. They convert user queries into actions and responses,    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>processing input and generating coherent output. However, the reliability of this interface can be a challenge, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>as LLMs may occasionally produce formatting errors or may not follow instructions precisely.                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">Interaction with External Tools and APIs</span>: LLMs can direct and manage interactions with external tools and APIs, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>expanding the capabilities of the autonomous agent beyond just language understanding. They can interpret       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>results from these interactions and adjust the agent's actions accordingly, demonstrating their role in         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>integrating diverse technologies.                                                                               \n",
       "\n",
       "In summary, LLMs create a cohesive integration point in an autonomous agent system, allowing for seamless planning,\n",
       "problem-solving, and interaction with both users and external technology components, thereby enhancing the overall \n",
       "functionality and effectiveness of the system.                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How do LLMs integrate with other technologies in an autonomous agent system?                             \n",
       "Answer: Large language models (LLMs) integrate with other technologies in an autonomous agent system by serving as \n",
       "the core controller that drives decision-making and task execution. Here are the key ways LLMs interact with other \n",
       "components and technologies within such systems:                                                                   \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mPlanning and Task Management\u001b[0m: LLMs are central to planning processes within the autonomous agent. They leverage \n",
       "\u001b[1;33m   \u001b[0mtheir ability to break down complex tasks into smaller, manageable subgoals through techniques like chain of    \n",
       "\u001b[1;33m   \u001b[0mthought (CoT) prompting. This enables the agent to systematically approach multi-step tasks, providing a        \n",
       "\u001b[1;33m   \u001b[0mstructured way to handle complexity.                                                                            \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mReflection and Refinement\u001b[0m: LLMs can engage in self-reflection and self-criticism of their decisions, learning   \n",
       "\u001b[1;33m   \u001b[0mfrom past actions to improve future performance. This capability allows the agent to refine its approach based  \n",
       "\u001b[1;33m   \u001b[0mon experiences, leading to enhanced problem-solving outcomes.                                                   \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mNatural Language Interface\u001b[0m: LLMs often act as the natural language interface between the user and various       \n",
       "\u001b[1;33m   \u001b[0mexternal components, such as memory systems and tools. They convert user queries into actions and responses,    \n",
       "\u001b[1;33m   \u001b[0mprocessing input and generating coherent output. However, the reliability of this interface can be a challenge, \n",
       "\u001b[1;33m   \u001b[0mas LLMs may occasionally produce formatting errors or may not follow instructions precisely.                    \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1mInteraction with External Tools and APIs\u001b[0m: LLMs can direct and manage interactions with external tools and APIs, \n",
       "\u001b[1;33m   \u001b[0mexpanding the capabilities of the autonomous agent beyond just language understanding. They can interpret       \n",
       "\u001b[1;33m   \u001b[0mresults from these interactions and adjust the agent's actions accordingly, demonstrating their role in         \n",
       "\u001b[1;33m   \u001b[0mintegrating diverse technologies.                                                                               \n",
       "\n",
       "In summary, LLMs create a cohesive integration point in an autonomous agent system, allowing for seamless planning,\n",
       "problem-solving, and interaction with both users and external technology components, thereby enhancing the overall \n",
       "functionality and effectiveness of the system.                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What are the main components of an LLM-powered autonomous agent system?                                  \n",
       "Answer: The main components of an LLM-powered autonomous agent system include:                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Planning</span>: This involves the systematic organization of actions, particularly for complex tasks that necessitate \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>multiple steps. Key aspects include:                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Task Decomposition</span>: The agent breaks down larger tasks into smaller, manageable subgoals, often utilizing    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>techniques such as chain of thought (CoT) prompting to ensure a structured approach.                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Reflection and Refinement</span>: The agent is capable of self-evaluation, allowing it to learn from past actions,     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>identify mistakes, and improve its future performance. This iterative self-criticism enhances the quality of    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>outcomes over time.                                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Memory</span>: An effective autonomous agent system often incorporates a memory component, which enables the agent to  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>retain information from past interactions and tasks. This capability allows it to leverage previous knowledge   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and experiences in making informed decisions.                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">Natural Language Interface</span>: LLMs serve as the interface that facilitates communication between the user and the \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>system. They convert user queries into actions and manage responses, although there may be challenges with      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>reliability and consistency in understanding user instructions.                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span><span style=\"font-weight: bold\">Integration with External Tools and APIs</span>: The agent interacts with various external components and systems to   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>expand its functionality beyond mere language processing. This integration allows for a broader range of actions\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and improved task execution.                                                                                    \n",
       "\n",
       "These components work together to enable the autonomous agent to function effectively, manage complex tasks, and   \n",
       "adapt based on its experiences.                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What are the main components of an LLM-powered autonomous agent system?                                  \n",
       "Answer: The main components of an LLM-powered autonomous agent system include:                                     \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mPlanning\u001b[0m: This involves the systematic organization of actions, particularly for complex tasks that necessitate \n",
       "\u001b[1;33m   \u001b[0mmultiple steps. Key aspects include:                                                                            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mTask Decomposition\u001b[0m: The agent breaks down larger tasks into smaller, manageable subgoals, often utilizing    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mtechniques such as chain of thought (CoT) prompting to ensure a structured approach.                         \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mReflection and Refinement\u001b[0m: The agent is capable of self-evaluation, allowing it to learn from past actions,     \n",
       "\u001b[1;33m   \u001b[0midentify mistakes, and improve its future performance. This iterative self-criticism enhances the quality of    \n",
       "\u001b[1;33m   \u001b[0moutcomes over time.                                                                                             \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mMemory\u001b[0m: An effective autonomous agent system often incorporates a memory component, which enables the agent to  \n",
       "\u001b[1;33m   \u001b[0mretain information from past interactions and tasks. This capability allows it to leverage previous knowledge   \n",
       "\u001b[1;33m   \u001b[0mand experiences in making informed decisions.                                                                   \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1mNatural Language Interface\u001b[0m: LLMs serve as the interface that facilitates communication between the user and the \n",
       "\u001b[1;33m   \u001b[0msystem. They convert user queries into actions and manage responses, although there may be challenges with      \n",
       "\u001b[1;33m   \u001b[0mreliability and consistency in understanding user instructions.                                                 \n",
       "\u001b[1;33m 5 \u001b[0m\u001b[1mIntegration with External Tools and APIs\u001b[0m: The agent interacts with various external components and systems to   \n",
       "\u001b[1;33m   \u001b[0mexpand its functionality beyond mere language processing. This integration allows for a broader range of actions\n",
       "\u001b[1;33m   \u001b[0mand improved task execution.                                                                                    \n",
       "\n",
       "These components work together to enable the autonomous agent to function effectively, manage complex tasks, and   \n",
       "adapt based on its experiences.                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qa_pairs = \"\"\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever, \n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"qa_pairs\": itemgetter(\"qa_pairs\")\n",
    "    } \n",
    "    | recursive_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "for question in questions:\n",
    "    answer = rag_chain.invoke(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"qa_pairs\": qa_pairs\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    qa_pair = format_qa_pair(question, answer)\n",
    "    display(Markdown(qa_pair))\n",
    "    qa_pairs += qa_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4a8708-1c2a-4d34-a9d1-cee0b580a4dd",
   "metadata": {},
   "source": [
    "### LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "277799eb-70ca-4d70-b93b-ac62ee4c62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78609718-3a1a-4f11-b063-52ed7f695a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    all_questions: list[str]\n",
    "    current_question_idx: int\n",
    "    qa_pairs: list[str]\n",
    "    context: list[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8545d97-c61b-48bd-9659-09870773bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sub_questions(state: State, config: RunnableConfig) -> list[str]:\n",
    "    max_generated_sub_questions_count = config['configurable'].get(\"max_generated_sub_questions_count\", 3)\n",
    "    query = state['question']\n",
    "    \n",
    "    class SubQuestionsGenerator(BaseModel):\n",
    "        sub_questions: list[str] = Field(\n",
    "            ..., \n",
    "            description=\"List of generated sub-problems / sub-questions\",\n",
    "            max_items=max_generated_sub_questions_count\n",
    "        )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(SubQuestionsGenerator, method=\"function_calling\")\n",
    "    chain = (\n",
    "        decomposition_prompt\n",
    "        | structured_llm\n",
    "    )\n",
    "    response = chain.invoke(query)\n",
    "    questions = response.sub_questions + [query]\n",
    "    \n",
    "    return {\"all_questions\": questions, \"current_question_idx\": 0}\n",
    "\n",
    "\n",
    "def retrieve_docs(state: State):\n",
    "    question = state[\"all_questions\"][state[\"current_question_idx\"]]\n",
    "    retrieved_docs = vectorstore.similarity_search(question)\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    chain = (\n",
    "        recursive_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    question = state[\"all_questions\"][state[\"current_question_idx\"]]\n",
    "    answer = chain.invoke(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"qa_pairs\": state.get(\"qa_pairs\", \"\"),\n",
    "            \"context\": state[\"context\"]\n",
    "        }\n",
    "    )\n",
    "    qa_pair = format_qa_pair(question, answer)\n",
    "    qa_pairs = state.get(\"qa_pairs\", \"\") + qa_pair\n",
    "\n",
    "    if state[\"current_question_idx\"] == len(state['all_questions']) - 1:\n",
    "        return {\"answer\": answer}\n",
    "    else:\n",
    "        return {\"qa_pairs\": qa_pairs, \"current_question_idx\": state[\"current_question_idx\"] + 1}\n",
    "\n",
    "\n",
    "def check_answer_status(state: State) -> Literal[\"Next sub-question\", \"Final answer\"]:\n",
    "    if state.get(\"answer\"):\n",
    "        return \"Final answer\"\n",
    "    else:\n",
    "        return \"Next sub-question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f60d3431-881f-4c8e-b1e5-f1dbc827ff78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7ffb20574550>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"generate_sub_questions\", generate_sub_questions)\n",
    "graph_builder.add_node(\"retrieve_docs\", retrieve_docs)\n",
    "graph_builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "graph_builder.add_edge(START, \"generate_sub_questions\")\n",
    "graph_builder.add_edge(\"generate_sub_questions\", \"retrieve_docs\")\n",
    "graph_builder.add_edge(\"retrieve_docs\", \"generate_answer\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"generate_answer\", \n",
    "    check_answer_status, \n",
    "    {\n",
    "        \"Next sub-question\": \"retrieve_docs\",\n",
    "        \"Final answer\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "822a2d07-f777-45f6-ab99-15ea783f9319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_sub_questions'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'all_questions'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What is a large language model (LLM) and how does it function as a core component of an autonomous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent system?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What are the crucial hardware requirements for operating an LLM-powered autonomous agent?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'How do different components of an LLM-powered autonomous agent interact with each other to achieve </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomy?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What are the main components of an LLM-powered autonomous agent system?'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'current_question_idx'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_sub_questions'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'all_questions'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'What is a large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and how does it function as a core component of an autonomous \u001b[0m\n",
       "\u001b[32magent system?'\u001b[0m,\n",
       "            \u001b[32m'What are the crucial hardware requirements for operating an LLM-powered autonomous agent?'\u001b[0m,\n",
       "            \u001b[32m'How do different components of an LLM-powered autonomous agent interact with each other to achieve \u001b[0m\n",
       "\u001b[32mautonomy?'\u001b[0m,\n",
       "            \u001b[32m'What are the main components of an LLM-powered autonomous agent system?'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'current_question_idx'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve_docs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'55c59502-88e0-431e-a6a6-0849807e2365'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'528a5e02-d0f2-46a5-b82c-88844346f021'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language as an interface between LLMs and external components such as memory and tools. However, the reliability of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2fa4551e-4ee8-473a-a2b3-f9f0023916ae'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'7c0fa5e6-9243-49d0-83a4-e2f450a7964e'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">= \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Efficient Vector Similarity Search” July 28, 2020.\\n[7] </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve_docs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'55c59502-88e0-431e-a6a6-0849807e2365'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: \u001b[0m\n",
       "\u001b[32m31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a \u001b[0m\n",
       "\u001b[32mcool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'528a5e02-d0f2-46a5-b82c-88844346f021'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural \u001b[0m\n",
       "\u001b[32mlanguage as an interface between LLMs and external components such as memory and tools. However, the reliability of\u001b[0m\n",
       "\u001b[32mmodel outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. refuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'2fa4551e-4ee8-473a-a2b3-f9f0023916ae'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'7c0fa5e6-9243-49d0-83a4-e2f450a7964e'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Or\\n@article\u001b[0m\u001b[32m{\u001b[0m\u001b[32mweng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  \u001b[0m\n",
       "\u001b[32m= \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \u001b[0m\n",
       "\u001b[32m\"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\nReferences#\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Wei et al. “Chain of thought prompting \u001b[0m\n",
       "\u001b[32melicits reasoning in large language models.” NeurIPS 2022\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Yao et al. “Tree of Thoughts: Dliberate Problem \u001b[0m\n",
       "\u001b[32mSolving with Large Language Models.” arXiv preprint arXiv:2305.10601 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Liu et al. “Chain of Hindsight \u001b[0m\n",
       "\u001b[32mAligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Liu et al. “LLM+P: Empowering \u001b[0m\n",
       "\u001b[32mLarge Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Yao et al. \u001b[0m\n",
       "\u001b[32m“ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Google Blog. “Announcing ScaNN: \u001b[0m\n",
       "\u001b[32mEfficient Vector Similarity Search” July 28, 2020.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mhttps://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LLM) is an advanced type of artificial intelligence that is designed to understand and generate human-like text. These models are trained on vast datasets of text from the internet and other diverse sources, enabling them to perform a wide range of language tasks, such as writing, summarizing, translating, and answering questions.\n",
      "\n",
      "In the context of an autonomous agent system, an LLM functions as the \"brain\" or central controller of the system. It integrates several critical functions that allow the agent to effectively handle complex tasks. Here are the key components of how an LLM operates within such a system:\n",
      "\n",
      "1. **Planning**: The LLM helps the agent to plan its actions by identifying the necessary steps to accomplish a given task. This involves breaking down larger tasks into smaller, more manageable subgoals, which allows the agent to approach complicated problems methodically.\n",
      "\n",
      "2. **Subgoal Decomposition**: By utilizing techniques such as \"Chain of Thought\" (CoT) prompting, the LLM can guide the agent to think through complex problems step-by-step. This technique encourages the model to decompose hard tasks into simpler ones, aiding in the understanding and execution of the required actions.\n",
      "\n",
      "3. **Reflection and Refinement**: The agent can utilize the LLM's capabilities for self-assessment and learning. It reflects on past actions, critiques its decisions, and revises its approach based on previous experiences, improving future performance.\n",
      "\n",
      "4. **Natural Language Interface**: LLMs often serve as the primary interface between users and the agent's various components, including memory and tools. While this allows for intuitive interaction, it's important to note that the reliability of the model's outputs can vary, necessitating careful parsing and validation of the information generated.\n",
      "\n",
      "In summary, a large language model plays a foundational role in autonomous agents by enabling them to plan, reflect, and communicate effectively, thereby enhancing their problem-solving capabilities and overall functionality."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_answer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'qa_pairs'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Question: What is a large language model (LLM) and how does it function as a core component of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an autonomous agent system?  \\nAnswer:\\nA large language model (LLM) is an advanced type of artificial intelligence</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that is designed to understand and generate human-like text. These models are trained on vast datasets of text from</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the internet and other diverse sources, enabling them to perform a wide range of language tasks, such as writing, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarizing, translating, and answering questions.\\n\\nIn the context of an autonomous agent system, an LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">functions as the \"brain\" or central controller of the system. It integrates several critical functions that allow </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the agent to effectively handle complex tasks. Here are the key components of how an LLM operates within such a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system:\\n\\n1. **Planning**: The LLM helps the agent to plan its actions by identifying the necessary steps to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accomplish a given task. This involves breaking down larger tasks into smaller, more manageable subgoals, which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">allows the agent to approach complicated problems methodically.\\n\\n2. **Subgoal Decomposition**: By utilizing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">techniques such as \"Chain of Thought\" (CoT) prompting, the LLM can guide the agent to think through complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problems step-by-step. This technique encourages the model to decompose hard tasks into simpler ones, aiding in the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">understanding and execution of the required actions.\\n\\n3. **Reflection and Refinement**: The agent can utilize the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM\\'s capabilities for self-assessment and learning. It reflects on past actions, critiques its decisions, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">revises its approach based on previous experiences, improving future performance.\\n\\n4. **Natural Language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Interface**: LLMs often serve as the primary interface between users and the agent\\'s various components, including</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory and tools. While this allows for intuitive interaction, it\\'s important to note that the reliability of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model\\'s outputs can vary, necessitating careful parsing and validation of the information generated.\\n\\nIn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summary, a large language model plays a foundational role in autonomous agents by enabling them to plan, reflect, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and communicate effectively, thereby enhancing their problem-solving capabilities and overall functionality.\\n\\n'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'current_question_idx'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_answer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'qa_pairs'\u001b[0m: \u001b[32m'Question: What is a large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and how does it function as a core component of\u001b[0m\n",
       "\u001b[32man autonomous agent system?  \\nAnswer:\\nA large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is an advanced type of artificial intelligence\u001b[0m\n",
       "\u001b[32mthat is designed to understand and generate human-like text. These models are trained on vast datasets of text from\u001b[0m\n",
       "\u001b[32mthe internet and other diverse sources, enabling them to perform a wide range of language tasks, such as writing, \u001b[0m\n",
       "\u001b[32msummarizing, translating, and answering questions.\\n\\nIn the context of an autonomous agent system, an LLM \u001b[0m\n",
       "\u001b[32mfunctions as the \"brain\" or central controller of the system. It integrates several critical functions that allow \u001b[0m\n",
       "\u001b[32mthe agent to effectively handle complex tasks. Here are the key components of how an LLM operates within such a \u001b[0m\n",
       "\u001b[32msystem:\\n\\n1. **Planning**: The LLM helps the agent to plan its actions by identifying the necessary steps to \u001b[0m\n",
       "\u001b[32maccomplish a given task. This involves breaking down larger tasks into smaller, more manageable subgoals, which \u001b[0m\n",
       "\u001b[32mallows the agent to approach complicated problems methodically.\\n\\n2. **Subgoal Decomposition**: By utilizing \u001b[0m\n",
       "\u001b[32mtechniques such as \"Chain of Thought\" \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m prompting, the LLM can guide the agent to think through complex \u001b[0m\n",
       "\u001b[32mproblems step-by-step. This technique encourages the model to decompose hard tasks into simpler ones, aiding in the\u001b[0m\n",
       "\u001b[32munderstanding and execution of the required actions.\\n\\n3. **Reflection and Refinement**: The agent can utilize the\u001b[0m\n",
       "\u001b[32mLLM\\'s capabilities for self-assessment and learning. It reflects on past actions, critiques its decisions, and \u001b[0m\n",
       "\u001b[32mrevises its approach based on previous experiences, improving future performance.\\n\\n4. **Natural Language \u001b[0m\n",
       "\u001b[32mInterface**: LLMs often serve as the primary interface between users and the agent\\'s various components, including\u001b[0m\n",
       "\u001b[32mmemory and tools. While this allows for intuitive interaction, it\\'s important to note that the reliability of the \u001b[0m\n",
       "\u001b[32mmodel\\'s outputs can vary, necessitating careful parsing and validation of the information generated.\\n\\nIn \u001b[0m\n",
       "\u001b[32msummary, a large language model plays a foundational role in autonomous agents by enabling them to plan, reflect, \u001b[0m\n",
       "\u001b[32mand communicate effectively, thereby enhancing their problem-solving capabilities and overall functionality.\\n\\n'\u001b[0m,\n",
       "        \u001b[32m'current_question_idx'\u001b[0m: \u001b[1;36m1\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve_docs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'55c59502-88e0-431e-a6a6-0849807e2365'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2fa4551e-4ee8-473a-a2b3-f9f0023916ae'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'528a5e02-d0f2-46a5-b82c-88844346f021'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language as an interface between LLMs and external components such as memory and tools. However, the reliability of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'5c38295c-953c-4e16-9db2-88a47a5d73be'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents, I start to see a couple common limitations:'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve_docs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'55c59502-88e0-431e-a6a6-0849807e2365'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: \u001b[0m\n",
       "\u001b[32m31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a \u001b[0m\n",
       "\u001b[32mcool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'2fa4551e-4ee8-473a-a2b3-f9f0023916ae'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'528a5e02-d0f2-46a5-b82c-88844346f021'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural \u001b[0m\n",
       "\u001b[32mlanguage as an interface between LLMs and external components such as memory and tools. However, the reliability of\u001b[0m\n",
       "\u001b[32mmodel outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. refuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'5c38295c-953c-4e16-9db2-88a47a5d73be'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered \u001b[0m\n",
       "\u001b[32magents, I start to see a couple common limitations:'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To effectively operate an LLM-powered autonomous agent, several crucial hardware requirements must be met. These requirements stem from the demands of the large language model (LLM) itself and the overall system that supports the autonomous agent. Here are the key hardware considerations:\n",
      "\n",
      "1. **CPU and GPU Performance**: Powerful CPUs and GPUs are essential for training and running large language models. High-performance GPUs are particularly important for handling the computational load of running LLMs in real-time, as they provide the necessary parallel processing capabilities.\n",
      "\n",
      "2. **Memory (RAM)**: Sufficient RAM is crucial, as LLMs often require a substantial amount of memory to store model weights and handle intermediate computations. Systems should be equipped with enough RAM to accommodate the size of the model and the data processed during operation.\n",
      "\n",
      "3. **Storage**: Fast and high-capacity storage solutions, such as SSDs, are important for storing the large datasets used to train the LLMs and for quick access to the model files during inference. The storage should also allow for rapid read/write speeds to manage real-time data processing.\n",
      "\n",
      "4. **Networking Capabilities**: For distributed systems or cloud-based applications, robust networking hardware is required to facilitate communication between different components of the system. High bandwidth and low latency are necessary to ensure that the LLM can effectively interact with other modules, such as memory and tools.\n",
      "\n",
      "5. **Power Supply and Cooling**: The hardware for running LLMs can be power-intensive and generate significant heat, especially in multi-GPU setups. Adequate power supply units and cooling solutions are necessary to prevent overheating and ensure reliability over extended periods of operation.\n",
      "\n",
      "6. **Edge Processing Units**: If the autonomous agent operates in environments where cloud processing is not feasible, specialized edge processing units or AI accelerators may be necessary to run LLMs with lower latency and reduced bandwidth usage.\n",
      "\n",
      "These hardware requirements ensure that an LLM-powered autonomous agent can efficiently process information, respond to tasks, and execute plans effectively, thus fulfilling its role as a sophisticated and autonomous system."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_answer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'qa_pairs'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Question: What is a large language model (LLM) and how does it function as a core component of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an autonomous agent system?  \\nAnswer:\\nA large language model (LLM) is an advanced type of artificial intelligence</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that is designed to understand and generate human-like text. These models are trained on vast datasets of text from</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the internet and other diverse sources, enabling them to perform a wide range of language tasks, such as writing, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarizing, translating, and answering questions.\\n\\nIn the context of an autonomous agent system, an LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">functions as the \"brain\" or central controller of the system. It integrates several critical functions that allow </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the agent to effectively handle complex tasks. Here are the key components of how an LLM operates within such a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system:\\n\\n1. **Planning**: The LLM helps the agent to plan its actions by identifying the necessary steps to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accomplish a given task. This involves breaking down larger tasks into smaller, more manageable subgoals, which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">allows the agent to approach complicated problems methodically.\\n\\n2. **Subgoal Decomposition**: By utilizing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">techniques such as \"Chain of Thought\" (CoT) prompting, the LLM can guide the agent to think through complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problems step-by-step. This technique encourages the model to decompose hard tasks into simpler ones, aiding in the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">understanding and execution of the required actions.\\n\\n3. **Reflection and Refinement**: The agent can utilize the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM\\'s capabilities for self-assessment and learning. It reflects on past actions, critiques its decisions, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">revises its approach based on previous experiences, improving future performance.\\n\\n4. **Natural Language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Interface**: LLMs often serve as the primary interface between users and the agent\\'s various components, including</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory and tools. While this allows for intuitive interaction, it\\'s important to note that the reliability of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model\\'s outputs can vary, necessitating careful parsing and validation of the information generated.\\n\\nIn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summary, a large language model plays a foundational role in autonomous agents by enabling them to plan, reflect, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and communicate effectively, thereby enhancing their problem-solving capabilities and overall </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">functionality.\\n\\nQuestion: What are the crucial hardware requirements for operating an LLM-powered autonomous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent?  \\nAnswer:\\nTo effectively operate an LLM-powered autonomous agent, several crucial hardware requirements </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">must be met. These requirements stem from the demands of the large language model (LLM) itself and the overall </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system that supports the autonomous agent. Here are the key hardware considerations:\\n\\n1. **CPU and GPU </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Performance**: Powerful CPUs and GPUs are essential for training and running large language models. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">High-performance GPUs are particularly important for handling the computational load of running LLMs in real-time, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as they provide the necessary parallel processing capabilities.\\n\\n2. **Memory (RAM)**: Sufficient RAM is crucial, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as LLMs often require a substantial amount of memory to store model weights and handle intermediate computations. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Systems should be equipped with enough RAM to accommodate the size of the model and the data processed during </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">operation.\\n\\n3. **Storage**: Fast and high-capacity storage solutions, such as SSDs, are important for storing the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">large datasets used to train the LLMs and for quick access to the model files during inference. The storage should </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">also allow for rapid read/write speeds to manage real-time data processing.\\n\\n4. **Networking Capabilities**: For </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">distributed systems or cloud-based applications, robust networking hardware is required to facilitate communication</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">between different components of the system. High bandwidth and low latency are necessary to ensure that the LLM can</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectively interact with other modules, such as memory and tools.\\n\\n5. **Power Supply and Cooling**: The hardware</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for running LLMs can be power-intensive and generate significant heat, especially in multi-GPU setups. Adequate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">power supply units and cooling solutions are necessary to prevent overheating and ensure reliability over extended </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">periods of operation.\\n\\n6. **Edge Processing Units**: If the autonomous agent operates in environments where cloud</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">processing is not feasible, specialized edge processing units or AI accelerators may be necessary to run LLMs with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lower latency and reduced bandwidth usage.\\n\\nThese hardware requirements ensure that an LLM-powered autonomous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent can efficiently process information, respond to tasks, and execute plans effectively, thus fulfilling its </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">role as a sophisticated and autonomous system.\\n\\n'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'current_question_idx'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_answer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'qa_pairs'\u001b[0m: \u001b[32m'Question: What is a large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and how does it function as a core component of\u001b[0m\n",
       "\u001b[32man autonomous agent system?  \\nAnswer:\\nA large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is an advanced type of artificial intelligence\u001b[0m\n",
       "\u001b[32mthat is designed to understand and generate human-like text. These models are trained on vast datasets of text from\u001b[0m\n",
       "\u001b[32mthe internet and other diverse sources, enabling them to perform a wide range of language tasks, such as writing, \u001b[0m\n",
       "\u001b[32msummarizing, translating, and answering questions.\\n\\nIn the context of an autonomous agent system, an LLM \u001b[0m\n",
       "\u001b[32mfunctions as the \"brain\" or central controller of the system. It integrates several critical functions that allow \u001b[0m\n",
       "\u001b[32mthe agent to effectively handle complex tasks. Here are the key components of how an LLM operates within such a \u001b[0m\n",
       "\u001b[32msystem:\\n\\n1. **Planning**: The LLM helps the agent to plan its actions by identifying the necessary steps to \u001b[0m\n",
       "\u001b[32maccomplish a given task. This involves breaking down larger tasks into smaller, more manageable subgoals, which \u001b[0m\n",
       "\u001b[32mallows the agent to approach complicated problems methodically.\\n\\n2. **Subgoal Decomposition**: By utilizing \u001b[0m\n",
       "\u001b[32mtechniques such as \"Chain of Thought\" \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m prompting, the LLM can guide the agent to think through complex \u001b[0m\n",
       "\u001b[32mproblems step-by-step. This technique encourages the model to decompose hard tasks into simpler ones, aiding in the\u001b[0m\n",
       "\u001b[32munderstanding and execution of the required actions.\\n\\n3. **Reflection and Refinement**: The agent can utilize the\u001b[0m\n",
       "\u001b[32mLLM\\'s capabilities for self-assessment and learning. It reflects on past actions, critiques its decisions, and \u001b[0m\n",
       "\u001b[32mrevises its approach based on previous experiences, improving future performance.\\n\\n4. **Natural Language \u001b[0m\n",
       "\u001b[32mInterface**: LLMs often serve as the primary interface between users and the agent\\'s various components, including\u001b[0m\n",
       "\u001b[32mmemory and tools. While this allows for intuitive interaction, it\\'s important to note that the reliability of the \u001b[0m\n",
       "\u001b[32mmodel\\'s outputs can vary, necessitating careful parsing and validation of the information generated.\\n\\nIn \u001b[0m\n",
       "\u001b[32msummary, a large language model plays a foundational role in autonomous agents by enabling them to plan, reflect, \u001b[0m\n",
       "\u001b[32mand communicate effectively, thereby enhancing their problem-solving capabilities and overall \u001b[0m\n",
       "\u001b[32mfunctionality.\\n\\nQuestion: What are the crucial hardware requirements for operating an LLM-powered autonomous \u001b[0m\n",
       "\u001b[32magent?  \\nAnswer:\\nTo effectively operate an LLM-powered autonomous agent, several crucial hardware requirements \u001b[0m\n",
       "\u001b[32mmust be met. These requirements stem from the demands of the large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m itself and the overall \u001b[0m\n",
       "\u001b[32msystem that supports the autonomous agent. Here are the key hardware considerations:\\n\\n1. **CPU and GPU \u001b[0m\n",
       "\u001b[32mPerformance**: Powerful CPUs and GPUs are essential for training and running large language models. \u001b[0m\n",
       "\u001b[32mHigh-performance GPUs are particularly important for handling the computational load of running LLMs in real-time, \u001b[0m\n",
       "\u001b[32mas they provide the necessary parallel processing capabilities.\\n\\n2. **Memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRAM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m**: Sufficient RAM is crucial, \u001b[0m\n",
       "\u001b[32mas LLMs often require a substantial amount of memory to store model weights and handle intermediate computations. \u001b[0m\n",
       "\u001b[32mSystems should be equipped with enough RAM to accommodate the size of the model and the data processed during \u001b[0m\n",
       "\u001b[32moperation.\\n\\n3. **Storage**: Fast and high-capacity storage solutions, such as SSDs, are important for storing the\u001b[0m\n",
       "\u001b[32mlarge datasets used to train the LLMs and for quick access to the model files during inference. The storage should \u001b[0m\n",
       "\u001b[32malso allow for rapid read/write speeds to manage real-time data processing.\\n\\n4. **Networking Capabilities**: For \u001b[0m\n",
       "\u001b[32mdistributed systems or cloud-based applications, robust networking hardware is required to facilitate communication\u001b[0m\n",
       "\u001b[32mbetween different components of the system. High bandwidth and low latency are necessary to ensure that the LLM can\u001b[0m\n",
       "\u001b[32meffectively interact with other modules, such as memory and tools.\\n\\n5. **Power Supply and Cooling**: The hardware\u001b[0m\n",
       "\u001b[32mfor running LLMs can be power-intensive and generate significant heat, especially in multi-GPU setups. Adequate \u001b[0m\n",
       "\u001b[32mpower supply units and cooling solutions are necessary to prevent overheating and ensure reliability over extended \u001b[0m\n",
       "\u001b[32mperiods of operation.\\n\\n6. **Edge Processing Units**: If the autonomous agent operates in environments where cloud\u001b[0m\n",
       "\u001b[32mprocessing is not feasible, specialized edge processing units or AI accelerators may be necessary to run LLMs with \u001b[0m\n",
       "\u001b[32mlower latency and reduced bandwidth usage.\\n\\nThese hardware requirements ensure that an LLM-powered autonomous \u001b[0m\n",
       "\u001b[32magent can efficiently process information, respond to tasks, and execute plans effectively, thus fulfilling its \u001b[0m\n",
       "\u001b[32mrole as a sophisticated and autonomous system.\\n\\n'\u001b[0m,\n",
       "        \u001b[32m'current_question_idx'\u001b[0m: \u001b[1;36m2\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve_docs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2fa4551e-4ee8-473a-a2b3-f9f0023916ae'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'55c59502-88e0-431e-a6a6-0849807e2365'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'528a5e02-d0f2-46a5-b82c-88844346f021'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language as an interface between LLMs and external components such as memory and tools. However, the reliability of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'eab2657d-ba82-4c8b-9814-b5b8926f86d2'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve_docs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'2fa4551e-4ee8-473a-a2b3-f9f0023916ae'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'55c59502-88e0-431e-a6a6-0849807e2365'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: \u001b[0m\n",
       "\u001b[32m31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a \u001b[0m\n",
       "\u001b[32mcool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'528a5e02-d0f2-46a5-b82c-88844346f021'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural \u001b[0m\n",
       "\u001b[32mlanguage as an interface between LLMs and external components such as memory and tools. However, the reliability of\u001b[0m\n",
       "\u001b[32mmodel outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. refuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'eab2657d-ba82-4c8b-9814-b5b8926f86d2'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 13. The generative agent architecture. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Park et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThis \u001b[0m\n",
       "\u001b[32mfun simulation results in emergent social behavior, such as information diffusion, relationship memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. two \u001b[0m\n",
       "\u001b[32magents continuing the conversation topic\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and coordination of social events \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. host a party and invite many \u001b[0m\n",
       "\u001b[32mothers\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up \u001b[0m\n",
       "\u001b[32mautonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural \u001b[0m\n",
       "\u001b[32mlanguage interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format \u001b[0m\n",
       "\u001b[32mparsing.\\nHere is the system message used by AutoGPT, where \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m...\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m are user inputs:\\nYou are \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mai-name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser-provided AI bot description\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.\\nYour decisions must always be made independently without seeking user \u001b[0m\n",
       "\u001b[32massistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In an LLM-powered autonomous agent system, various components work together in a coordinated manner to achieve autonomy. The primary components and their interactions can be summarized as follows:\n",
      "\n",
      "1. **Planning**: The large language model (LLM) serves as the brain of the agent, facilitating planning by identifying necessary actions to accomplish tasks. It analyzes the overall goal and determines the sequence of steps required for execution.\n",
      "\n",
      "2. **Subgoal Decomposition**: The LLM employs techniques such as Chain of Thought (CoT) prompting to break down complex tasks into smaller, manageable subgoals. This approach not only simplifies the planning process but also helps the agent structure its thought process and actions logically.\n",
      "\n",
      "3. **Execution and Memory**: As the agent progresses through subgoals, it interacts with its memory component to retain relevant information, learned experiences, and previously executed actions. This memory allows the agent to recall past successes and failures, which informs future decision-making.\n",
      "\n",
      "4. **Reflection and Refinement**: After executing tasks, the LLM enables the agent to reflect on its performance. It assesses the effectiveness of its actions, critiques its decisions, and learns from mistakes. This self-reflection leads to refinements in strategy, enhancing the agent’s ability to address similar tasks in the future.\n",
      "\n",
      "5. **Natural Language Interface**: The interaction between the LLM and external components—such as tools or additional memory—is primarily conducted through a natural language interface. While this allows for flexible communication, it also poses challenges, as the reliability of the model's outputs can vary. As such, careful parsing and validation of these outputs are necessary to ensure coherent interaction.\n",
      "\n",
      "6. **Feedback Loop**: There exists a feedback loop where the outcomes of tasks executed by the agent inform future planning and decomposition efforts. By learning continuously from experiences and integrating this knowledge into the decision-making process, the agent improves its autonomous capabilities over time.\n",
      "\n",
      "In conclusion, the interaction between planning, subgoal decomposition, execution, memory, and reflection within an LLM-powered autonomous agent creates a synergistic environment that enhances autonomy. By utilizing the strengths of the LLM in natural language processing, the agent can navigate complex tasks independently and adaptively, learning from its experiences and refining its approaches accordingly."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_answer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'qa_pairs'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Question: What is a large language model (LLM) and how does it function as a core component of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an autonomous agent system?  \\nAnswer:\\nA large language model (LLM) is an advanced type of artificial intelligence</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that is designed to understand and generate human-like text. These models are trained on vast datasets of text from</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the internet and other diverse sources, enabling them to perform a wide range of language tasks, such as writing, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarizing, translating, and answering questions.\\n\\nIn the context of an autonomous agent system, an LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">functions as the \"brain\" or central controller of the system. It integrates several critical functions that allow </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the agent to effectively handle complex tasks. Here are the key components of how an LLM operates within such a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system:\\n\\n1. **Planning**: The LLM helps the agent to plan its actions by identifying the necessary steps to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accomplish a given task. This involves breaking down larger tasks into smaller, more manageable subgoals, which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">allows the agent to approach complicated problems methodically.\\n\\n2. **Subgoal Decomposition**: By utilizing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">techniques such as \"Chain of Thought\" (CoT) prompting, the LLM can guide the agent to think through complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problems step-by-step. This technique encourages the model to decompose hard tasks into simpler ones, aiding in the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">understanding and execution of the required actions.\\n\\n3. **Reflection and Refinement**: The agent can utilize the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM\\'s capabilities for self-assessment and learning. It reflects on past actions, critiques its decisions, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">revises its approach based on previous experiences, improving future performance.\\n\\n4. **Natural Language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Interface**: LLMs often serve as the primary interface between users and the agent\\'s various components, including</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory and tools. While this allows for intuitive interaction, it\\'s important to note that the reliability of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model\\'s outputs can vary, necessitating careful parsing and validation of the information generated.\\n\\nIn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summary, a large language model plays a foundational role in autonomous agents by enabling them to plan, reflect, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and communicate effectively, thereby enhancing their problem-solving capabilities and overall </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">functionality.\\n\\nQuestion: What are the crucial hardware requirements for operating an LLM-powered autonomous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent?  \\nAnswer:\\nTo effectively operate an LLM-powered autonomous agent, several crucial hardware requirements </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">must be met. These requirements stem from the demands of the large language model (LLM) itself and the overall </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system that supports the autonomous agent. Here are the key hardware considerations:\\n\\n1. **CPU and GPU </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Performance**: Powerful CPUs and GPUs are essential for training and running large language models. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">High-performance GPUs are particularly important for handling the computational load of running LLMs in real-time, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as they provide the necessary parallel processing capabilities.\\n\\n2. **Memory (RAM)**: Sufficient RAM is crucial, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as LLMs often require a substantial amount of memory to store model weights and handle intermediate computations. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Systems should be equipped with enough RAM to accommodate the size of the model and the data processed during </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">operation.\\n\\n3. **Storage**: Fast and high-capacity storage solutions, such as SSDs, are important for storing the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">large datasets used to train the LLMs and for quick access to the model files during inference. The storage should </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">also allow for rapid read/write speeds to manage real-time data processing.\\n\\n4. **Networking Capabilities**: For </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">distributed systems or cloud-based applications, robust networking hardware is required to facilitate communication</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">between different components of the system. High bandwidth and low latency are necessary to ensure that the LLM can</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectively interact with other modules, such as memory and tools.\\n\\n5. **Power Supply and Cooling**: The hardware</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for running LLMs can be power-intensive and generate significant heat, especially in multi-GPU setups. Adequate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">power supply units and cooling solutions are necessary to prevent overheating and ensure reliability over extended </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">periods of operation.\\n\\n6. **Edge Processing Units**: If the autonomous agent operates in environments where cloud</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">processing is not feasible, specialized edge processing units or AI accelerators may be necessary to run LLMs with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lower latency and reduced bandwidth usage.\\n\\nThese hardware requirements ensure that an LLM-powered autonomous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent can efficiently process information, respond to tasks, and execute plans effectively, thus fulfilling its </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">role as a sophisticated and autonomous system.\\n\\nQuestion: How do different components of an LLM-powered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agent interact with each other to achieve autonomy?  \\nAnswer:\\nIn an LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, various components work together in a coordinated manner to achieve autonomy. The primary components and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">their interactions can be summarized as follows:\\n\\n1. **Planning**: The large language model (LLM) serves as the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">brain of the agent, facilitating planning by identifying necessary actions to accomplish tasks. It analyzes the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">overall goal and determines the sequence of steps required for execution.\\n\\n2. **Subgoal Decomposition**: The LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">employs techniques such as Chain of Thought (CoT) prompting to break down complex tasks into smaller, manageable </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">subgoals. This approach not only simplifies the planning process but also helps the agent structure its thought </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">process and actions logically.\\n\\n3. **Execution and Memory**: As the agent progresses through subgoals, it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interacts with its memory component to retain relevant information, learned experiences, and previously executed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">actions. This memory allows the agent to recall past successes and failures, which informs future </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decision-making.\\n\\n4. **Reflection and Refinement**: After executing tasks, the LLM enables the agent to reflect </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on its performance. It assesses the effectiveness of its actions, critiques its decisions, and learns from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mistakes. This self-reflection leads to refinements in strategy, enhancing the agent’s ability to address similar </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks in the future.\\n\\n5. **Natural Language Interface**: The interaction between the LLM and external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components—such as tools or additional memory—is primarily conducted through a natural language interface. While </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">this allows for flexible communication, it also poses challenges, as the reliability of the model\\'s outputs can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">vary. As such, careful parsing and validation of these outputs are necessary to ensure coherent interaction.\\n\\n6. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Feedback Loop**: There exists a feedback loop where the outcomes of tasks executed by the agent inform future </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">planning and decomposition efforts. By learning continuously from experiences and integrating this knowledge into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the decision-making process, the agent improves its autonomous capabilities over time.\\n\\nIn conclusion, the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interaction between planning, subgoal decomposition, execution, memory, and reflection within an LLM-powered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agent creates a synergistic environment that enhances autonomy. By utilizing the strengths of the LLM in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">natural language processing, the agent can navigate complex tasks independently and adaptively, learning from its </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experiences and refining its approaches accordingly.\\n\\n'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'current_question_idx'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_answer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'qa_pairs'\u001b[0m: \u001b[32m'Question: What is a large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and how does it function as a core component of\u001b[0m\n",
       "\u001b[32man autonomous agent system?  \\nAnswer:\\nA large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is an advanced type of artificial intelligence\u001b[0m\n",
       "\u001b[32mthat is designed to understand and generate human-like text. These models are trained on vast datasets of text from\u001b[0m\n",
       "\u001b[32mthe internet and other diverse sources, enabling them to perform a wide range of language tasks, such as writing, \u001b[0m\n",
       "\u001b[32msummarizing, translating, and answering questions.\\n\\nIn the context of an autonomous agent system, an LLM \u001b[0m\n",
       "\u001b[32mfunctions as the \"brain\" or central controller of the system. It integrates several critical functions that allow \u001b[0m\n",
       "\u001b[32mthe agent to effectively handle complex tasks. Here are the key components of how an LLM operates within such a \u001b[0m\n",
       "\u001b[32msystem:\\n\\n1. **Planning**: The LLM helps the agent to plan its actions by identifying the necessary steps to \u001b[0m\n",
       "\u001b[32maccomplish a given task. This involves breaking down larger tasks into smaller, more manageable subgoals, which \u001b[0m\n",
       "\u001b[32mallows the agent to approach complicated problems methodically.\\n\\n2. **Subgoal Decomposition**: By utilizing \u001b[0m\n",
       "\u001b[32mtechniques such as \"Chain of Thought\" \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m prompting, the LLM can guide the agent to think through complex \u001b[0m\n",
       "\u001b[32mproblems step-by-step. This technique encourages the model to decompose hard tasks into simpler ones, aiding in the\u001b[0m\n",
       "\u001b[32munderstanding and execution of the required actions.\\n\\n3. **Reflection and Refinement**: The agent can utilize the\u001b[0m\n",
       "\u001b[32mLLM\\'s capabilities for self-assessment and learning. It reflects on past actions, critiques its decisions, and \u001b[0m\n",
       "\u001b[32mrevises its approach based on previous experiences, improving future performance.\\n\\n4. **Natural Language \u001b[0m\n",
       "\u001b[32mInterface**: LLMs often serve as the primary interface between users and the agent\\'s various components, including\u001b[0m\n",
       "\u001b[32mmemory and tools. While this allows for intuitive interaction, it\\'s important to note that the reliability of the \u001b[0m\n",
       "\u001b[32mmodel\\'s outputs can vary, necessitating careful parsing and validation of the information generated.\\n\\nIn \u001b[0m\n",
       "\u001b[32msummary, a large language model plays a foundational role in autonomous agents by enabling them to plan, reflect, \u001b[0m\n",
       "\u001b[32mand communicate effectively, thereby enhancing their problem-solving capabilities and overall \u001b[0m\n",
       "\u001b[32mfunctionality.\\n\\nQuestion: What are the crucial hardware requirements for operating an LLM-powered autonomous \u001b[0m\n",
       "\u001b[32magent?  \\nAnswer:\\nTo effectively operate an LLM-powered autonomous agent, several crucial hardware requirements \u001b[0m\n",
       "\u001b[32mmust be met. These requirements stem from the demands of the large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m itself and the overall \u001b[0m\n",
       "\u001b[32msystem that supports the autonomous agent. Here are the key hardware considerations:\\n\\n1. **CPU and GPU \u001b[0m\n",
       "\u001b[32mPerformance**: Powerful CPUs and GPUs are essential for training and running large language models. \u001b[0m\n",
       "\u001b[32mHigh-performance GPUs are particularly important for handling the computational load of running LLMs in real-time, \u001b[0m\n",
       "\u001b[32mas they provide the necessary parallel processing capabilities.\\n\\n2. **Memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRAM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m**: Sufficient RAM is crucial, \u001b[0m\n",
       "\u001b[32mas LLMs often require a substantial amount of memory to store model weights and handle intermediate computations. \u001b[0m\n",
       "\u001b[32mSystems should be equipped with enough RAM to accommodate the size of the model and the data processed during \u001b[0m\n",
       "\u001b[32moperation.\\n\\n3. **Storage**: Fast and high-capacity storage solutions, such as SSDs, are important for storing the\u001b[0m\n",
       "\u001b[32mlarge datasets used to train the LLMs and for quick access to the model files during inference. The storage should \u001b[0m\n",
       "\u001b[32malso allow for rapid read/write speeds to manage real-time data processing.\\n\\n4. **Networking Capabilities**: For \u001b[0m\n",
       "\u001b[32mdistributed systems or cloud-based applications, robust networking hardware is required to facilitate communication\u001b[0m\n",
       "\u001b[32mbetween different components of the system. High bandwidth and low latency are necessary to ensure that the LLM can\u001b[0m\n",
       "\u001b[32meffectively interact with other modules, such as memory and tools.\\n\\n5. **Power Supply and Cooling**: The hardware\u001b[0m\n",
       "\u001b[32mfor running LLMs can be power-intensive and generate significant heat, especially in multi-GPU setups. Adequate \u001b[0m\n",
       "\u001b[32mpower supply units and cooling solutions are necessary to prevent overheating and ensure reliability over extended \u001b[0m\n",
       "\u001b[32mperiods of operation.\\n\\n6. **Edge Processing Units**: If the autonomous agent operates in environments where cloud\u001b[0m\n",
       "\u001b[32mprocessing is not feasible, specialized edge processing units or AI accelerators may be necessary to run LLMs with \u001b[0m\n",
       "\u001b[32mlower latency and reduced bandwidth usage.\\n\\nThese hardware requirements ensure that an LLM-powered autonomous \u001b[0m\n",
       "\u001b[32magent can efficiently process information, respond to tasks, and execute plans effectively, thus fulfilling its \u001b[0m\n",
       "\u001b[32mrole as a sophisticated and autonomous system.\\n\\nQuestion: How do different components of an LLM-powered \u001b[0m\n",
       "\u001b[32mautonomous agent interact with each other to achieve autonomy?  \\nAnswer:\\nIn an LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, various components work together in a coordinated manner to achieve autonomy. The primary components and \u001b[0m\n",
       "\u001b[32mtheir interactions can be summarized as follows:\\n\\n1. **Planning**: The large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m serves as the \u001b[0m\n",
       "\u001b[32mbrain of the agent, facilitating planning by identifying necessary actions to accomplish tasks. It analyzes the \u001b[0m\n",
       "\u001b[32moverall goal and determines the sequence of steps required for execution.\\n\\n2. **Subgoal Decomposition**: The LLM \u001b[0m\n",
       "\u001b[32memploys techniques such as Chain of Thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m prompting to break down complex tasks into smaller, manageable \u001b[0m\n",
       "\u001b[32msubgoals. This approach not only simplifies the planning process but also helps the agent structure its thought \u001b[0m\n",
       "\u001b[32mprocess and actions logically.\\n\\n3. **Execution and Memory**: As the agent progresses through subgoals, it \u001b[0m\n",
       "\u001b[32minteracts with its memory component to retain relevant information, learned experiences, and previously executed \u001b[0m\n",
       "\u001b[32mactions. This memory allows the agent to recall past successes and failures, which informs future \u001b[0m\n",
       "\u001b[32mdecision-making.\\n\\n4. **Reflection and Refinement**: After executing tasks, the LLM enables the agent to reflect \u001b[0m\n",
       "\u001b[32mon its performance. It assesses the effectiveness of its actions, critiques its decisions, and learns from \u001b[0m\n",
       "\u001b[32mmistakes. This self-reflection leads to refinements in strategy, enhancing the agent’s ability to address similar \u001b[0m\n",
       "\u001b[32mtasks in the future.\\n\\n5. **Natural Language Interface**: The interaction between the LLM and external \u001b[0m\n",
       "\u001b[32mcomponents—such as tools or additional memory—is primarily conducted through a natural language interface. While \u001b[0m\n",
       "\u001b[32mthis allows for flexible communication, it also poses challenges, as the reliability of the model\\'s outputs can \u001b[0m\n",
       "\u001b[32mvary. As such, careful parsing and validation of these outputs are necessary to ensure coherent interaction.\\n\\n6. \u001b[0m\n",
       "\u001b[32m**Feedback Loop**: There exists a feedback loop where the outcomes of tasks executed by the agent inform future \u001b[0m\n",
       "\u001b[32mplanning and decomposition efforts. By learning continuously from experiences and integrating this knowledge into \u001b[0m\n",
       "\u001b[32mthe decision-making process, the agent improves its autonomous capabilities over time.\\n\\nIn conclusion, the \u001b[0m\n",
       "\u001b[32minteraction between planning, subgoal decomposition, execution, memory, and reflection within an LLM-powered \u001b[0m\n",
       "\u001b[32mautonomous agent creates a synergistic environment that enhances autonomy. By utilizing the strengths of the LLM in\u001b[0m\n",
       "\u001b[32mnatural language processing, the agent can navigate complex tasks independently and adaptively, learning from its \u001b[0m\n",
       "\u001b[32mexperiences and refining its approaches accordingly.\\n\\n'\u001b[0m,\n",
       "        \u001b[32m'current_question_idx'\u001b[0m: \u001b[1;36m3\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'retrieve_docs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'55c59502-88e0-431e-a6a6-0849807e2365'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2fa4551e-4ee8-473a-a2b3-f9f0023916ae'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'528a5e02-d0f2-46a5-b82c-88844346f021'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language as an interface between LLMs and external components such as memory and tools. However, the reliability of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'eab2657d-ba82-4c8b-9814-b5b8926f86d2'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'retrieve_docs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'55c59502-88e0-431e-a6a6-0849807e2365'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: \u001b[0m\n",
       "\u001b[32m31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a \u001b[0m\n",
       "\u001b[32mcool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'2fa4551e-4ee8-473a-a2b3-f9f0023916ae'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: \u001b[0m\n",
       "\u001b[32mPlanning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan \u001b[0m\n",
       "\u001b[32mahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for \u001b[0m\n",
       "\u001b[32menhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more \u001b[0m\n",
       "\u001b[32mtest-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into \u001b[0m\n",
       "\u001b[32mmultiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'528a5e02-d0f2-46a5-b82c-88844346f021'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural \u001b[0m\n",
       "\u001b[32mlanguage as an interface between LLMs and external components such as memory and tools. However, the reliability of\u001b[0m\n",
       "\u001b[32mmodel outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. refuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mid\u001b[0m=\u001b[32m'eab2657d-ba82-4c8b-9814-b5b8926f86d2'\u001b[0m,\n",
       "                \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 13. The generative agent architecture. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Park et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThis \u001b[0m\n",
       "\u001b[32mfun simulation results in emergent social behavior, such as information diffusion, relationship memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. two \u001b[0m\n",
       "\u001b[32magents continuing the conversation topic\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and coordination of social events \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. host a party and invite many \u001b[0m\n",
       "\u001b[32mothers\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up \u001b[0m\n",
       "\u001b[32mautonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural \u001b[0m\n",
       "\u001b[32mlanguage interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format \u001b[0m\n",
       "\u001b[32mparsing.\\nHere is the system message used by AutoGPT, where \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m...\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m are user inputs:\\nYou are \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mai-name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser-provided AI bot description\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.\\nYour decisions must always be made independently without seeking user \u001b[0m\n",
       "\u001b[32massistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main components of an LLM-powered autonomous agent system include:\n",
      "\n",
      "1. **Large Language Model (LLM)**: The core of the system, serving as the \"brain\" that processes natural language and manages the agent's functions. It integrates various capabilities essential for autonomous operations.\n",
      "\n",
      "2. **Planning**: The LLM assists in planning by identifying the necessary actions and determining the sequence of steps required to achieve specific goals.\n",
      "\n",
      "3. **Subgoal Decomposition**: Utilizing techniques like Chain of Thought (CoT) prompting, the agent breaks down complex tasks into smaller, manageable subgoals, enabling more efficient handling of overall tasks.\n",
      "\n",
      "4. **Reflection and Refinement**: The agent can reflect on its past actions, assess its decision-making, and learn from previous experiences, allowing for improved strategies in future operations.\n",
      "\n",
      "5. **Memory**: A memory component allows the agent to retain relevant information, learned experiences, and previously executed actions, enhancing its ability to recall successes and failures for better decision-making.\n",
      "\n",
      "6. **Natural Language Interface**: This component facilitates communication between the LLM and external tools or memory, allowing for intuitive interactions, although it may present challenges due to potential reliability issues with the model's outputs.\n",
      "\n",
      "Together, these components create a synergistic environment that enhances the agent's autonomy and problem-solving capabilities, enabling it to navigate and execute complex tasks independently."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generate_answer'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The main components of an LLM-powered autonomous agent system include:\\n\\n1. **Large Language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Model (LLM)**: The core of the system, serving as the \"brain\" that processes natural language and manages the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent\\'s functions. It integrates various capabilities essential for autonomous operations.\\n\\n2. **Planning**: The</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM assists in planning by identifying the necessary actions and determining the sequence of steps required to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">achieve specific goals.\\n\\n3. **Subgoal Decomposition**: Utilizing techniques like Chain of Thought (CoT) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">prompting, the agent breaks down complex tasks into smaller, manageable subgoals, enabling more efficient handling </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of overall tasks.\\n\\n4. **Reflection and Refinement**: The agent can reflect on its past actions, assess its </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decision-making, and learn from previous experiences, allowing for improved strategies in future operations.\\n\\n5. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Memory**: A memory component allows the agent to retain relevant information, learned experiences, and previously</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">executed actions, enhancing its ability to recall successes and failures for better decision-making.\\n\\n6. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Natural Language Interface**: This component facilitates communication between the LLM and external tools or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory, allowing for intuitive interactions, although it may present challenges due to potential reliability issues</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with the model\\'s outputs.\\n\\nTogether, these components create a synergistic environment that enhances the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent\\'s autonomy and problem-solving capabilities, enabling it to navigate and execute complex tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">independently.'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'generate_answer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'answer'\u001b[0m: \u001b[32m'The main components of an LLM-powered autonomous agent system include:\\n\\n1. **Large Language \u001b[0m\n",
       "\u001b[32mModel \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m**: The core of the system, serving as the \"brain\" that processes natural language and manages the \u001b[0m\n",
       "\u001b[32magent\\'s functions. It integrates various capabilities essential for autonomous operations.\\n\\n2. **Planning**: The\u001b[0m\n",
       "\u001b[32mLLM assists in planning by identifying the necessary actions and determining the sequence of steps required to \u001b[0m\n",
       "\u001b[32machieve specific goals.\\n\\n3. **Subgoal Decomposition**: Utilizing techniques like Chain of Thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mprompting, the agent breaks down complex tasks into smaller, manageable subgoals, enabling more efficient handling \u001b[0m\n",
       "\u001b[32mof overall tasks.\\n\\n4. **Reflection and Refinement**: The agent can reflect on its past actions, assess its \u001b[0m\n",
       "\u001b[32mdecision-making, and learn from previous experiences, allowing for improved strategies in future operations.\\n\\n5. \u001b[0m\n",
       "\u001b[32m**Memory**: A memory component allows the agent to retain relevant information, learned experiences, and previously\u001b[0m\n",
       "\u001b[32mexecuted actions, enhancing its ability to recall successes and failures for better decision-making.\\n\\n6. \u001b[0m\n",
       "\u001b[32m**Natural Language Interface**: This component facilitates communication between the LLM and external tools or \u001b[0m\n",
       "\u001b[32mmemory, allowing for intuitive interactions, although it may present challenges due to potential reliability issues\u001b[0m\n",
       "\u001b[32mwith the model\\'s outputs.\\n\\nTogether, these components create a synergistic environment that enhances the \u001b[0m\n",
       "\u001b[32magent\\'s autonomy and problem-solving capabilities, enabling it to navigate and execute complex tasks \u001b[0m\n",
       "\u001b[32mindependently.'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The main components of an LLM-powered autonomous agent system include:                                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Large Language Model (LLM)</span>: The core of the system, serving as the \"brain\" that processes natural language and  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>manages the agent's functions. It integrates various capabilities essential for autonomous operations.          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Planning</span>: The LLM assists in planning by identifying the necessary actions and determining the sequence of steps\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>required to achieve specific goals.                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Subgoal Decomposition</span>: Utilizing techniques like Chain of Thought (CoT) prompting, the agent breaks down complex\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>tasks into smaller, manageable subgoals, enabling more efficient handling of overall tasks.                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">Reflection and Refinement</span>: The agent can reflect on its past actions, assess its decision-making, and learn from\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>previous experiences, allowing for improved strategies in future operations.                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span><span style=\"font-weight: bold\">Memory</span>: A memory component allows the agent to retain relevant information, learned experiences, and previously \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>executed actions, enhancing its ability to recall successes and failures for better decision-making.            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 6 </span><span style=\"font-weight: bold\">Natural Language Interface</span>: This component facilitates communication between the LLM and external tools or      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>memory, allowing for intuitive interactions, although it may present challenges due to potential reliability    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>issues with the model's outputs.                                                                                \n",
       "\n",
       "Together, these components create a synergistic environment that enhances the agent's autonomy and problem-solving \n",
       "capabilities, enabling it to navigate and execute complex tasks independently.                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "The main components of an LLM-powered autonomous agent system include:                                             \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mLarge Language Model (LLM)\u001b[0m: The core of the system, serving as the \"brain\" that processes natural language and  \n",
       "\u001b[1;33m   \u001b[0mmanages the agent's functions. It integrates various capabilities essential for autonomous operations.          \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mPlanning\u001b[0m: The LLM assists in planning by identifying the necessary actions and determining the sequence of steps\n",
       "\u001b[1;33m   \u001b[0mrequired to achieve specific goals.                                                                             \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mSubgoal Decomposition\u001b[0m: Utilizing techniques like Chain of Thought (CoT) prompting, the agent breaks down complex\n",
       "\u001b[1;33m   \u001b[0mtasks into smaller, manageable subgoals, enabling more efficient handling of overall tasks.                     \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1mReflection and Refinement\u001b[0m: The agent can reflect on its past actions, assess its decision-making, and learn from\n",
       "\u001b[1;33m   \u001b[0mprevious experiences, allowing for improved strategies in future operations.                                    \n",
       "\u001b[1;33m 5 \u001b[0m\u001b[1mMemory\u001b[0m: A memory component allows the agent to retain relevant information, learned experiences, and previously \n",
       "\u001b[1;33m   \u001b[0mexecuted actions, enhancing its ability to recall successes and failures for better decision-making.            \n",
       "\u001b[1;33m 6 \u001b[0m\u001b[1mNatural Language Interface\u001b[0m: This component facilitates communication between the LLM and external tools or      \n",
       "\u001b[1;33m   \u001b[0mmemory, allowing for intuitive interactions, although it may present challenges due to potential reliability    \n",
       "\u001b[1;33m   \u001b[0missues with the model's outputs.                                                                                \n",
       "\n",
       "Together, these components create a synergistic environment that enhances the agent's autonomy and problem-solving \n",
       "capabilities, enabling it to navigate and execute complex tasks independently.                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"max_generated_sub_questions_count\": 3\n",
    "    }\n",
    "}\n",
    "\n",
    "for stream_mode, event in graph.stream(\n",
    "    {\"question\": query}, \n",
    "    stream_mode=[\"messages\", \"updates\"],\n",
    "    config=config\n",
    "):\n",
    "    match stream_mode:\n",
    "        case \"messages\":\n",
    "            message, metadata = event\n",
    "            print(message.content, end=\"\", flush=True)\n",
    "        case \"updates\":\n",
    "            rprint(event)\n",
    "\n",
    "display(Markdown(event['generate_answer']['answer']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-rag",
   "language": "python",
   "name": "llm-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
